#!/usr/bin/env python3
"""
An√°lise completa e robusta do dataset GOLD_TRADING_READY_2M
para identificar problemas de converg√™ncia de RL
"""

import pandas as pd
import numpy as np
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

def analyze_dataset_complete():
    """An√°lise completa do dataset"""
    
    print("="*90)
    print("AN√ÅLISE COMPLETA DO DATASET GOLD_TRADING_READY_2M - PROBLEMAS DE CONVERG√äNCIA RL")
    print("="*90)
    
    # Carregar dataset
    filepath = r"D:\Projeto\data\GOLD_TRADING_READY_2M_20250803_222334.csv"
    df = pd.read_csv(filepath)
    
    # Converter timestamp e calcular returns
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    df.set_index('timestamp', inplace=True)
    df['returns'] = df['close'].pct_change()
    df['log_returns'] = np.log(df['close'] / df['close'].shift(1))
    
    print(f"\nüìä ESTRUTURA B√ÅSICA:")
    print(f"   Tamanho: {df.shape[0]:,} linhas x {df.shape[1]} colunas")
    print(f"   Per√≠odo: {df.index[0]} at√© {df.index[-1]}")
    print(f"   Colunas: {list(df.columns)}")
    
    # ========== AN√ÅLISES CR√çTICAS ==========
    
    print(f"\nüîç 1. AN√ÅLISE DE REGIMES (CR√çTICO)")
    print("="*50)
    
    if 'regime' in df.columns:
        regime_stats = df.groupby('regime')['returns'].agg(['count', 'mean', 'std']).round(8)
        print("Performance por regime:")
        print(regime_stats)
        
        # Verificar se regimes s√£o distintivos
        mean_diff = regime_stats['mean'].max() - regime_stats['mean'].min()
        std_diff = regime_stats['std'].max() - regime_stats['std'].min()
        
        print(f"\nDiferen√ßa entre regimes:")
        print(f"   Returns m√©dios: {mean_diff:.8f}")
        print(f"   Volatilidade: {std_diff:.8f}")
        
        if mean_diff < 0.0001:  # < 0.01%
            print("üö® PROBLEMA CR√çTICO: Regimes t√™m performance id√™ntica - ZERO predibilidade!")
        elif mean_diff < 0.001:  # < 0.1%
            print("‚ö†Ô∏è  PROBLEMA: Regimes pouco distintivos - dificulta aprendizado RL")
        else:
            print("‚úÖ Regimes suficientemente distintivos")
    else:
        print("‚ùå Coluna 'regime' n√£o encontrada")
    
    print(f"\nüîç 2. DISTRIBUI√á√ÉO DOS RETURNS")
    print("="*50)
    
    returns = df['returns'].dropna()
    
    # Estat√≠sticas b√°sicas
    print(f"Estat√≠sticas dos returns:")
    print(f"   M√©dia: {returns.mean():.8f}")
    print(f"   Desvio padr√£o: {returns.std():.6f}")
    print(f"   Assimetria: {stats.skew(returns):.6f}")
    print(f"   Curtose: {stats.kurtosis(returns):.6f}")
    
    # Outliers
    Q1, Q3 = returns.quantile([0.25, 0.75])
    IQR = Q3 - Q1
    outliers = returns[(returns < Q1 - 1.5*IQR) | (returns > Q3 + 1.5*IQR)]
    outlier_pct = len(outliers) / len(returns) * 100
    
    print(f"   Outliers: {len(outliers):,} ({outlier_pct:.2f}%)")
    print(f"   Range outliers: [{outliers.min():.6f}, {outliers.max():.6f}]")
    
    # Returns zerados
    zero_returns = (returns == 0).sum()
    zero_pct = zero_returns / len(returns) * 100
    print(f"   Returns zerados: {zero_returns:,} ({zero_pct:.3f}%)")
    
    if outlier_pct > 10:
        print("‚ö†Ô∏è  PROBLEMA: Muitos outliers podem dificultar aprendizado")
    if zero_pct > 1:
        print("‚ö†Ô∏è  PROBLEMA: Muitos returns zerados - poss√≠vel problema de dados")
    
    print(f"\nüîç 3. AUTOCORRELA√á√ÉO E PREDIBILIDADE")
    print("="*50)
    
    # Autocorrela√ß√£o
    lags = [1, 5, 10, 20, 50]
    autocorrs = [returns.autocorr(lag=lag) for lag in lags]
    
    print("Autocorrela√ß√£o dos returns:")
    for lag, autocorr in zip(lags, autocorrs):
        print(f"   Lag {lag:2d}: {autocorr:.6f}")
    
    # Autocorrela√ß√£o significativa
    significant_autocorr = [abs(ac) > 0.05 for ac in autocorrs]
    
    if autocorrs[0] < -0.1:
        print("üö® PROBLEMA CR√çTICO: Forte autocorrela√ß√£o negativa - dados artificiais?")
    elif any(significant_autocorr):
        print("‚úÖ Autocorrela√ß√£o detectada - h√° padr√µes para RL aprender")
    else:
        print("‚ö†Ô∏è  Baixa autocorrela√ß√£o - dificulta predi√ß√£o")
    
    # Volatilidade clustering
    returns_sq = returns ** 2
    vol_autocorr = [returns_sq.autocorr(lag=lag) for lag in lags[:3]]
    print(f"\nVolatilidade clustering (returns¬≤):")
    for lag, autocorr in zip(lags[:3], vol_autocorr):
        print(f"   Lag {lag:2d}: {autocorr:.6f}")
    
    if vol_autocorr[0] > 0.1:
        print("‚úÖ Clustering de volatilidade detectado - padr√£o realista")
    else:
        print("‚ö†Ô∏è  Pouco clustering de volatilidade")
    
    print(f"\nüîç 4. QUALIDADE DOS DADOS OHLC")
    print("="*50)
    
    # Consist√™ncia OHLC
    high_issues = (df['high'] < df[['open', 'close']].max(axis=1)).sum()
    low_issues = (df['low'] > df[['open', 'close']].min(axis=1)).sum()
    
    print(f"Inconsist√™ncias OHLC:")
    print(f"   High < max(Open,Close): {high_issues:,}")
    print(f"   Low > min(Open,Close): {low_issues:,}")
    
    if high_issues > 0 or low_issues > 0:
        print("üö® PROBLEMA CR√çTICO: Dados OHLC inconsistentes!")
    else:
        print("‚úÖ Dados OHLC consistentes")
    
    # Missing values
    missing_total = df.isnull().sum().sum()
    print(f"   Missing values total: {missing_total:,}")
    
    # Gaps extremos
    price_changes = df['close'].pct_change().abs()
    extreme_gaps = (price_changes > 0.1).sum()  # > 10%
    print(f"   Gaps extremos (>10%): {extreme_gaps:,}")
    
    if extreme_gaps > len(df) * 0.001:  # > 0.1%
        print("‚ö†Ô∏è  PROBLEMA: Muitos gaps extremos")
    
    print(f"\nüîç 5. VOLUME E CORRELA√á√ïES")
    print("="*50)
    
    # Volume statistics
    print(f"Volume:")
    print(f"   M√©dia: {df['volume'].mean():,.0f}")
    print(f"   Desvio padr√£o: {df['volume'].std():,.0f}")
    print(f"   Min/Max: {df['volume'].min():,.0f} / {df['volume'].max():,.0f}")
    
    # Volume constante (problema sint√©tico)
    volume_unique_pct = df['volume'].nunique() / len(df) * 100
    print(f"   Valores √∫nicos: {df['volume'].nunique():,} ({volume_unique_pct:.2f}%)")
    
    if volume_unique_pct < 1:
        print("üö® PROBLEMA: Volume muito repetitivo - dados sint√©ticos mal constru√≠dos")
    
    # Correla√ß√µes importantes
    vol_ret_corr = df['volume'].corr(returns.abs())
    vol_range_corr = df['volume'].corr((df['high'] - df['low']) / df['close'])
    
    print(f"\nCorrela√ß√µes:")
    print(f"   Volume vs |Returns|: {vol_ret_corr:.6f}")
    print(f"   Volume vs Range: {vol_range_corr:.6f}")
    
    if abs(vol_ret_corr) < 0.01 and abs(vol_range_corr) < 0.01:
        print("üö® PROBLEMA: Volume n√£o correlacionado - elimina informa√ß√£o t√©cnica")
    
    print(f"\nüîç 6. INDICADORES T√âCNICOS")
    print("="*50)
    
    # Verificar indicadores existentes
    tech_indicators = [col for col in df.columns if any(ind in col.lower() 
                      for ind in ['sma', 'ema', 'rsi', 'macd', 'bb', 'atr', 'momentum', 'stoch'])]
    
    print(f"Indicadores t√©cnicos encontrados: {len(tech_indicators)}")
    print(f"   {tech_indicators}")
    
    if len(tech_indicators) == 0:
        print("üö® PROBLEMA CR√çTICO: Nenhum indicador t√©cnico - agente RL precisa de features!")
        
        # Criar indicadores b√°sicos para an√°lise
        print("\nCriando indicadores b√°sicos para an√°lise...")
        df['sma_20'] = df['close'].rolling(20).mean()
        df['volatility'] = returns.rolling(20).std()
        
        # RSI simplificado
        delta = df['close'].diff()
        gain = delta.where(delta > 0, 0).rolling(14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
        df['rsi'] = 100 - (100 / (1 + gain / loss))
        
        tech_indicators = ['sma_20', 'volatility', 'rsi']
        print(f"   Criados: {tech_indicators}")
    
    # An√°lise dos indicadores
    for indicator in tech_indicators[:3]:  # Analisar primeiros 3
        if indicator in df.columns:
            ind_data = df[indicator].dropna()
            if len(ind_data) > 100:
                ind_std = ind_data.std()
                ind_range = ind_data.max() - ind_data.min()
                
                print(f"\n{indicator.upper()}:")
                print(f"   Range: [{ind_data.min():.4f}, {ind_data.max():.4f}]")
                print(f"   Std: {ind_std:.6f}")
                
                if ind_std < 1e-6:
                    print(f"   üö® PROBLEMA: {indicator} √© praticamente constante!")
    
    print(f"\nüîç 7. AN√ÅLISE TEMPORAL E REGIMES")
    print("="*50)
    
    # An√°lise por per√≠odos
    df_temp = df.copy()
    df_temp.reset_index(inplace=True)
    df_temp['period'] = df_temp.index // 100000  # Per√≠odos de 100k
    
    period_stats = df_temp.groupby('period')['returns'].agg(['mean', 'std']).round(8)
    print("Estat√≠sticas por per√≠odo (100k obs):")
    print(period_stats.head(10))
    
    # Verificar drift temporal
    period_means = period_stats['mean']
    mean_trend = np.corrcoef(range(len(period_means)), period_means)[0,1]
    print(f"\nTend√™ncia temporal dos returns: {mean_trend:.6f}")
    
    if abs(mean_trend) > 0.3:
        print("‚ö†Ô∏è  PROBLEMA: Forte tend√™ncia temporal - dados n√£o estacion√°rios")
    
    # Estabilidade da volatilidade
    period_stds = period_stats['std']
    vol_cv = period_stds.std() / period_stds.mean()
    print(f"Coeficiente de varia√ß√£o da volatilidade: {vol_cv:.4f}")
    
    if vol_cv > 0.5:
        print("‚ö†Ô∏è  PROBLEMA: Volatilidade muito inst√°vel entre per√≠odos")
    
    print(f"\nüîç 8. RESUMO DE PROBLEMAS CR√çTICOS PARA RL")
    print("="*60)
    
    problems = []
    
    # 1. Regimes n√£o distintivos
    if 'regime' in df.columns:
        regime_stats = df.groupby('regime')['returns'].agg(['mean', 'std'])
        mean_diff = regime_stats['mean'].max() - regime_stats['mean'].min()
        if mean_diff < 0.0001:
            problems.append("CR√çTICO: Regimes com performance id√™ntica - zero predibilidade")
        elif mean_diff < 0.001:
            problems.append("GRAVE: Regimes pouco distintivos - dificulta aprendizado")
    
    # 2. Falta de features t√©cnicas
    if len(tech_indicators) == 0:
        problems.append("CR√çTICO: Nenhum indicador t√©cnico no dataset")
    elif len(tech_indicators) < 5:
        problems.append("GRAVE: Poucos indicadores t√©cnicos - features insuficientes")
    
    # 3. Dados OHLC inconsistentes
    if high_issues > 0 or low_issues > 0:
        problems.append(f"CR√çTICO: {high_issues + low_issues} inconsist√™ncias OHLC")
    
    # 4. Volume n√£o correlacionado
    if abs(vol_ret_corr) < 0.01:
        problems.append("GRAVE: Volume n√£o correlacionado com price action")
    
    # 5. Autocorrela√ß√£o problem√°tica
    if autocorrs[0] < -0.1:
        problems.append("CR√çTICO: Autocorrela√ß√£o negativa extrema - dados artificiais")
    elif all(abs(ac) < 0.02 for ac in autocorrs):
        problems.append("GRAVE: Aus√™ncia de autocorrela√ß√£o - dificulta predi√ß√£o")
    
    # 6. Returns zerados excessivos
    if zero_pct > 1:
        problems.append(f"GRAVE: {zero_pct:.2f}% returns zerados - problema de dados")
    
    # 7. Outliers excessivos
    if outlier_pct > 10:
        problems.append(f"MODERADO: {outlier_pct:.1f}% outliers - pode dificultar treinamento")
    
    # 8. Volume sint√©tico
    if volume_unique_pct < 1:
        problems.append("GRAVE: Volume muito repetitivo - sint√©tico mal constru√≠do")
    
    # 9. Volatilidade inst√°vel
    if vol_cv > 0.5:
        problems.append("MODERADO: Volatilidade muito inst√°vel entre per√≠odos")
    
    # Resumo final
    print(f"TOTAL DE PROBLEMAS IDENTIFICADOS: {len(problems)}")
    print()
    
    for i, problem in enumerate(problems, 1):
        severity = problem.split(':')[0]
        if severity == "CR√çTICO":
            print(f"üö® {i:2d}. {problem}")
        elif severity == "GRAVE":
            print(f"‚ö†Ô∏è  {i:2d}. {problem}")
        else:
            print(f"üìã {i:2d}. {problem}")
    
    # Diagn√≥stico final
    critical_count = sum(1 for p in problems if p.startswith("CR√çTICO"))
    grave_count = sum(1 for p in problems if p.startswith("GRAVE"))
    
    print(f"\n" + "="*60)
    print("DIAGN√ìSTICO FINAL DE CONVERG√äNCIA RL")
    print("="*60)
    
    if critical_count > 0:
        print("üö® CONVERG√äNCIA: IMPOSS√çVEL")
        print(f"   {critical_count} problemas cr√≠ticos impedem qualquer aprendizado")
        print("   A√á√ÉO: Recriar dataset completamente")
    elif grave_count >= 3:
        print("‚ö†Ô∏è  CONVERG√äNCIA: MUITO IMPROV√ÅVEL") 
        print(f"   {grave_count} problemas graves dificultam severamente o aprendizado")
        print("   A√á√ÉO: Corrigir problemas graves antes do treinamento")
    elif grave_count >= 1:
        print("üìã CONVERG√äNCIA: POSS√çVEL MAS DIF√çCIL")
        print(f"   {grave_count} problemas graves podem atrasar converg√™ncia")
        print("   A√á√ÉO: Corrigir se poss√≠vel, monitorar treinamento")
    else:
        print("‚úÖ CONVERG√äNCIA: PROV√ÅVEL")
        print("   Dataset adequado para treinamento RL")
    
    print(f"\nTotal de observa√ß√µes analisadas: {len(df):,}")
    print(f"Per√≠odo de an√°lise: {df.index[0].strftime('%Y-%m-%d')} at√© {df.index[-1].strftime('%Y-%m-%d')}")
    
    print("\n" + "="*90)
    print("AN√ÅLISE CONCLU√çDA")
    print("="*90)
    
    return df, problems

if __name__ == "__main__":
    df, problems = analyze_dataset_complete()