#!/usr/bin/env python3
"""
ğŸš€ CRIADOR DE DATASET OTIMIZADO PARA AVALIAÃ‡ÃƒO - V4 BASE
======================================================

OBJETIVO: Criar dataset pequeno e rÃ¡pido baseado no V4 existente
- Usar dataset V4 como base (dados confiÃ¡veis)
- Extrair Ãºltimas 50k barras (vs 216k atuais)
- Features prÃ©-computadas 
- Formato idÃªntico ao dataset V4
- ~5x mais rÃ¡pido para testes
"""

import pandas as pd
import numpy as np
from datetime import datetime
import os
import warnings
warnings.filterwarnings('ignore')

def load_v4_dataset():
    """
    ğŸ“Š Carregar dataset V4 original
    """
    print("ğŸ“Š Carregando dataset V4 original...")
    
    dataset_path = 'D:/Projeto/data/GC=F_REALISTIC_V4_20250911_235945.csv'
    
    try:
        data = pd.read_csv(dataset_path)
        print(f"âœ… Dataset V4 carregado: {len(data)} barras")
        print(f"   PerÃ­odo: {data['time'].min()} a {data['time'].max()}")
        print(f"   Colunas: {list(data.columns)}")
        
        return data
        
    except Exception as e:
        print(f"âŒ Erro ao carregar dataset V4: {e}")
        return None

def optimize_v4_for_eval(data, target_size=50000):
    """
    ğŸ¯ Otimizar dataset V4 para avaliaÃ§Ã£o rÃ¡pida
    """
    print(f"ğŸ¯ Otimizando dataset V4: {len(data)} â†’ {target_size} barras")
    
    # Pegar dados mais recentes (final do dataset)
    optimized = data.tail(target_size).reset_index(drop=True)
    
    # Converter time para datetime se string
    if 'time' in optimized.columns:
        if optimized['time'].dtype == 'object':
            optimized['time'] = pd.to_datetime(optimized['time'])
    
    print(f"âœ… Dataset otimizado: {len(optimized)} barras")
    print(f"   PerÃ­odo otimizado: {optimized['time'].min()} a {optimized['time'].max()}")
    
    return optimized

def add_missing_1m_columns(data):
    """
    ğŸ”§ Garantir que todas as colunas _1m estejam presentes
    """
    print("ğŸ”§ Verificando colunas _1m...")
    
    # Mapeamento para garantir formato 1m
    required_mappings = {
        'open': 'open_1m',
        'high': 'high_1m', 
        'low': 'low_1m',
        'close': 'close_1m',
        'tick_volume': 'tick_volume_1m'
    }
    
    # Aplicar mapeamentos se necessÃ¡rio
    for old_col, new_col in required_mappings.items():
        if old_col in data.columns and new_col not in data.columns:
            data[new_col] = data[old_col]
            print(f"  âœ… Criado: {old_col} â†’ {new_col}")
    
    # Verificar features tÃ©cnicas mÃ­nimas _1m
    required_features_1m = [
        'returns_1m', 'volatility_20_1m', 'sma_20_1m', 'sma_50_1m', 
        'rsi_14_1m', 'stoch_k_1m', 'bb_position_1m', 'trend_strength_1m'
    ]
    
    missing_features = [f for f in required_features_1m if f not in data.columns]
    
    if missing_features:
        print(f"  âš ï¸ Features ausentes: {missing_features}")
        
        # Criar features bÃ¡sicas se ausentes
        if 'returns_1m' in missing_features and 'close_1m' in data.columns:
            data['returns_1m'] = data['close_1m'].pct_change().fillna(0)
            print("  âœ… Criado: returns_1m")
        
        if 'volatility_20_1m' in missing_features and 'close_1m' in data.columns:
            data['volatility_20_1m'] = data['close_1m'].rolling(20).std().fillna(0.001)
            print("  âœ… Criado: volatility_20_1m")
            
        if 'sma_20_1m' in missing_features and 'close_1m' in data.columns:
            data['sma_20_1m'] = data['close_1m'].rolling(20).mean().fillna(data['close_1m'])
            print("  âœ… Criado: sma_20_1m")
        
        # Features com valores padrÃ£o para velocidade
        for feature in missing_features:
            if feature not in data.columns:
                if 'rsi' in feature:
                    data[feature] = 50.0
                elif 'stoch' in feature:
                    data[feature] = 50.0  
                elif 'bb_position' in feature:
                    data[feature] = 0.5
                else:
                    data[feature] = 0.001
                print(f"  âœ… Criado com valor padrÃ£o: {feature}")
    
    return data

def validate_eval_dataset(data):
    """
    âœ… Validar dataset otimizado para compatibilidade
    """
    print("âœ… Validando dataset otimizado...")
    
    # Verificar tamanho mÃ­nimo
    if len(data) < 20000:
        print(f"âŒ Dataset muito pequeno: {len(data)} barras (mÃ­nimo 20k)")
        return False
    
    # Verificar colunas essenciais
    essential_columns = ['time', 'close_1m', 'open_1m', 'high_1m', 'low_1m']
    missing_essential = [col for col in essential_columns if col not in data.columns]
    
    if missing_essential:
        print(f"âŒ Colunas essenciais ausentes: {missing_essential}")
        return False
    
    # Verificar dados vÃ¡lidos
    null_percentage = data.isnull().sum().sum() / (len(data) * len(data.columns)) * 100
    if null_percentage > 10:
        print(f"âŒ Muitos valores nulos: {null_percentage:.1f}% (mÃ¡ximo 10%)")
        return False
    
    # Verificar sequÃªncia temporal
    if 'time' in data.columns:
        time_diffs = pd.to_datetime(data['time']).diff().dt.total_seconds()
        invalid_times = time_diffs[time_diffs <= 0].count()
        if invalid_times > len(data) * 0.01:  # MÃ¡ximo 1% de problemas temporais
            print(f"âŒ SequÃªncia temporal invÃ¡lida: {invalid_times} problemas")
            return False
    
    print(f"âœ… Dataset vÃ¡lido para avaliaÃ§Ã£o:")
    print(f"   ğŸ“Š Barras: {len(data):,}")
    print(f"   ğŸ“ˆ Colunas: {len(data.columns)}")
    print(f"   ğŸ” Valores nulos: {null_percentage:.2f}%")
    print(f"   â° PerÃ­odo: {data['time'].min()} a {data['time'].max()}")
    
    return True

def save_optimized_dataset(data, filename=None):
    """
    ğŸ’¾ Salvar dataset otimizado
    """
    if filename is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"GC=F_EVAL_OPTIMIZED_V4_{timestamp}.csv"
    
    filepath = f"D:/Projeto/data/{filename}"
    
    print(f"ğŸ’¾ Salvando dataset otimizado: {filename}")
    
    try:
        data.to_csv(filepath, index=False)
        
        file_size_mb = os.path.getsize(filepath) / (1024*1024)
        print(f"âœ… Dataset salvo:")
        print(f"   ğŸ“ Arquivo: {filename}")
        print(f"   ğŸ“Š Tamanho: {file_size_mb:.1f} MB")
        print(f"   ğŸ“ˆ Barras: {len(data):,}")
        print(f"   ğŸ” Colunas: {len(data.columns)}")
        
        return filepath
        
    except Exception as e:
        print(f"âŒ Erro ao salvar: {e}")
        return None

def calculate_optimization_stats(original_size, optimized_size):
    """
    ğŸ“Š Calcular estatÃ­sticas de otimizaÃ§Ã£o
    """
    reduction = (1 - optimized_size / original_size) * 100
    speedup = original_size / optimized_size
    
    print("\nğŸ“Š ESTATÃSTICAS DE OTIMIZAÃ‡ÃƒO:")
    print(f"   ğŸ“‰ ReduÃ§Ã£o de tamanho: {reduction:.1f}%")
    print(f"   âš¡ Speedup esperado: {speedup:.1f}x mais rÃ¡pido")
    print(f"   ğŸ’¾ Dados originais: {original_size:,} barras")
    print(f"   ğŸ¯ Dados otimizados: {optimized_size:,} barras")

def main():
    """
    ğŸš€ FunÃ§Ã£o principal: Criar dataset de avaliaÃ§Ã£o otimizado do V4
    """
    print("ğŸš€ CRIANDO DATASET DE AVALIAÃ‡ÃƒO OTIMIZADO - V4 BASE")
    print("=" * 60)
    
    # 1. Carregar dataset V4
    data = load_v4_dataset()
    if data is None:
        return False
    
    original_size = len(data)
    
    # 2. Otimizar tamanho (pegar Ãºltimas 50k barras)
    target_size = 50000
    data = optimize_v4_for_eval(data, target_size=target_size)
    
    # 3. Garantir colunas _1m
    data = add_missing_1m_columns(data)
    
    # 4. Validar dataset
    if not validate_eval_dataset(data):
        print("âŒ Dataset invÃ¡lido apÃ³s otimizaÃ§Ã£o")
        return False
    
    # 5. Salvar dataset otimizado
    filepath = save_optimized_dataset(data)
    if filepath is None:
        return False
    
    # 6. Mostrar estatÃ­sticas
    calculate_optimization_stats(original_size, len(data))
    
    print("\n" + "=" * 60)
    print("âœ… DATASET DE AVALIAÃ‡ÃƒO OTIMIZADO CRIADO!")
    print(f"ğŸ“ Arquivo: {os.path.basename(filepath)}")
    print(f"ğŸ“Š Dados: {len(data):,} barras")
    print(f"ğŸ• PerÃ­odo: {data['time'].min()} a {data['time'].max()}")
    print(f"âš¡ Performance: ~{original_size/len(data):.1f}x mais rÃ¡pido")
    
    print("\nğŸ¯ PRÃ“XIMOS PASSOS:")
    print("1. Atualizar completo_1m_optimized.py para usar este dataset")
    print("2. Testar velocidade de avaliaÃ§Ã£o")
    print("3. Validar mÃ©tricas vs dataset V4 completo")
    print("4. Comparar consistÃªncia dos resultados")
    
    return True

if __name__ == "__main__":
    main()