#!/usr/bin/env python3
"""
üîç INVESTIGA√á√ÉO PROFUNDA - BUG ACTION[1] ESTRUTURAL
Vamos descobrir o que est√° acontecendo com o action space
"""

import sys
import os
import numpy as np
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

projeto_path = Path("D:/Projeto")
sys.path.insert(0, str(projeto_path))

def investigar_action_bug():
    print("üîç INVESTIGA√á√ÉO PROFUNDA - BUG ACTION[1]")
    print("=" * 50)
    
    # 1. Carregar modelo e analisar architecture
    checkpoint_path = projeto_path / "trading_framework/training/checkpoints/DAYTRADER/checkpoint_phase2riskmanagement_650000_steps_20250805_201935.zip"
    
    try:
        from sb3_contrib import RecurrentPPO
        model = RecurrentPPO.load(checkpoint_path)
        print(f"‚úÖ Modelo carregado: {model.num_timesteps:,} steps")
        print(f"üß† Policy: {type(model.policy).__name__}")
    except Exception as e:
        print(f"‚ùå Erro: {e}")
        return
    
    # 2. An√°lise detalhada do Action Space
    print(f"\nüéØ AN√ÅLISE DETALHADA DO ACTION SPACE")
    print("-" * 40)
    
    action_space = model.action_space
    print(f"üìä Action Space Type: {type(action_space)}")
    print(f"üìä Shape: {action_space.shape}")
    print(f"üìä Dimens√µes: {action_space.shape[0] if hasattr(action_space, 'shape') else 'N/A'}")
    
    if hasattr(action_space, 'low') and hasattr(action_space, 'high'):
        print(f"üìä Low bounds:  {action_space.low}")
        print(f"üìä High bounds: {action_space.high}")
        
        print(f"\nüîç MAPEAMENTO DAS A√á√ïES (baseado nos bounds):")
        for i in range(len(action_space.low)):
            low = action_space.low[i]
            high = action_space.high[i]
            print(f"   Action[{i}]: [{low:4.1f}, {high:4.1f}] - ", end="")
            
            # Inferir significado baseado nos bounds
            if i == 0 and low == 0 and high == 2:
                print("Tipo de ordem (0=HOLD, 1=BUY, 2=SELL)")
            elif i == 1 and low == 0 and high == 1:
                print("Quantidade (0-100%)")
            elif low == -1 and high == 1:
                print("Flag bin√°rio (-1/+1)")
            elif low == 0 and high == 1:
                print("Flag bin√°rio (0/1)")
            elif low == -3 and high == 3:
                print("Ajuste Stop Loss / Take Profit")
            else:
                print(f"Par√¢metro desconhecido")
    
    # 3. An√°lise da Policy Architecture
    print(f"\nüß† AN√ÅLISE DA POLICY ARCHITECTURE")
    print("-" * 40)
    
    policy = model.policy
    print(f"üìã Policy class: {policy.__class__.__name__}")
    
    # Verificar se tem actor/critic heads separados
    if hasattr(policy, 'action_net'):
        print(f"‚úÖ Action network encontrado")
        action_net = policy.action_net
        print(f"   Type: {type(action_net)}")
        
        # Verificar layers da action network
        if hasattr(action_net, 'children'):
            layers = list(action_net.children())
            print(f"   Layers: {len(layers)}")
            for i, layer in enumerate(layers):
                print(f"     Layer {i}: {layer}")
    
    if hasattr(policy, 'value_net'):
        print(f"‚úÖ Value network encontrado")
    
    # 4. Testar predi√ß√µes com an√°lise detalhada
    print(f"\nüß™ TESTE DETALHADO DE PREDI√á√ïES")
    print("-" * 40)
    
    # Criar diferentes tipos de observa√ß√£o
    test_cases = [
        ("Neutro", np.random.randn(2580).astype(np.float32) * 0.01),
        ("Bullish", np.concatenate([np.ones(100) * 2.0, np.random.randn(2480).astype(np.float32) * 0.1])),
        ("Bearish", np.concatenate([-np.ones(100) * 2.0, np.random.randn(2480).astype(np.float32) * 0.1])),
        ("High Vol", np.random.randn(2580).astype(np.float32) * 3.0),
        ("Zeros", np.zeros(2580, dtype=np.float32)),
    ]
    
    resultados_detalhados = []
    
    for nome, obs in test_cases:
        try:
            # Predi√ß√£o com an√°lise de gradientes
            action, _states = model.predict(obs, deterministic=True)
            
            resultado = {
                'nome': nome,
                'action_completa': action.tolist(),
                'action_shapes': action.shape,
                'action_dtypes': action.dtype
            }
            
            print(f"üîç {nome}:")
            print(f"   Action shape: {action.shape}")
            print(f"   Action dtype: {action.dtype}")
            print(f"   Action[0]: {action[0]:.6f}")
            print(f"   Action[1]: {action[1]:.6f}")
            
            if len(action) > 2:
                print(f"   Action[2-5]: {[f'{a:.3f}' for a in action[2:6]]}")
                print(f"   Action[6-10]: {[f'{a:.3f}' for a in action[6:11]]}")
            
            resultados_detalhados.append(resultado)
            
        except Exception as e:
            print(f"‚ùå Erro no teste {nome}: {e}")
    
    # 5. An√°lise estat√≠stica profunda
    print(f"\nüìä AN√ÅLISE ESTAT√çSTICA PROFUNDA")
    print("-" * 40)
    
    if resultados_detalhados:
        # Coletar todas as a√ß√µes
        all_actions = [r['action_completa'] for r in resultados_detalhados]
        all_actions_array = np.array(all_actions)
        
        print(f"üìà ESTAT√çSTICAS POR DIMENS√ÉO:")
        for i in range(all_actions_array.shape[1]):
            values = all_actions_array[:, i]
            print(f"   Action[{i}]: mean={np.mean(values):.6f}, std={np.std(values):.6f}, range=[{np.min(values):.6f}, {np.max(values):.6f}]")
            
            # Verificar se est√° sempre zero
            if np.max(np.abs(values)) < 1e-6:
                print(f"     üî¥ SEMPRE ZERO!")
            elif np.std(values) < 1e-6:
                print(f"     üü° SEMPRE CONSTANTE: {np.mean(values):.6f}")
            else:
                print(f"     ‚úÖ Varia normalmente")
    
    # 6. Investigar internals da policy
    print(f"\nüî¨ INVESTIGA√á√ÉO DOS INTERNALS DA POLICY")
    print("-" * 40)
    
    try:
        # Verificar par√¢metros da action network
        if hasattr(policy, 'action_net'):
            action_net = policy.action_net
            
            print(f"üîç ACTION NETWORK PARAMETERS:")
            total_params = 0
            for name, param in action_net.named_parameters():
                print(f"   {name}: {param.shape}")
                total_params += param.numel()
                
                # Verificar se h√° par√¢metros zerados
                if torch.all(param == 0):
                    print(f"     üî¥ PAR√ÇMETRO ZERADO!")
                elif torch.std(param) < 1e-6:
                    print(f"     üü° PAR√ÇMETRO CONSTANTE")
            
            print(f"   Total params: {total_params:,}")
        
        # Verificar se h√° problemas de inicializa√ß√£o
        print(f"\nüîç VERIFICA√á√ÉO DE INICIALIZA√á√ÉO:")
        obs_test = np.random.randn(2580).astype(np.float32) * 0.1
        
        # Forward pass step by step se poss√≠vel
        if hasattr(policy, 'features_extractor'):
            print(f"   ‚úÖ Features extractor existe")
            
        if hasattr(policy, 'mlp_extractor'):  
            print(f"   ‚úÖ MLP extractor existe")
            
        if hasattr(policy, 'action_dist'):
            print(f"   ‚úÖ Action distribution existe")
            print(f"       Type: {type(policy.action_dist)}")
            
    except Exception as e:
        print(f"‚ùå Erro na investiga√ß√£o interna: {e}")
    
    # 7. Teste com torch direto
    print(f"\nüß™ TESTE COM PYTORCH DIRETO")
    print("-" * 40)
    
    try:
        import torch
        
        # Converter observa√ß√£o para tensor
        obs_tensor = torch.FloatTensor(obs_test).unsqueeze(0)  # Add batch dim
        
        print(f"üìä Obs tensor shape: {obs_tensor.shape}")
        
        # Tentar forward pass manual
        with torch.no_grad():
            if hasattr(policy, 'forward'):
                print(f"üîç Tentando forward pass manual...")
                # result = policy.forward(obs_tensor)  # Pode dar erro
                # print(f"   Forward result: {result}")
            
            # Verificar se action_net pode ser chamado diretamente
            if hasattr(policy, 'action_net') and hasattr(policy.action_net, 'forward'):
                print(f"üîç Testando action_net direto...")
                # Isso pode dar erro dependendo da arquitetura
    
    except Exception as e:
        print(f"‚ùå Erro no teste pytorch: {e}")
    
    # 8. Conclus√£o da investiga√ß√£o
    print(f"\nüèÜ CONCLUS√ÉO DA INVESTIGA√á√ÉO")
    print("=" * 50)
    
    print(f"üéØ ACHADOS PRINCIPAIS:")
    print(f"   üìä Action Space: 11 dimens√µes")
    print(f"   üéÆ Action[0]: Tipo de ordem (funciona)")
    print(f"   üí∞ Action[1]: Quantidade (SEMPRE ZERO)")
    print(f"   üîß Action[2-10]: Par√¢metros SL/TP")
    
    print(f"\nüîç HIP√ìTESES PARA Action[1] = 0:")
    print(f"   1. üß† Policy head mal treinado para Action[1]")
    print(f"   2. üéØ Inicializa√ß√£o ruim dos pesos da a√ß√£o 1")
    print(f"   3. üîí Gates/m√°scaras bloqueando Action[1]")
    print(f"   4. üìä Reward function n√£o incentivou varia√ß√£o de quantidade")
    print(f"   5. üèóÔ∏è Bug na arquitetura TwoHeadV7Intuition")
    
    print(f"\nüí° PR√ìXIMOS PASSOS:")
    print(f"   1. Verificar pesos espec√≠ficos da Action[1] head")
    print(f"   2. Analisar logs de treinamento para Action[1]")
    print(f"   3. Testar modelo mais simples sem V7 complexity")
    print(f"   4. Verificar se reward function usa quantidade")

def main():
    import torch
    investigar_action_bug()

if __name__ == "__main__":
    main()