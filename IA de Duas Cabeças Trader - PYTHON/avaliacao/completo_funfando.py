#!/usr/bin/env python3
"""
ğŸš€ AVALIAÃ‡ÃƒO REALÃSTICA 1MIN - DATASET V4 REALISTA
=================================================

CONFIGURAÃ‡ÃƒO PARA TIMEFRAME 1 MINUTO:
âœ… 1. Dataset V4: InterpolaÃ§Ã£o de dados reais (1.7% estÃ¡ticas)
âœ… 2. Timeframe ajustado: 1 semana = 7200 steps (1440 min/dia Ã— 5 dias)
âœ… 3. Dados sequenciais recentes (nÃ£o aleatÃ³rios)
âœ… 4. ConfiguraÃ§Ã£o idÃªntica ao silus.py
âœ… 5. Stochastic mode (exploration ativa)
âœ… 6. MÃ©tricas realistas de trading
âœ… 7. Multiple seeds para robustez
"""

import sys
import os
import traceback
from datetime import datetime, timedelta
import random
import json
from scipy import stats
import warnings
warnings.filterwarnings('ignore')
sys.path.append("D:/Projeto")

# MUDAR PARA O DIRETÃ“RIO CORRETO PARA ACESSAR data/
os.chdir("D:/Projeto")

import numpy as np
import pandas as pd
import torch

# ğŸ”¥ V3 BRUTAL CHECKPOINTS - ULTRA RELIABLE PEAKS + REQUESTED STEPS
CHECKPOINTS_TO_TEST = [
    # ğŸ¥‡ TOP ULTRA RELIABLE PEAKS (Sharpe > 8.8)
    "D:/Projeto/Otimizacao/treino_principal/models/v3brutal/v3brutal_simpledirecttraining_975000_steps_20250915_131608.zip",    # 975k (~966k peak)
    "D:/Projeto/Otimizacao/treino_principal/models/v3brutal/v3brutal_simpledirecttraining_625000_steps_20250915_125401.zip",    # 625k (~630k peaks)
    "D:/Projeto/Otimizacao/treino_principal/models/v3brutal/v3brutal_simpledirecttraining_650000_steps_20250915_125539.zip",    # 650k (~630k peaks)
    
    # ğŸ“Š REQUESTED EVALUATION STEPS 300K-750K
    "D:/Projeto/Otimizacao/treino_principal/models/v3brutal/v3brutal_simpledirecttraining_300000_steps_20250915_123319.zip",    # 300k
    "D:/Projeto/Otimizacao/treino_principal/models/v3brutal/v3brutal_simpledirecttraining_350000_steps_20250915_123631.zip",    # 350k
    "D:/Projeto/Otimizacao/treino_principal/models/v3brutal/v3brutal_simpledirecttraining_400000_steps_20250915_123938.zip",    # 400k
    "D:/Projeto/Otimizacao/treino_principal/models/v3brutal/v3brutal_simpledirecttraining_450000_steps_20250915_124250.zip",    # 450k
    "D:/Projeto/Otimizacao/treino_principal/models/v3brutal/v3brutal_simpledirecttraining_500000_steps_20250915_124559.zip",    # 500k
    "D:/Projeto/Otimizacao/treino_principal/models/v3brutal/v3brutal_simpledirecttraining_550000_steps_20250915_124918.zip",    # 550k
    "D:/Projeto/Otimizacao/treino_principal/models/v3brutal/v3brutal_simpledirecttraining_600000_steps_20250915_125225.zip",    # 600k
    "D:/Projeto/Otimizacao/treino_principal/models/v3brutal/v3brutal_simpledirecttraining_700000_steps_20250915_125846.zip",    # 700k
    "D:/Projeto/Otimizacao/treino_principal/models/v3brutal/v3brutal_simpledirecttraining_750000_steps_20250915_130200.zip"     # 750k
]

# PARÃ‚METROS REALÃSTICOS
INITIAL_PORTFOLIO = 500.0
BASE_LOT_SIZE = 0.02
MAX_LOT_SIZE = 0.03

# ğŸ”¥ EPISÃ“DIOS OTIMIZADOS PARA VELOCIDADE
TEST_STEPS = 3600          # ğŸš€ OTIMIZAÃ‡ÃƒO: 2.5 dias (3600 steps) vs 1 semana (7200) - 2x mais rÃ¡pido
NUM_EPISODES = 20          # ğŸš€ OTIMIZAÃ‡ÃƒO: 20 episÃ³dios vs 25 - 20% mais rÃ¡pido  
SEEDS = [42]               # ğŸš€ OTIMIZAÃ‡ÃƒO: 1 seed vs 2 - 50% mais rÃ¡pido
DETERMINISTIC = False      # ğŸ”§ REVERTIDO: Modo estocÃ¡stico para avaliaÃ§Ã£o realÃ­stica
CONFIDENCE_THRESHOLD = 0.3 # Baixo como produÃ§Ã£o

# USAR TODO O DATASET EVAL (50K Ã© o tamanho correto para avaliaÃ§Ã£o)
USE_RECENT_DATA = False  # ğŸ”§ FIX: Dataset EVAL jÃ¡ Ã© otimizado, usar completo
RECENT_WEEKS_COUNT = 5   # ğŸ”§ REDUZIDO: Se usar recent, apenas 5 semanas

def setup_realistic_environment():
    """
    Configurar ambiente IDÃŠNTICO Ã  produÃ§Ã£o (usa o mesmo TradingEnv do SILUS)
    """
    # Importar as mesmas funÃ§Ãµes do SILUS
    from silus import load_optimized_data_original, TradingEnv
    
    # ğŸš€ USAR DATASET EVAL OTIMIZADO - 50K LINHAS PREPARADAS PARA AVALIAÃ‡ÃƒO
    dataset_path = 'data/GC=F_EVAL_OPTIMIZED_V4_20250912_164339.csv'
    data = pd.read_csv(dataset_path)
    
    # Converter time para datetime se necessÃ¡rio
    if 'time' in data.columns:
        data['time'] = pd.to_datetime(data['time'])
    
    # ğŸ”¥ FIX CRÃTICO: Dataset jÃ¡ tem features _1m, manter apenas colunas bÃ¡sicas OHLCV
    # O problema Ã© que tem features duplicadas causando shape (50000, 2)
    basic_columns = ['time', 'open_1m', 'high_1m', 'low_1m', 'close_1m', 'tick_volume_1m']
    
    # Se nÃ£o existirem _1m, usar colunas bÃ¡sicas e renomear
    if 'open_1m' not in data.columns:
        column_mapping = {
            'open': 'open_1m',
            'high': 'high_1m', 
            'low': 'low_1m',
            'close': 'close_1m',
            'tick_volume': 'tick_volume_1m'
        }
        
        # Aplicar renomeaÃ§Ã£o apenas para colunas que existem
        columns_to_rename = {old: new for old, new in column_mapping.items() if old in data.columns}
        if columns_to_rename:
            data = data.rename(columns=columns_to_rename)
            print(f"ğŸ“Š Colunas renomeadas para formato 1min: {list(columns_to_rename.keys())}")
    
    # ğŸš€ MANTER APENAS COLUNAS BÃSICAS PARA EVITAR CONFLITOS
    available_basic = [col for col in basic_columns if col in data.columns]
    data = data[available_basic].copy()
    
    print(f"ğŸ“Š Dataset V4 carregado: {len(data)} linhas, {len(data.columns)} colunas bÃ¡sicas (timeframe 1min)")
    
    # ğŸ”¥ AJUSTE PARA 1MIN: 1 semana = 7200 steps (1440 min/dia Ã— 5 dias)
    if USE_RECENT_DATA and len(data) > RECENT_WEEKS_COUNT * 7200:
        # Pegar Ãºltimas semanas (7200 steps por semana - timeframe 1min)
        recent_data_size = RECENT_WEEKS_COUNT * 7200
        data = data.iloc[-recent_data_size:].reset_index(drop=True)
        print(f"ğŸ“… Usando dados recentes: {len(data)} steps ({RECENT_WEEKS_COUNT} semanas - 1min timeframe)")
    
    # ğŸ”¥ VERIFICAÃ‡ÃƒO FINAL DO DATASET
    print(f"ğŸ” VerificaÃ§Ã£o dataset antes do TradingEnv:")
    print(f"   Shape: {data.shape}")
    print(f"   Colunas: {list(data.columns)}")
    for col in data.columns:
        if col != 'time':
            col_shape = data[col].shape if hasattr(data[col], 'shape') else 'No shape'
            print(f"   {col}: {col_shape}, tipo: {type(data[col].iloc[0] if len(data) > 0 else 'empty')}")
    
    # ğŸ”¥ AMBIENTE PARA TESTE PURO - SEM COOLDOWNS/TIMEOUTS
    env = TradingEnv(
        df=data,
        window_size=20,  # Mesmo do SILUS
        is_training=False,  # ğŸ”§ TESTE PURO: Modo eval (sem enhancements)
        initial_balance=INITIAL_PORTFOLIO,
        trading_params={
            'min_lot_size': BASE_LOT_SIZE,
            'max_lot_size': MAX_LOT_SIZE,
            'enable_shorts': True,
            'max_positions': 2
        }
    )
    
    # ğŸš¨ CRÃTICO: Configurar activity_system para timeframe 1min
    if hasattr(env, 'activity_system') and env.activity_system is not None:
        # âœ… OPÃ‡ÃƒO 1: Ajustar timeout de 60 candles (1h) para 300 candles (5h em 1min)
        if hasattr(env.activity_system.config, 'position_timeout_candles'):
            env.activity_system.config.position_timeout_candles = 300  # 5h em candles 1min
            print("ğŸ”§ Position timeout ajustado: 60 â†’ 300 candles (5h em 1min)")
        
        # âœ… OPÃ‡ÃƒO 2: Para teste PURO, desabilitar completamente
        # env.activity_system = None
        # print("ğŸ”§ Activity system desabilitado para teste puro")
    
    # ğŸš¨ CRÃTICO: Zerar cooldowns para teste puro 
    if hasattr(env, 'cooldown_after_trade'):
        env.cooldown_after_trade = 0
        print("ğŸ”§ Cooldowns zerrados para teste puro")
    
    if hasattr(env, 'cooldown_base'):
        env.cooldown_base = 0
        print("ğŸ”§ Cooldown base zerrado para teste puro")
    
    return env

# ğŸš€ CACHE GLOBAL DE MODELOS PARA EVITAR RECARREGAMENTO
_model_cache = {}

def evaluate_model_realistic(model_path, num_episodes=NUM_EPISODES):
    """
    AvaliaÃ§Ã£o realÃ­stica de um modelo COM CACHE OTIMIZADO
    """
    model_name = os.path.basename(model_path)
    print(f"\\nâš¡ TESTE REALÃSTICO: {model_name}")
    print("", end='', flush=True)  # Iniciar linha de progresso
    
    # ğŸš€ OTIMIZAÃ‡ÃƒO: Usar cache de modelos
    from sb3_contrib import RecurrentPPO
    try:
        if model_path not in _model_cache:
            print(f" [LOADING]", end='', flush=True)
            model = RecurrentPPO.load(model_path)
            
            # ğŸ”§ CONFIGURAÃ‡Ã•ES IDÃŠNTICAS AO CHERRY
            model.policy.set_training_mode(False)  # Modo eval
            for param in model.policy.parameters():
                param.requires_grad = False        # Desabilitar gradientes
            
            _model_cache[model_path] = model
            print(f" [CACHED]", end='', flush=True)
        else:
            model = _model_cache[model_path]
            print(f" [FROM CACHE]", end='', flush=True)
            
        print(f" âœ…")
    except Exception as e:
        print(f"âŒ Erro ao carregar modelo: {e}")
        return None
    
    results = {
        'episodes': [],
        'trades_per_episode': [],
        'active_episodes': 0,
        'total_trades': 0,
        'seeds_results': {}
    }
    
    # ğŸš€ OTIMIZAÃ‡ÃƒO: Criar environment UMA VEZ e reutilizar
    print(f"ğŸ”§ Criando ambiente...")
    env = setup_realistic_environment()
    
    # Testar com mÃºltiplas seeds
    for seed_idx, seed in enumerate(SEEDS):
        print(f"\\nğŸ² Testando com seed {seed} ({seed_idx+1}/{len(SEEDS)}) [REUSING ENV]")
        
        np.random.seed(seed)
        torch.manual_seed(seed)
        
        seed_results = []
        
        for episode in range(num_episodes // len(SEEDS)):
            try:
                # Reset environment
                obs = env.reset()
                episode_return = 0.0
                episode_trades = 0
                episode_steps = 0
                lstm_states = None  # ğŸ”§ ADICIONADO: LSTM states como Cherry
                
                # Run episode with torch optimization + EARLY TERMINATION
                with torch.no_grad():  # ğŸš€ OTIMIZAÃ‡ÃƒO: Disable gradients para inference
                    consecutive_holds = 0
                    max_consecutive_holds = 100  # ğŸš€ OTIMIZAÃ‡ÃƒO: Early termination se ficar muito tempo em HOLD
                    
                    for step in range(TEST_STEPS):
                        # Predict action (IGUAL AO CHERRY)
                        action, lstm_states = model.predict(
                            obs, 
                            state=lstm_states,    # ğŸ”§ ADICIONADO: state parameter
                            deterministic=DETERMINISTIC
                        )
                        
                        # ğŸš€ OTIMIZAÃ‡ÃƒO: Tracking de aÃ§Ãµes para early termination
                        if hasattr(action, '__len__') and len(action) > 0:
                            if abs(action[0]) < 0.33:  # HOLD action
                                consecutive_holds += 1
                            else:
                                consecutive_holds = 0
                        
                        # Step environment
                        obs, reward, done, info = env.step(action)
                        episode_return += reward
                        episode_steps += 1
                        
                        # ğŸš€ OTIMIZAÃ‡ÃƒO: Early termination conditions
                        if done:
                            break
                        if consecutive_holds > max_consecutive_holds and episode_steps > TEST_STEPS // 4:
                            # Se ficou muito tempo em HOLD apÃ³s 25% do episÃ³dio, terminar cedo
                            print("E", end='', flush=True)  # Early termination indicator
                            break
                
                # ğŸ”¥ COLETAR MÃ‰TRICAS REAIS DO TRADING (IGUAL AO CHERRY)
                portfolio_pnl = env.portfolio_value - INITIAL_PORTFOLIO
                trades_list = getattr(env, 'trades', [])
                
                # ğŸ”¥ AJUSTE: Calcular win/loss baseado na estrutura de trades do sistema
                # Verificar estrutura dos trades para compatibilidade
                winning_trades = 0
                losing_trades = 0
                total_trades_real = len(trades_list)
                
                for trade in trades_list:
                    # Tentar diferentes campos de PnL baseado na estrutura do trade
                    pnl = trade.get('pnl_usd', trade.get('pnl', trade.get('profit', 0)))
                    if pnl > 0:
                        winning_trades += 1
                    elif pnl < 0:
                        losing_trades += 1
                
                seed_results.append({
                    'return': episode_return,
                    'trades': total_trades_real,  # ğŸ”§ USANDO TRADES REAIS
                    'steps': episode_steps,
                    'active': total_trades_real > 0,
                    # MÃ©tricas adicionais
                    'portfolio_pnl': portfolio_pnl,
                    'winning_trades': winning_trades,
                    'losing_trades': losing_trades
                })
                
                if total_trades_real > 0:
                    results['active_episodes'] += 1
                
                results['total_trades'] += total_trades_real
                results['trades_per_episode'].append(total_trades_real)
                
                # Progress indicator (igual ao Cherry)
                print(".", end='', flush=True)
                
            except Exception as e:
                print(f"âŒ Erro no episÃ³dio {episode}: {e}")
                continue
        
        print(f" âœ“")  # Finalizar linha de progresso
        
        results['seeds_results'][seed] = seed_results
        results['episodes'].extend(seed_results)
    
    # ğŸš€ LIMPEZA DE MEMÃ“RIA entre modelos (igual ao Cherry)
    import gc
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    
    # ğŸ”¥ CALCULAR MÃ‰TRICAS COMPLETAS DE TRADING (IGUAL AO CHERRY)
    if len(results['episodes']) > 0:
        returns = [ep['return'] for ep in results['episodes']]
        trades = [ep['trades'] for ep in results['episodes']]
        
        # ğŸš¨ MÃ‰TRICAS REAIS DE TRADING
        portfolio_pnls = [ep.get('portfolio_pnl', 0) for ep in results['episodes']]
        portfolio_values = [ep.get('portfolio_value', INITIAL_PORTFOLIO) for ep in results['episodes']]
        
        # Agregar todos os trades de todos os episÃ³dios
        total_winning_trades = sum(ep.get('winning_trades', 0) for ep in results['episodes'])
        total_losing_trades = sum(ep.get('losing_trades', 0) for ep in results['episodes'])
        total_real_trades = total_winning_trades + total_losing_trades
        
        # Calcular win rate REAL baseado em trades individuais
        real_win_rate = (total_winning_trades / total_real_trades * 100) if total_real_trades > 0 else 0
        
        metrics = {
            # MÃ©tricas de reward (para compatibilidade)
            'mean_return': np.mean(returns),
            'std_return': np.std(returns),
            'sharpe_ratio': np.mean(portfolio_pnls) / (np.std(portfolio_pnls) + 1e-8),  # ğŸ”§ Sharpe baseado em PnL real
            
            # MÃ©tricas bÃ¡sicas
            'total_episodes': len(results['episodes']),
            'active_episodes': sum(1 for ep in results['episodes'] if ep['active']),
            'activity_rate': sum(1 for ep in results['episodes'] if ep['active']) / len(results['episodes']) * 100,
            
            # ğŸš¨ MÃ‰TRICAS REAIS DE TRADING
            'mean_portfolio_pnl': np.mean(portfolio_pnls),
            'std_portfolio_pnl': np.std(portfolio_pnls),
            'median_portfolio_pnl': np.median(portfolio_pnls),
            'mean_portfolio_value': np.mean(portfolio_values),
            'total_real_pnl': sum(portfolio_pnls),
            
            # MÃ©tricas de trades
            'total_trades': sum(trades),
            'avg_trades_per_episode': np.mean(trades),
            'avg_trades_per_day': np.mean(trades) / 5,  # ğŸ”¥ AJUSTE: 5 dias Ãºteis por semana (nÃ£o 7)
            'total_trades_real': total_real_trades,
            'winning_trades': total_winning_trades,
            'losing_trades': total_losing_trades,
            
            # ğŸ¯ WIN RATE CORRETO - baseado em trades individuais
            'win_rate': real_win_rate,
            
            # Episodes com lucro (PnL > 0)
            'profitable_episodes': sum(1 for pnl in portfolio_pnls if pnl > 0),
            'losing_episodes_pnl': sum(1 for pnl in portfolio_pnls if pnl < 0),
            'episode_profit_rate': sum(1 for pnl in portfolio_pnls if pnl > 0) / len(portfolio_pnls) * 100 if portfolio_pnls else 0,
            
            'seeds_consistency': {
                seed: {
                    'mean_return': np.mean([ep['return'] for ep in seed_data]),
                    'mean_trades': np.mean([ep['trades'] for ep in seed_data])
                }
                for seed, seed_data in results['seeds_results'].items()
            }
        }
    else:
        metrics = {'error': 'No valid episodes'}
    
    return {
        'model_path': model_path,
        'metrics': metrics,
        'raw_results': results
    }

def run_realistic_comparison():
    """
    Executar comparaÃ§Ã£o realÃ­stica entre modelos
    """
    from datetime import datetime
    
    print("ğŸš€ AVALIAÃ‡ÃƒO REALÃSTICA SILUS - COMPARAÃ‡ÃƒO COMPLETA")
    print("=" * 60)
    
    print(f"ğŸ“Š Testando {len(CHECKPOINTS_TO_TEST)} modelos SILUS")
    print(f"âš¡ {NUM_EPISODES} episÃ³dios por modelo") 
    print(f"ğŸ² {len(SEEDS)} seeds")
    print(f"ğŸ“ˆ Total: {len(CHECKPOINTS_TO_TEST) * NUM_EPISODES} episÃ³dios")
    print(f"ğŸ• Steps por episÃ³dio: {TEST_STEPS}")
    print("-" * 60)
    
    results = {}
    start_time = datetime.now()
    
    for idx, model_path in enumerate(CHECKPOINTS_TO_TEST):
        model_start = datetime.now()
        
        if os.path.exists(model_path):
            result = evaluate_model_realistic(model_path)
            if result:
                model_name = os.path.basename(model_path)
                results[model_name] = result
                
                # ğŸ”¥ ANÃLISE INDIVIDUAL POR MODELO (IGUAL AO CHERRY)
                model_time = (datetime.now() - model_start).total_seconds()
                metrics = result['metrics']
                
                print(f"  â±ï¸ Tempo: {model_time:.1f}s")
                print(f"  ğŸ“Š Sharpe: {metrics.get('sharpe_ratio', 0):.4f}")
                print(f"  ğŸ’° PnL: ${metrics.get('total_real_pnl', 0):.2f}")
                print(f"  ğŸ¯ Win Rate: {metrics.get('win_rate', 0):.1f}% ({metrics.get('winning_trades', 0)}/{metrics.get('total_trades_real', 0)})")
                print(f"  ğŸ“ˆ Trades/ep: {metrics.get('avg_trades_per_episode', 0):.1f}")
                print(f"  ğŸ¯ Activity: {metrics.get('activity_rate', 0):.1f}%")
        else:
            print(f"âš ï¸ Modelo nÃ£o encontrado: {model_path}")
    
    total_time = (datetime.now() - start_time).total_seconds()
    
    # ğŸ”¥ RELATÃ“RIO COMPARATIVO FINAL (IGUAL AO CHERRY)
    print("\\n" + "=" * 60)
    print("ğŸ“Š RESULTADOS COMPARATIVOS FINAIS - SILUS:")
    print("-" * 60)
    
    # Encontrar melhor modelo
    best_sharpe = -999
    best_pnl = -99999
    best_model_sharpe = None
    best_model_pnl = None
    
    for model_name, result in results.items():
        metrics = result['metrics']
        if 'error' not in metrics:
            # Extrair nÃºmero de steps do nome
            try:
                steps = model_name.split('_')[2]  # SILUS_simpledirecttraining_500000_steps...
            except:
                steps = model_name
            
            print(f"\\nğŸ·ï¸ {steps} STEPS:")
            print(f"  ğŸ“Š Sharpe: {metrics.get('sharpe_ratio', 0):.4f}")
            print(f"  ğŸ’° Total PnL: ${metrics.get('total_real_pnl', 0):.2f}")
            print(f"  ğŸ“ˆ Win Rate: {metrics.get('win_rate', 0):.1f}% ({metrics.get('winning_trades', 0)}/{metrics.get('total_trades_real', 0)})")
            print(f"  ğŸ¯ Activity: {metrics.get('activity_rate', 0):.1f}%")
            print(f"  ğŸ“ˆ Trades/ep: {metrics.get('avg_trades_per_episode', 0):.1f}")
            print(f"  ğŸ“ˆ Episodes lucrativos: {metrics.get('profitable_episodes', 0)}/{metrics.get('total_episodes', 0)}")
            
            # Tracking dos melhores
            if metrics.get('sharpe_ratio', -999) > best_sharpe:
                best_sharpe = metrics.get('sharpe_ratio', -999)
                best_model_sharpe = steps
            
            if metrics.get('total_real_pnl', -99999) > best_pnl:
                best_pnl = metrics.get('total_real_pnl', -99999)
                best_model_pnl = steps
    
    print("\\n" + "=" * 60)
    print("ğŸ† RANKING FINAL:")
    print(f"   ğŸ¥‡ MELHOR SHARPE: {best_model_sharpe} STEPS (Sharpe: {best_sharpe:.4f})")
    print(f"   ğŸ’° MELHOR PnL: {best_model_pnl} STEPS (PnL: ${best_pnl:.2f})")
    print(f"â±ï¸ TEMPO TOTAL: {total_time:.1f} segundos ({total_time/60:.1f} minutos)")
    print(f"âš¡ VELOCIDADE: {total_time/len(results):.1f}s por modelo")
    print("=" * 60)
    
    for model_name, result in results.items():
        metrics = result['metrics']
        if 'error' not in metrics:
            steps = model_name.split('_')[2]  # Extrair steps
            print(f"\\nğŸ·ï¸ {steps} STEPS:")
            print(f"  ğŸ“ˆ Return mÃ©dio: {metrics['mean_return']:.4f}")
            print(f"  ğŸ“Š Sharpe: {metrics['sharpe_ratio']:.4f}")
            print(f"  ğŸ¯ Taxa atividade: {metrics['activity_rate']:.1f}%")
            print(f"  ğŸ“ˆ Trades/episÃ³dio: {metrics['avg_trades_per_episode']:.1f}")
            print(f"  ğŸ“… Trades/dia: {metrics['avg_trades_per_day']:.1f}")
            print(f"  ğŸ² ConsistÃªncia seeds: {len(metrics['seeds_consistency'])} seeds")
    
    # Salvar resultados
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"avaliacao_realistica_{timestamp}.json"
    
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False, default=str)
    
    print(f"\\nğŸ’¾ Resultados salvos: {filename}")
    
    return results

if __name__ == "__main__":
    try:
        results = run_realistic_comparison()
        
        print("\\nâœ… AVALIAÃ‡ÃƒO REALÃSTICA CONCLUÃDA!")
        print("\\nğŸ¯ PRÃ“XIMOS PASSOS:")
        print("1. Compare com dados de produÃ§Ã£o real")
        print("2. Valide taxa de atividade vs robÃ´ real") 
        print("3. Confirme nÃºmero de trades/dia")
        
    except Exception as e:
        print(f"âŒ ERRO: {e}")
        traceback.print_exc()