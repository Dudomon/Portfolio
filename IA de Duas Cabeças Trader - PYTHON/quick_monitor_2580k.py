#!/usr/bin/env python3
"""
üîç MONITOR R√ÅPIDO - Checkpoint 2.58M Steps
An√°lise espec√≠fica do checkpoint 2580000 para verificar satura√ß√£o
"""

import sys
import os
sys.path.append("D:/Projeto")

import numpy as np
import torch
from sb3_contrib import RecurrentPPO

# Checkpoint espec√≠fico
CHECKPOINT_PATH = "D:/Projeto/Otimizacao/treino_principal/models/DAYTRADER/FINAL_phase1fundamentalsextended_2580000_steps_20250813_221317.zip"

def analyze_checkpoint_2580k():
    """An√°lise r√°pida do checkpoint 2.58M"""
    
    print("üîç MONITOR SATURA√á√ÉO - Checkpoint 2.58M")
    print("=" * 60)
    
    try:
        # Carregar modelo
        print(f"üìÇ Carregando: {os.path.basename(CHECKPOINT_PATH)}")
        model = RecurrentPPO.load(CHECKPOINT_PATH, device='cuda')
        model.policy.set_training_mode(False)
        
        # Estat√≠sticas b√°sicas do modelo
        total_params = sum(p.numel() for p in model.policy.parameters())
        trainable_params = sum(p.numel() for p in model.policy.parameters() if p.requires_grad)
        
        print(f"üìä Total params: {total_params:,}")
        print(f"üìä Trainable params: {trainable_params:,}")
        
        # An√°lise de satura√ß√£o
        print("\nüéØ AN√ÅLISE DE SATURA√á√ÉO:")
        
        # Test predictions
        lstm_states = None
        activations = []
        actions_taken = []
        
        for i in range(100):  # 100 samples r√°pidos
            obs = np.random.normal(0, 1.0, (2580,)).astype(np.float32)
            action, lstm_states = model.predict(obs, state=lstm_states, deterministic=False)
            actions_taken.append(action)
            
            if i % 20 == 0:
                print(f"   Sample {i}: action[0]={action[0]:.4f}")
        
        actions_array = np.array(actions_taken)
        
        # An√°lise das a√ß√µes
        print(f"\nüìà ESTAT√çSTICAS A√á√ïES (100 samples):")
        print(f"   Entry decisions (action[0]):")
        print(f"     Mean: {actions_array[:, 0].mean():.4f}")
        print(f"     Std: {actions_array[:, 0].std():.4f}")
        print(f"     Min: {actions_array[:, 0].min():.4f}")
        print(f"     Max: {actions_array[:, 0].max():.4f}")
        
        # Verificar range das a√ß√µes
        entry_range = actions_array[:, 0].max() - actions_array[:, 0].min()
        print(f"     Range: {entry_range:.4f}")
        
        if entry_range < 0.1:
            print("   ‚ö†Ô∏è BAIXA VARIABILIDADE - Poss√≠vel satura√ß√£o")
        elif entry_range < 0.5:
            print("   üìä VARIABILIDADE MODERADA")
        else:
            print("   ‚úÖ BOA VARIABILIDADE")
        
        # Verificar concentra√ß√£o em extremos
        extreme_low = (actions_array[:, 0] < 0.1).sum()
        extreme_high = (actions_array[:, 0] > 0.9).sum()
        
        print(f"   Concentra√ß√£o extremos:")
        print(f"     < 0.1: {extreme_low}% ({extreme_low}/100)")
        print(f"     > 0.9: {extreme_high}% ({extreme_high}/100)")
        
        if extreme_low > 80 or extreme_high > 80:
            print("   üî• ALTA CONCENTRA√á√ÉO EM EXTREMOS - Satura√ß√£o detectada")
        elif extreme_low + extreme_high > 60:
            print("   ‚ö†Ô∏è CONCENTRA√á√ÉO MODERADA EM EXTREMOS")
        else:
            print("   ‚úÖ DISTRIBUI√á√ÉO SAUD√ÅVEL")
        
        # An√°lise de layers espec√≠ficos do V7
        print(f"\nüß† AN√ÅLISE LAYERS V7:")
        
        # Tentar acessar layers espec√≠ficos
        try:
            policy = model.policy
            print(f"   Policy type: {type(policy).__name__}")
            
            # Verificar se tem mlp_extractor
            if hasattr(policy, 'mlp_extractor'):
                extractor = policy.mlp_extractor
                print(f"   Extractor type: {type(extractor).__name__}")
                
                # Verificar layers
                if hasattr(extractor, 'shared_net'):
                    print(f"   Shared net layers: {len(extractor.shared_net)}")
                
            # Verificar action_net
            if hasattr(policy, 'action_net'):
                print(f"   Action net: {type(policy.action_net).__name__}")
        
        except Exception as e:
            print(f"   ‚ö†Ô∏è Erro acessando layers: {e}")
        
        print(f"\n‚úÖ AN√ÅLISE CONCLU√çDA - Checkpoint 2.58M")
        return True
        
    except Exception as e:
        print(f"‚ùå ERRO: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = analyze_checkpoint_2580k()
    print(f"\nStatus: {'‚úÖ Sucesso' if success else '‚ùå Falha'}")