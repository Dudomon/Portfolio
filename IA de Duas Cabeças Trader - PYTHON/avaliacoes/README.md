# üî• Sistema de Monitoramento em Tempo Real

Sistema completo de logging JSON e monitoramento tempo real para substituir CSVs pesados e permitir an√°lise instant√¢nea de converg√™ncia e gradientes.

## üìÅ Estrutura

```
avaliacoes/
‚îú‚îÄ‚îÄ real_time_logger.py      # Logger JSON streaming principal
‚îú‚îÄ‚îÄ real_time_monitor.py     # Dashboard interativo tempo real  
‚îú‚îÄ‚îÄ logger_integration.py    # Integra√ß√£o com sistema existente
‚îú‚îÄ‚îÄ README.md               # Esta documenta√ß√£o
‚îî‚îÄ‚îÄ [dados gerados]/
    ‚îú‚îÄ‚îÄ training_YYYYMMDD_HHMMSS.jsonl     # Dados de treinamento
    ‚îú‚îÄ‚îÄ gradients_YYYYMMDD_HHMMSS.jsonl    # Informa√ß√µes de gradiente
    ‚îú‚îÄ‚îÄ convergence_YYYYMMDD_HHMMSS.jsonl  # M√©tricas de converg√™ncia
    ‚îú‚îÄ‚îÄ rewards_YYYYMMDD_HHMMSS.jsonl      # Dados de reward/epis√≥dio
    ‚îú‚îÄ‚îÄ performance_YYYYMMDD_HHMMSS.jsonl  # M√©tricas de performance
    ‚îî‚îÄ‚îÄ dashboard_YYYYMMDD_HHMMSS.html     # Dashboard interativo
```

## üöÄ Quick Start

### 1. Usar o Logger Diretamente

```python
from avaliacoes.real_time_logger import create_real_time_logger

# Criar logger
with create_real_time_logger() as logger:
    # Log dados de treinamento
    logger.log_training_step(step=100, loss=0.5, learning_rate=2e-4)
    
    # Log gradientes
    logger.log_gradient_info(step=100, grad_norm=1.2, grad_zeros_ratio=0.1)
    
    # Log epis√≥dios
    logger.log_reward_info(step=100, episode_reward=150.0, episode_length=50)
```

### 2. Monitoramento em Tempo Real

```python
from avaliacoes.real_time_monitor import create_monitor

# Criar monitor
monitor = create_monitor(refresh_interval=1.0)

# Iniciar monitoramento (busca automaticamente √∫ltima sess√£o)
monitor.start_monitoring()

# Monitor roda em background, criando dashboard interativo
```

### 3. Integra√ß√£o com Sistema Existente

```python
from avaliacoes.logger_integration import create_integrated_logger

# Criar integra√ß√£o transparente
integration = create_integrated_logger()
session_id = integration.start_session("meu_treino")

# Usar normalmente - substitui CSV automaticamente
integration.log_training_step(loss=0.5, lr=2e-4)
integration.log_gradient_info(model=meu_modelo)  # Extrai gradientes automaticamente
```

## üìä Vantagens sobre CSV

### ‚ùå Problemas do CSV
- **Travamento**: Arquivo grande trava leitura tempo real
- **Parsing**: Precisa ler arquivo inteiro para dados recentes  
- **Mem√≥ria**: CSV gigante consome muita RAM
- **Concorr√™ncia**: Conflitos entre escrita/leitura simult√¢nea
- **Formato**: Estrutura r√≠gida, dif√≠cil extensibilidade

### ‚úÖ Benef√≠cios do JSON Streaming (JSONL)
- **Stream Real-Time**: Leitura linha por linha sem travamento
- **Buffer Inteligente**: Flush autom√°tico otimizado para performance
- **Concorr√™ncia**: Escrita/leitura simult√¢nea sem conflitos
- **Flexibilidade**: Estrutura JSON permite dados complexos
- **An√°lise Autom√°tica**: Alertas e detec√ß√£o de problemas em tempo real
- **Dashboard**: Visualiza√ß√£o interativa instant√¢nea

## üìà Features do Sistema

### üî• RealTimeLogger
- **JSON Lines (JSONL)**: Formato otimizado para streaming
- **Buffer Circular**: Mem√≥ria eficiente com flush autom√°tico
- **Multi-Categoria**: Diferentes tipos de dados organizados
- **Thread Safety**: Opera√ß√£o segura em ambiente multi-thread
- **Auto-Flush**: Persist√™ncia autom√°tica configur√°vel
- **Alertas**: Detec√ß√£o autom√°tica de problemas (gradient explosion, etc.)

### üìä RealTimeMonitor  
- **Dashboard Plotly**: Gr√°ficos interativos profissionais
- **Matplotlib Fallback**: Suporte sem depend√™ncias externas
- **An√°lise Cont√≠nua**: Detec√ß√£o autom√°tica de padr√µes problem√°ticos
- **Alertas Visuais**: Notifica√ß√µes em tempo real de issues
- **M√∫ltiplas M√©tricas**: Loss, gradientes, rewards, performance
- **Export**: Relat√≥rios de an√°lise autom√°ticos

### üîó LoggerIntegration
- **Patch Transparente**: Integra√ß√£o sem modificar c√≥digo existente
- **SB3 Callback**: Suporte nativo para Stable-Baselines3
- **CSV Fallback**: Compatibilidade com sistemas legados
- **Extra√ß√£o Autom√°tica**: Coleta autom√°tica de gradientes do modelo
- **Bridge**: Converte sistemas antigos para novo formato

## üéØ Casos de Uso

### 1. Monitoramento de Treinamento RL
```python
# Durante treinamento PPO/SAC/etc
integration.log_training_step(
    step=step,
    loss=loss_value,
    policy_loss=policy_loss,
    value_loss=value_loss,
    entropy_loss=entropy_loss,
    learning_rate=lr,
    clipfrac=clipfrac,
    explained_variance=explained_var
)
```

### 2. An√°lise de Gradientes
```python
# Autom√°tico via modelo
integration.log_gradient_info(model=policy_network)

# Manual para componentes espec√≠ficos  
integration.log_gradient_info(
    component="actor_head",
    grad_norm=norm_value,
    grad_zeros_ratio=zeros_ratio,
    weight_update_ratio=update_ratio
)
```

### 3. Tracking de Performance
```python
# M√©tricas de epis√≥dio
integration.log_episode_end(
    episode_reward=total_reward,
    episode_length=steps,
    win_rate=win_percentage,
    drawdown=max_drawdown,
    trades_count=num_trades
)
```

### 4. Alertas Autom√°ticos
O sistema detecta automaticamente:
- **Gradient Explosion**: `grad_norm > 10.0`
- **Vanishing Gradients**: `grad_norm < 1e-8`  
- **Muitos Zeros**: `zeros_ratio > 50%`
- **Loss Divergence**: Tend√™ncia crescente por 50+ steps
- **Stagnation**: Loss sem mudan√ßa significativa
- **Poor Performance**: Rewards consistentemente baixos

## üîß Configura√ß√£o Avan√ßada

### Logger Personalizado
```python
logger = RealTimeLogger(
    base_path="meus_logs",
    buffer_size=2000,          # Buffer maior para alta frequ√™ncia
    flush_interval=0.5         # Flush mais frequente
)
```

### Monitor Personalizado
```python
monitor = RealTimeMonitor(
    log_path="meus_logs", 
    refresh_interval=1.0,      # Atualiza√ß√£o a cada 1s
    history_window=2000        # Manter 2000 pontos na mem√≥ria
)

# Configurar alertas
monitor.plot_config.update({
    'gradient_threshold_high': 8.0,    # Threshold menor
    'convergence_window': 100,         # Janela maior  
    'alert_retention_minutes': 60      # Manter alertas por 1h
})
```

### Integra√ß√£o SB3
```python
from stable_baselines3 import PPO

# Criar callback
integration = create_integrated_logger()
callback = integration.create_sb3_callback()

# Usar no treinamento
model = PPO("MlpPolicy", env)
model.learn(total_timesteps=100000, callback=callback)
```

## üì± Dashboard Interativo

O dashboard gerado automaticamente inclui:

### üìä Painel 1: Loss & Learning Rate
- Evolu√ß√£o da loss ao longo do tempo
- Learning rate scheduling
- Trends e m√©dias m√≥veis

### üî• Painel 2: Gradient Health  
- Norma dos gradientes
- Percentual de zeros
- Alertas visuais para problemas

### üí∞ Painel 3: Reward Trends
- Rewards por epis√≥dio  
- M√©dias m√≥veis
- Performance ao longo do tempo

### ‚öôÔ∏è Painel 4: Training Metrics
- Entropy loss, value loss, policy loss
- Explained variance
- Outras m√©tricas customizadas

## üö® Sistema de Alertas

### N√≠veis de Alerta
- üî¥ **ERROR**: Problemas cr√≠ticos (gradient explosion, divergence)
- üü° **WARNING**: Problemas moderados (muitos zeros, performance baixa)  
- üîµ **INFO**: Informa√ß√µes relevantes (stagnation, padr√µes)

### Persist√™ncia  
- Alertas ficam vis√≠veis por 30 minutos (configur√°vel)
- Hist√≥rico completo salvo nos logs JSON
- Relat√≥rios de an√°lise incluem sum√°rio de alertas

## üéõÔ∏è API Reference

### RealTimeLogger
```python
logger = RealTimeLogger(base_path, buffer_size, flush_interval)
logger.log_training_step(step, **metrics)
logger.log_gradient_info(step, **gradient_data)  
logger.log_convergence_metrics(step, **convergence_data)
logger.log_reward_info(step, **reward_data)
logger.log_performance_metrics(step, **performance_data)
logger.get_real_time_stats()
logger.close()
```

### RealTimeMonitor
```python  
monitor = RealTimeMonitor(log_path, refresh_interval, history_window)
monitor.start_monitoring(session_id)
monitor.stop_monitoring()
monitor.get_current_status()
monitor.export_analysis_report()
```

### LoggerIntegration
```python
integration = TrainingLoggerIntegration(base_path, enable_csv_fallback, gradient_monitoring)
session_id = integration.start_session(prefix)
integration.log_training_step(**kwargs)
integration.log_gradient_info(model, **manual_data)
integration.log_episode_end(**episode_data)  
integration.create_sb3_callback()
integration.patch_existing_logger(logger_instance, method_name)
integration.end_session()
```

## üîÑ Migra√ß√£o do Sistema Atual

### Passo 1: Teste Paralelo
```python
# Manter CSV atual + adicionar JSON
integration = create_integrated_logger(enable_csv_fallback=True)
```

### Passo 2: Valida√ß√£o
```python
# Comparar dados CSV vs JSON
reader = LogReader()
json_data = reader.read_stream('training')
# Verificar consist√™ncia
```

### Passo 3: Substitui√ß√£o Gradual
```python  
# Desabilitar CSV quando confiante
integration = create_integrated_logger(enable_csv_fallback=False)
```

### Passo 4: Cleanup
```python
# Remover CSVs antigos
import shutil
shutil.rmtree("logs_csv_antigos")
```

## üìù Exemplo Completo

```python
#!/usr/bin/env python3
from avaliacoes.logger_integration import create_integrated_logger
from avaliacoes.real_time_monitor import create_monitor
import time
import numpy as np

def exemplo_treinamento():
    # 1. Criar integra√ß√£o
    integration = create_integrated_logger()
    session_id = integration.start_session("exemplo_ppo")
    
    # 2. Iniciar monitor em thread separada
    monitor = create_monitor()
    monitor.start_monitoring(session_id)
    
    try:
        # 3. Simular treinamento
        for step in range(1000):
            # Log dados de treinamento
            integration.log_training_step(
                loss=np.random.uniform(0.5, 2.0),
                policy_loss=np.random.uniform(0.1, 0.8),
                value_loss=np.random.uniform(0.1, 0.5),
                entropy_loss=np.random.uniform(0.01, 0.1),
                learning_rate=2.5e-4 * (0.999 ** (step // 100)),
                clipfrac=np.random.uniform(0.1, 0.3)
            )
            
            # Log gradientes
            integration.log_gradient_info(
                grad_norm=np.random.lognormal(0, 0.5),
                grad_zeros_ratio=np.random.beta(1, 5)
            )
            
            # Log epis√≥dios
            if step % 20 == 0:
                integration.log_episode_end(
                    episode_reward=np.random.normal(100, 50),
                    episode_length=np.random.randint(50, 200),
                    win_rate=np.random.beta(3, 2)
                )
            
            time.sleep(0.01)  # Simular tempo de processamento
            
            # Status peri√≥dico
            if step % 100 == 0:
                stats = integration.get_current_stats()
                print(f"Step {step}: {stats}")
    
    finally:
        # 4. Cleanup
        monitor.stop_monitoring()
        report_file = monitor.export_analysis_report()
        integration.end_session()
        
        print(f"Treinamento conclu√≠do!")
        print(f"Relat√≥rio: {report_file}")
        print(f"Dashboard: avaliacoes/dashboard_{session_id}.html")

if __name__ == "__main__":
    exemplo_treinamento()
```

## üéâ Conclus√£o

Este sistema resolve completamente o problema de monitoramento em tempo real, substituindo CSVs pesados por JSON streaming eficiente. Permite:

- ‚úÖ **Zero Lag**: Monitoramento instant√¢neo sem travamentos
- ‚úÖ **Auto-An√°lise**: Detec√ß√£o autom√°tica de problemas  
- ‚úÖ **Dashboard**: Visualiza√ß√£o profissional em tempo real
- ‚úÖ **Integra√ß√£o**: Compat√≠vel com c√≥digo existente
- ‚úÖ **Alertas**: Notifica√ß√µes autom√°ticas de issues cr√≠ticos
- ‚úÖ **Performance**: Sistema otimizado para alta frequ√™ncia
- ‚úÖ **Flexibilidade**: Extens√≠vel para novos tipos de dados

**üöÄ Agora voc√™ pode monitorar converg√™ncia e gradientes em tempo real!**