#!/usr/bin/env python3
"""
üî¨ DEBUG V7 DIRETO - Acesso direto aos raw_actions
Investigar por que Action[1] sempre retorna zero
"""

import sys
import os
import numpy as np
import torch
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

projeto_path = Path("D:/Projeto")
sys.path.insert(0, str(projeto_path))

def debug_v7_direct():
    print("üî¨ DEBUG V7 DIRETO - Investiga√ß√£o Action[1]")
    print("=" * 50)
    
    # Carregar modelo
    checkpoint_path = projeto_path / "trading_framework/training/checkpoints/DAYTRADER/checkpoint_phase2riskmanagement_650000_steps_20250805_201935.zip"
    
    try:
        from sb3_contrib import RecurrentPPO
        model = RecurrentPPO.load(checkpoint_path)
        print(f"‚úÖ Modelo carregado: {model.num_timesteps:,} steps")
    except Exception as e:
        print(f"‚ùå Erro: {e}")
        return
    
    policy = model.policy
    print(f"üß† Policy: {type(policy).__name__}")
    
    # 1. ACESSAR DIRETAMENTE O ACTOR_HEAD
    print(f"\nüîç AN√ÅLISE DIRETA DO ACTOR_HEAD")
    print("-" * 50)
    
    if hasattr(policy, 'actor_head'):
        actor_head = policy.actor_head
        print(f"‚úÖ Actor head encontrado: {type(actor_head)}")
        
        # Verificar layers
        layers = list(actor_head.children())
        print(f"   Layers: {len(layers)}")
        for i, layer in enumerate(layers):
            print(f"     Layer {i}: {layer}")
        
        # Pegos da √∫ltima layer (Linear)
        final_layer = layers[-1] if layers else None
        if final_layer and hasattr(final_layer, 'weight'):
            weight = final_layer.weight  # [11, input_dim]
            bias = final_layer.bias      # [11]
            
            print(f"\nüí∞ AN√ÅLISE DOS PESOS DA ACTION[1]:")
            action1_weight = weight[1, :]  # Pesos da Action[1]
            action1_bias = bias[1]         # Bias da Action[1]
            
            print(f"   Weight shape: {action1_weight.shape}")
            print(f"   Weight mean: {action1_weight.mean():.8f}")
            print(f"   Weight std:  {action1_weight.std():.8f}")
            print(f"   Weight min:  {action1_weight.min():.8f}")
            print(f"   Weight max:  {action1_weight.max():.8f}")
            print(f"   Bias:        {action1_bias:.8f}")
            
            # Verificar se h√° problema √≥bvio
            if action1_bias < -5.0:
                print(f"   üî¥ BIAS MUITO NEGATIVO: {action1_bias:.3f} for√ßa sigmoid ‚Üí 0")
            elif torch.all(action1_weight == 0):
                print(f"   üî¥ PESOS ZERADOS: Todos os pesos s√£o zero")
            elif action1_weight.std() < 1e-7:
                print(f"   üü° PESOS CONSTANTES: Std muito baixo")
            else:
                print(f"   ‚úÖ Pesos parecem normais")
    
    # 2. TESTE DIRETO COM INPUTS SINT√âTICOS
    print(f"\nüß™ TESTE DIRETO COM O ACTOR_HEAD")
    print("-" * 50)
    
    try:
        # Descobrir input size do actor_head
        actor_input_size = None
        if hasattr(policy, 'actor_head'):
            first_layer = list(policy.actor_head.children())[0]
            if hasattr(first_layer, 'in_features'):
                actor_input_size = first_layer.in_features
                print(f"üìä Actor head input size: {actor_input_size}")
        
        if actor_input_size:
            # Testar com diferentes inputs
            test_inputs = [
                torch.zeros(1, actor_input_size),           # Zero
                torch.ones(1, actor_input_size) * 0.5,     # Positivo pequeno
                torch.ones(1, actor_input_size) * 2.0,     # Positivo grande
                -torch.ones(1, actor_input_size) * 2.0,    # Negativo
                torch.randn(1, actor_input_size) * 0.1,    # Random pequeno
                torch.randn(1, actor_input_size) * 2.0     # Random grande
            ]
            
            test_names = ["Zeros", "Pos_Small", "Pos_Big", "Negative", "Rand_Small", "Rand_Big"]
            
            print(f"\nüîç TESTANDO RAW OUTPUTS:")
            raw_action1_values = []
            
            for i, (name, input_tensor) in enumerate(zip(test_names, test_inputs)):
                with torch.no_grad():
                    raw_output = policy.actor_head(input_tensor)
                    raw_action1 = float(raw_output[0, 1])
                    sigmoid_result = float(torch.sigmoid(raw_output[0, 1]))
                    
                    raw_action1_values.append(raw_action1)
                    
                    print(f"   {name:10s}: raw[1]={raw_action1:+8.4f} ‚Üí sigmoid={sigmoid_result:.6f}")
            
            # An√°lise dos resultados
            raw_array = np.array(raw_action1_values)
            
            print(f"\nüìä AN√ÅLISE DOS RAW VALUES:")
            print(f"   Mean: {raw_array.mean():+.6f}")
            print(f"   Std:  {raw_array.std():.6f}")
            print(f"   Min:  {raw_array.min():+.6f}")
            print(f"   Max:  {raw_array.max():+.6f}")
            
            # Diagn√≥stico
            if raw_array.max() < -5.0:
                print(f"   üî¥ TODOS MUITO NEGATIVOS: sigmoid sempre ~0")
            elif raw_array.max() < -2.0:
                print(f"   üü° TEND√äNCIA NEGATIVA: sigmoid < 0.12")
            elif raw_array.std() < 0.1:
                print(f"   üü° BAIXA VARIA√á√ÉO: Range limitado")
            else:
                print(f"   ‚úÖ Valores normais")
    
    except Exception as e:
        print(f"‚ùå Erro no teste direto: {e}")
    
    # 3. COMPARAR COM PREDI√á√ÉO REAL DO MODELO
    print(f"\nüéØ COMPARA√á√ÉO COM PREDI√á√ÉO REAL")
    print("-" * 50)
    
    # Teste com observa√ß√£o real
    obs = np.random.randn(2580).astype(np.float32)
    
    try:
        # Predi√ß√£o normal
        action, _states = model.predict(obs, deterministic=True)
        print(f"üìä Predi√ß√£o do modelo:")
        print(f"   Action[0]: {action[0]:.6f}")
        print(f"   Action[1]: {action[1]:.6f}")
        print(f"   Action[2]: {action[2]:.6f}")
        
        # M√∫ltiplas predi√ß√µes para verificar consist√™ncia
        action1_values = []
        for i in range(10):
            obs_var = np.random.randn(2580).astype(np.float32) * (i + 1)
            action_var, _ = model.predict(obs_var, deterministic=True)
            action1_values.append(action_var[1])
        
        action1_array = np.array(action1_values)
        print(f"\nüìä M√∫ltiplas predi√ß√µes Action[1]:")
        print(f"   Values: {[f'{v:.6f}' for v in action1_values]}")
        print(f"   Mean: {action1_array.mean():.6f}")
        print(f"   Std:  {action1_array.std():.6f}")
        
        if action1_array.std() < 1e-6:
            print(f"   üî¥ CONFIRMADO: Action[1] sempre constante")
        else:
            print(f"   ‚úÖ Action[1] varia normalmente")
    
    except Exception as e:
        print(f"‚ùå Erro na predi√ß√£o: {e}")
    
    # 4. INVESTIGAR A PIPELINE COMPLETA
    print(f"\nüîç INVESTIGA√á√ÉO DA PIPELINE COMPLETA")
    print("-" * 50)
    
    try:
        # Verificar se podemos acessar componentes internos
        if hasattr(policy, 'forward_actor'):
            print(f"‚úÖ forward_actor dispon√≠vel")
        
        if hasattr(policy, 'features_extractor'):
            print(f"‚úÖ features_extractor dispon√≠vel")
        
        if hasattr(policy, 'mlp_extractor'):
            print(f"‚úÖ mlp_extractor dispon√≠vel")
        
        if hasattr(policy, 'action_dist'):
            print(f"‚úÖ action_dist dispon√≠vel: {type(policy.action_dist)}")
        
        # Verificar se h√° log_std espec√≠fico
        if hasattr(policy, 'log_std'):
            log_std = policy.log_std
            print(f"üìä Log std: {log_std}")
            if len(log_std) > 1:
                print(f"   Action[1] log_std: {log_std[1]:.6f}")
                print(f"   Action[1] std: {torch.exp(log_std[1]):.6f}")
    
    except Exception as e:
        print(f"‚ùå Erro na investiga√ß√£o da pipeline: {e}")
    
    # 5. CONCLUS√ÉO DO DEBUG
    print(f"\nüèÜ CONCLUS√ÉO DO DEBUG DIRETO")
    print("=" * 50)
    
    print(f"üéØ DESCOBERTAS:")
    print(f"   1. Policy √© TwoHeadV7Intuition")
    print(f"   2. Actor head tem estrutura normal")
    
    if 'raw_array' in locals():
        if raw_array.max() < -3:
            print(f"   3. üî¥ RAW VALUES muito negativos: {raw_array.mean():.3f}")
            print(f"      üí° CAUSA: Bias negativo ou weights inadequados")
            print(f"      üéØ EFEITO: sigmoid({raw_array.mean():.3f}) = {1/(1+np.exp(-raw_array.mean())):.6f}")
        else:
            print(f"   3. ‚úÖ Raw values normais: {raw_array.mean():.3f}")
    
    if 'action1_array' in locals():
        if action1_array.std() < 1e-6:
            print(f"   4. üî¥ CONFIRMADO: Action[1] sempre {action1_array.mean():.6f}")
        else:
            print(f"   4. ‚úÖ Action[1] varia: std={action1_array.std():.6f}")
    
    print(f"\nüí° PR√ìXIMO PASSO:")
    if 'raw_array' in locals() and raw_array.max() < -3:
        print(f"   üîß AJUSTAR BIAS: Adicionar +3 ao bias da Action[1]")
        print(f"   üîÑ OU RE-TREINAR: Com inicializa√ß√£o melhor")
    else:
        print(f"   üîç INVESTIGAR: Outros componentes da pipeline")

if __name__ == "__main__":
    debug_v7_direct()