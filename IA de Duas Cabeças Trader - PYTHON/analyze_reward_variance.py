#!/usr/bin/env python3
"""
Script para anÃ¡lise de variÃ¢ncia de rewards nos dados de avaliaÃ§Ã£o
"""
import json
import numpy as np
import pandas as pd
from pathlib import Path
import matplotlib.pyplot as plt
from collections import defaultdict
import statistics

def analyze_reward_variance():
    """Analisa variÃ¢ncia de rewards nos arquivos JSONL"""
    
    # Arquivos para anÃ¡lise
    files_to_analyze = [
        "D:/Projeto/avaliacoes/rewards_20250804_094339.jsonl",
        "D:/Projeto/avaliacoes/training_20250804_094339.jsonl"
    ]
    
    reward_data = []
    training_data = []
    
    print("ğŸ” ANÃLISE DE VARIÃ‚NCIA DE REWARDS")
    print("=" * 60)
    
    # AnÃ¡lise de dados de rewards
    try:
        with open(files_to_analyze[0], 'r') as f:
            for line_num, line in enumerate(f):
                if line_num == 0:  # Skip header
                    continue
                if line_num > 10000:  # Limit for performance
                    break
                    
                try:
                    data = json.loads(line.strip())
                    if data.get('type') == 'reward_info':
                        reward_data.append({
                            'step': data.get('step', 0),
                            'total_reward': data.get('total_reward', 0),
                            'portfolio_value': data.get('portfolio_value', 0),
                            'current_drawdown': data.get('current_drawdown', 0),
                            'win_rate': data.get('win_rate', 0),
                            'total_pnl': data.get('total_pnl', 0),
                            'trades_count': data.get('trades_count', 0),
                            'gaming_penalty': data.get('reward_components', {}).get('gaming_penalty', 0)
                        })
                except json.JSONDecodeError:
                    continue
                    
    except FileNotFoundError:
        print("âŒ Arquivo de rewards nÃ£o encontrado")
        return
        
    # AnÃ¡lise de dados de training
    try:
        with open(files_to_analyze[1], 'r') as f:
            for line_num, line in enumerate(f):
                if line_num == 0:  # Skip header
                    continue
                if line_num > 10000:  # Limit for performance
                    break
                    
                try:
                    data = json.loads(line.strip())
                    if data.get('type') == 'training_step':
                        training_data.append({
                            'step': data.get('step', 0),
                            'loss': data.get('loss', 0),
                            'value_loss': data.get('value_loss', 0),
                            'entropy_loss': data.get('entropy_loss', 0),
                            'clip_fraction': data.get('clip_fraction', 0),
                            'explained_variance': data.get('explained_variance', 0)
                        })
                except json.JSONDecodeError:
                    continue
                    
    except FileNotFoundError:
        print("âŒ Arquivo de training nÃ£o encontrado")
        
    if not reward_data:
        print("âŒ Nenhum dado de reward encontrado")
        return
        
    # Converter para DataFrames
    df_rewards = pd.DataFrame(reward_data)
    df_training = pd.DataFrame(training_data) if training_data else pd.DataFrame()
    
    print(f"ğŸ“Š Dados coletados:")
    print(f"   - Rewards: {len(df_rewards)} registros")
    print(f"   - Training: {len(df_training)} registros")
    print()
    
    # ANÃLISE 1: VariÃ¢ncia dos rewards ao longo do tempo
    print("1ï¸âƒ£ VARIÃ‚NCIA DOS REWARDS AO LONGO DO TEMPO")
    print("-" * 50)
    
    rewards = df_rewards['total_reward'].values
    rewards_non_zero = rewards[rewards != 0]
    
    print(f"Total de registros: {len(rewards)}")
    print(f"Registros nÃ£o-zero: {len(rewards_non_zero)}")
    print(f"Registros zero: {len(rewards) - len(rewards_non_zero)} ({((len(rewards) - len(rewards_non_zero))/len(rewards)*100):.1f}%)")
    print()
    
    if len(rewards_non_zero) > 0:
        print(f"EstatÃ­sticas dos rewards nÃ£o-zero:")
        print(f"   MÃ©dia: {np.mean(rewards_non_zero):.4f}")
        print(f"   Desvio PadrÃ£o: {np.std(rewards_non_zero):.4f}")
        print(f"   VariÃ¢ncia: {np.var(rewards_non_zero):.4f}")
        print(f"   MÃ­nimo: {np.min(rewards_non_zero):.4f}")
        print(f"   MÃ¡ximo: {np.max(rewards_non_zero):.4f}")
        print(f"   Mediana: {np.median(rewards_non_zero):.4f}")
        
        # AnÃ¡lise de instabilidade
        print(f"\nğŸ“ˆ ANÃLISE DE INSTABILIDADE:")
        reward_changes = np.diff(rewards_non_zero)
        if len(reward_changes) > 0:
            print(f"   VariaÃ§Ã£o mÃ©dia entre steps: {np.mean(np.abs(reward_changes)):.4f}")
            print(f"   VariaÃ§Ã£o mÃ¡xima: {np.max(np.abs(reward_changes)):.4f}")
            print(f"   Coeficiente de variaÃ§Ã£o: {(np.std(rewards_non_zero)/np.mean(rewards_non_zero)):.4f}")
    else:
        print("âŒ Todos os rewards sÃ£o zero - possÃ­vel problema no sistema")
    print()
    
    # ANÃLISE 2: CorrelaÃ§Ã£o com explained_variance
    print("2ï¸âƒ£ CORRELAÃ‡ÃƒO REWARD VARIANCE vs EXPLAINED VARIANCE")
    print("-" * 50)
    
    if not df_training.empty and 'explained_variance' in df_training.columns:
        # Alinhar dados por step
        merged = pd.merge(df_rewards, df_training, on='step', how='inner')
        
        if len(merged) > 0:
            reward_var = merged['total_reward'].values
            explained_var = merged['explained_variance'].values
            
            # Remove valores zero/NaN
            valid_mask = (reward_var != 0) & (~np.isnan(explained_var)) & (explained_var != 0)
            
            if np.sum(valid_mask) > 10:
                reward_var_clean = reward_var[valid_mask]
                explained_var_clean = explained_var[valid_mask]
                
                correlation = np.corrcoef(reward_var_clean, explained_var_clean)[0, 1]
                print(f"CorrelaÃ§Ã£o Reward Variance vs Explained Variance: {correlation:.4f}")
                
                print(f"Explained Variance Stats:")
                print(f"   MÃ©dia: {np.mean(explained_var_clean):.4f}")
                print(f"   Desvio PadrÃ£o: {np.std(explained_var_clean):.4f}")
                print(f"   MÃ­nimo: {np.min(explained_var_clean):.4f}")
                print(f"   MÃ¡ximo: {np.max(explained_var_clean):.4f}")
            else:
                print("âŒ Dados insuficientes para correlaÃ§Ã£o")
        else:
            print("âŒ NÃ£o foi possÃ­vel alinhar dados de reward e training")
    else:
        print("âŒ Dados de training nÃ£o disponÃ­veis ou incompletos")
    print()
    
    # ANÃLISE 3: PadrÃµes de instabilidade
    print("3ï¸âƒ£ PADRÃ•ES DE INSTABILIDADE NOS REWARDS")
    print("-" * 50)
    
    # AnÃ¡lise de gaming penalties
    gaming_penalties = df_rewards['gaming_penalty'].values
    gaming_penalties_non_zero = gaming_penalties[gaming_penalties != 0]
    
    print(f"Gaming Penalties:")
    print(f"   Total de penalidades: {len(gaming_penalties_non_zero)}")
    print(f"   Percentual de steps com penalidade: {(len(gaming_penalties_non_zero)/len(gaming_penalties)*100):.1f}%")
    
    if len(gaming_penalties_non_zero) > 0:
        print(f"   Penalidade mÃ©dia: {np.mean(gaming_penalties_non_zero):.4f}")
        print(f"   Penalidade mÃ¡xima: {np.min(gaming_penalties_non_zero):.4f}")  # min porque sÃ£o valores negativos
    
    # AnÃ¡lise de drawdown
    drawdowns = df_rewards['current_drawdown'].values
    drawdowns_non_zero = drawdowns[drawdowns > 0]
    
    print(f"\nDrawdown Analysis:")
    if len(drawdowns_non_zero) > 0:
        print(f"   Drawdown mÃ©dio: {np.mean(drawdowns_non_zero):.2f}%")
        print(f"   Drawdown mÃ¡ximo: {np.max(drawdowns_non_zero):.2f}%")
        print(f"   Steps em drawdown: {len(drawdowns_non_zero)} ({(len(drawdowns_non_zero)/len(drawdowns)*100):.1f}%)")
    print()
    
    # ANÃLISE 4: Clipping frequency
    print("4ï¸âƒ£ FREQUÃŠNCIA DE CLIPPING")
    print("-" * 50)
    
    if not df_training.empty and 'clip_fraction' in df_training.columns:
        clip_fractions = df_training['clip_fraction'].values
        clip_fractions_non_zero = clip_fractions[clip_fractions > 0]
        
        print(f"Clip Fraction Stats:")
        print(f"   Registros com clipping: {len(clip_fractions_non_zero)} de {len(clip_fractions)}")
        print(f"   Percentual com clipping: {(len(clip_fractions_non_zero)/len(clip_fractions)*100):.1f}%")
        
        if len(clip_fractions_non_zero) > 0:
            print(f"   Clip fraction mÃ©dia: {np.mean(clip_fractions_non_zero):.4f}")
            print(f"   Clip fraction mÃ¡xima: {np.max(clip_fractions_non_zero):.4f}")
            
            # AnÃ¡lise de clipping excessivo
            high_clip = clip_fractions_non_zero[clip_fractions_non_zero > 0.3]
            if len(high_clip) > 0:
                print(f"   âš ï¸ Steps com clipping alto (>30%): {len(high_clip)} ({(len(high_clip)/len(clip_fractions)*100):.1f}%)")
            
            very_high_clip = clip_fractions_non_zero[clip_fractions_non_zero > 0.5]
            if len(very_high_clip) > 0:
                print(f"   ğŸš¨ Steps com clipping muito alto (>50%): {len(very_high_clip)} ({(len(very_high_clip)/len(clip_fractions)*100):.1f}%)")
    else:
        print("âŒ Dados de clip_fraction nÃ£o disponÃ­veis")
    print()
    
    # SUMÃRIO FINAL
    print("ğŸ“‹ SUMÃRIO DA ANÃLISE")
    print("=" * 60)
    
    issues_found = []
    
    if len(rewards_non_zero) == 0:
        issues_found.append("ğŸš¨ CRÃTICO - Todos os rewards sÃ£o zero")
    elif len(rewards_non_zero) / len(rewards) < 0.1:
        issues_found.append("âš ï¸ ALTA - Mais de 90% dos rewards sÃ£o zero")
    
    if len(rewards_non_zero) > 0:
        cv = np.std(rewards_non_zero) / np.abs(np.mean(rewards_non_zero))
        if cv > 2.0:
            issues_found.append(f"âš ï¸ ALTA - Coeficiente de variaÃ§Ã£o muito alto ({cv:.2f})")
    
    if len(gaming_penalties_non_zero) / len(gaming_penalties) > 0.3:
        issues_found.append("âš ï¸ MÃ‰DIA - Muitas penalidades por gaming (>30%)")
    
    if not df_training.empty and len(clip_fractions_non_zero) > 0:
        high_clip_pct = len(clip_fractions_non_zero[clip_fractions_non_zero > 0.5]) / len(clip_fractions) * 100
        if high_clip_pct > 10:
            issues_found.append(f"âš ï¸ MÃ‰DIA - Clipping excessivo em {high_clip_pct:.1f}% dos steps")
    
    if issues_found:
        print("PROBLEMAS IDENTIFICADOS:")
        for issue in issues_found:
            print(f"   {issue}")
    else:
        print("âœ… Nenhum problema crÃ­tico identificado nos dados analisados")
    
    print(f"\nğŸ“Š AnÃ¡lise concluÃ­da - {len(df_rewards)} registros de rewards processados")

if __name__ == "__main__":
    analyze_reward_variance()