#!/usr/bin/env python3
"""
üéØ AVALIA√á√ÉO V7 CHECKPOINT 4M - Performance + Monitor de Satura√ß√£o
Teste completo do checkpoint de 4M steps do daytrader
"""

import sys
import os
sys.path.append("D:/Projeto")

import numpy as np
import torch
import pandas as pd
import time
from datetime import datetime
import json
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

print("üéØ AVALIA√á√ÉO V7 CHECKPOINT 4M - SISTEMA COMPLETO")
print("=" * 80)

def create_saturation_monitor():
    """Criar monitor de satura√ß√£o para an√°lise de gradientes"""
    class SaturationMonitor:
        def __init__(self):
            self.saturation_data = []
            self.gradient_data = []
            self.activation_data = []
            
        def analyze_model_saturation(self, model):
            """Analisar satura√ß√£o do modelo"""
            saturation_report = {
                'timestamp': datetime.now().isoformat(),
                'total_params': 0,
                'zero_params': 0,
                'saturated_params': 0,
                'components': {}
            }
            
            for name, param in model.policy.named_parameters():
                if param.numel() == 0:
                    continue
                    
                param_data = param.detach().cpu().numpy()
                total_elements = param.numel()
                
                # An√°lise de zeros
                zero_mask = np.abs(param_data) < 1e-8
                zero_count = np.sum(zero_mask)
                
                # An√°lise de satura√ß√£o (valores muito pr√≥ximos dos extremos)
                if 'tanh' in name.lower() or 'sigmoid' in name.lower():
                    # Para ativa√ß√µes Tanh/Sigmoid
                    saturated_mask = (np.abs(param_data) > 0.95)
                else:
                    # Para weights normais
                    saturated_mask = (np.abs(param_data) > 3.0)
                
                saturated_count = np.sum(saturated_mask)
                
                component_report = {
                    'total_elements': total_elements,
                    'zero_count': zero_count,
                    'zero_ratio': zero_count / total_elements,
                    'saturated_count': saturated_count,
                    'saturated_ratio': saturated_count / total_elements,
                    'mean': float(np.mean(param_data)),
                    'std': float(np.std(param_data)),
                    'min': float(np.min(param_data)),
                    'max': float(np.max(param_data))
                }
                
                saturation_report['components'][name] = component_report
                saturation_report['total_params'] += total_elements
                saturation_report['zero_params'] += zero_count
                saturation_report['saturated_params'] += saturated_count
            
            # Calcular ratios globais
            if saturation_report['total_params'] > 0:
                saturation_report['global_zero_ratio'] = saturation_report['zero_params'] / saturation_report['total_params']
                saturation_report['global_saturated_ratio'] = saturation_report['saturated_params'] / saturation_report['total_params']
            
            self.saturation_data.append(saturation_report)
            return saturation_report
            
        def analyze_gradients(self, model):
            """Analisar gradientes durante treinamento"""
            gradient_report = {
                'timestamp': datetime.now().isoformat(),
                'components': {}
            }
            
            for name, param in model.policy.named_parameters():
                if param.grad is not None and param.numel() > 0:
                    grad_data = param.grad.detach().cpu().numpy()
                    
                    gradient_report['components'][name] = {
                        'mean': float(np.mean(grad_data)),
                        'std': float(np.std(grad_data)),
                        'max': float(np.max(np.abs(grad_data))),
                        'zero_ratio': float(np.sum(np.abs(grad_data) < 1e-8) / grad_data.size)
                    }
            
            self.gradient_data.append(gradient_report)
            return gradient_report
            
        def generate_report(self):
            """Gerar relat√≥rio completo"""
            if not self.saturation_data:
                return "Nenhum dado de satura√ß√£o coletado"
            
            latest = self.saturation_data[-1]
            
            report = f"""
üéØ RELAT√ìRIO DE SATURA√á√ÉO - {latest['timestamp']}
{'='*60}

üìä ESTAT√çSTICAS GLOBAIS:
   Total de Par√¢metros: {latest['total_params']:,}
   Par√¢metros Zerados: {latest['zero_params']:,} ({latest.get('global_zero_ratio', 0)*100:.2f}%)
   Par√¢metros Saturados: {latest['saturated_params']:,} ({latest.get('global_saturated_ratio', 0)*100:.2f}%)

üîç COMPONENTES CR√çTICOS:
"""
            
            # An√°lise por componente
            critical_components = []
            for name, data in latest['components'].items():
                if data['zero_ratio'] > 0.1 or data['saturated_ratio'] > 0.1:
                    critical_components.append((name, data))
            
            if critical_components:
                for name, data in critical_components[:10]:  # Top 10
                    report += f"""
   {name}:
      Zeros: {data['zero_ratio']*100:.1f}% | Saturados: {data['saturated_ratio']*100:.1f}%
      Range: [{data['min']:.3f}, {data['max']:.3f}] | Std: {data['std']:.3f}
"""
            else:
                report += "   ‚úÖ Nenhum componente cr√≠tico detectado\n"
            
            return report
    
    return SaturationMonitor()

def load_checkpoint_and_evaluate():
    """Carregar checkpoint e executar avalia√ß√£o completa"""
    
    try:
        # 1. Carregar checkpoint
        print("1. üìÇ CARREGANDO CHECKPOINT 4M:")
        checkpoint_path = "./Otimizacao/treino_principal/models/DAYTRADER/DAYTRADER_phase2riskmanagement_4000000_steps_20250814_093028.zip"
        
        if not os.path.exists(checkpoint_path):
            checkpoint_path = "./trading_framework/training/checkpoints/DAYTRADER/checkpoint_4000000_steps_20250814_093028.zip"
        
        if not os.path.exists(checkpoint_path):
            print(f"   ‚ùå Checkpoint n√£o encontrado: {checkpoint_path}")
            return
        
        print(f"   ‚úÖ Checkpoint encontrado: {checkpoint_path}")
        
        # Import necess√°rio
        from sb3_contrib import RecurrentPPO
        from trading_framework.policies.two_head_v7_simple import TwoHeadV7Simple
        
        # Carregar modelo
        print("   üì¶ Carregando modelo...")
        model = RecurrentPPO.load(checkpoint_path)
        print(f"   ‚úÖ Modelo carregado: {type(model).__name__}")
        print(f"   ‚úÖ Pol√≠tica: {type(model.policy).__name__}")
        print(f"   ‚úÖ Device: {model.device}")
        print(f"   ‚úÖ Steps treinados: {getattr(model, 'num_timesteps', 'unknown')}")
        
        # 2. Criar monitor de satura√ß√£o
        print("\n2. üîç CRIANDO MONITOR DE SATURA√á√ÉO:")
        saturation_monitor = create_saturation_monitor()
        print("   ‚úÖ Monitor de satura√ß√£o criado")
        
        # 3. An√°lise inicial de satura√ß√£o
        print("\n3. üìä AN√ÅLISE INICIAL DE SATURA√á√ÉO:")
        saturation_report = saturation_monitor.analyze_model_saturation(model)
        print(f"   Total par√¢metros: {saturation_report['total_params']:,}")
        print(f"   Par√¢metros zerados: {saturation_report['zero_params']:,} ({saturation_report.get('global_zero_ratio', 0)*100:.2f}%)")
        print(f"   Par√¢metros saturados: {saturation_report['saturated_params']:,} ({saturation_report.get('global_saturated_ratio', 0)*100:.2f}%)")
        
        # 4. An√°lise detalhada por componente
        print("\n4. üîç AN√ÅLISE DETALHADA POR COMPONENTE:")
        
        # Features Extractor
        fe_components = {k: v for k, v in saturation_report['components'].items() if 'features_extractor' in k}
        if fe_components:
            print("   üìä FEATURES EXTRACTOR:")
            for name, data in list(fe_components.items())[:5]:
                print(f"      {name.split('.')[-2:]}: zeros={data['zero_ratio']*100:.1f}%, sat={data['saturated_ratio']*100:.1f}%")
        
        # Actor components
        actor_components = {k: v for k, v in saturation_report['components'].items() if 'actor' in k.lower()}
        if actor_components:
            print("   üé≠ ACTOR:")
            for name, data in list(actor_components.items())[:5]:
                print(f"      {name.split('.')[-1]}: zeros={data['zero_ratio']*100:.1f}%, sat={data['saturated_ratio']*100:.1f}%")
        
        # Critic components
        critic_components = {k: v for k, v in saturation_report['components'].items() if 'critic' in k.lower()}
        if critic_components:
            print("   üéØ CRITIC:")
            for name, data in list(critic_components.items())[:5]:
                print(f"      {name.split('.')[-1]}: zeros={data['zero_ratio']*100:.1f}%, sat={data['saturated_ratio']*100:.1f}%")
        
        # 5. Teste de performance (sem environment - apenas an√°lise do modelo)
        print("\n5. ‚ö° TESTE DE PERFORMANCE DO MODELO:")
        
        # Criar dados de teste sint√©ticos (simulando observa√ß√µes de trading)
        batch_size = 32
        features_dim = 256  # Baseado na configura√ß√£o V7
        
        # Simular observa√ß√µes
        dummy_obs = torch.randn(batch_size, features_dim, device=model.device)
        
        # Simular LSTM states
        lstm_states = (
            torch.zeros(1, batch_size, 256, device=model.device),  # h
            torch.zeros(1, batch_size, 256, device=model.device)   # c
        )
        episode_starts = torch.zeros(batch_size, dtype=torch.bool, device=model.device)
        
        # Teste de throughput
        print("   üöÄ Teste de throughput:")
        num_iterations = 100
        
        model.policy.eval()
        with torch.no_grad():
            start_time = time.time()
            
            for i in range(num_iterations):
                try:
                    # Forward pass completo
                    actions, values, log_probs, new_lstm_states = model.policy.forward(
                        dummy_obs, lstm_states, episode_starts
                    )
                    lstm_states = new_lstm_states
                except Exception as e:
                    print(f"      ‚ö†Ô∏è Erro no forward pass {i}: {e}")
                    break
            
            end_time = time.time()
            
            if i > 0:
                total_time = end_time - start_time
                throughput = (i * batch_size) / total_time
                print(f"      ‚úÖ Throughput: {throughput:.1f} inferences/sec")
                print(f"      ‚úÖ Lat√™ncia m√©dia: {(total_time/i)*1000:.1f}ms per batch")
            
        # 6. An√°lise de outputs
        print("\n6. üìà AN√ÅLISE DE OUTPUTS:")
        if 'actions' in locals():
            print(f"   Actions shape: {actions.shape}")
            print(f"   Actions range: [{actions.min():.3f}, {actions.max():.3f}]")
            print(f"   Actions mean: {actions.mean():.3f} ¬± {actions.std():.3f}")
            
        if 'values' in locals():
            print(f"   Values shape: {values.shape}")
            print(f"   Values range: [{values.min():.3f}, {values.max():.3f}]")
            print(f"   Values mean: {values.mean():.3f} ¬± {values.std():.3f}")
        
        # 7. Relat√≥rio final
        print("\n7. üìã RELAT√ìRIO FINAL:")
        final_report = saturation_monitor.generate_report()
        print(final_report)
        
        # 8. Salvar relat√≥rio
        print("\n8. üíæ SALVANDO RELAT√ìRIO:")
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = f"avaliacoes/avaliacao_v7_4m_{timestamp}.txt"
        
        os.makedirs("avaliacoes", exist_ok=True)
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(f"AVALIA√á√ÉO V7 CHECKPOINT 4M - {timestamp}\n")
            f.write("="*60 + "\n\n")
            f.write(f"Checkpoint: {checkpoint_path}\n")
            f.write(f"Modelo: {type(model).__name__}\n")
            f.write(f"Pol√≠tica: {type(model.policy).__name__}\n")
            f.write(f"Device: {model.device}\n")
            f.write(f"Steps: {getattr(model, 'num_timesteps', 'unknown')}\n\n")
            f.write(final_report)
            
            if 'throughput' in locals():
                f.write(f"\n\nPERFORMANCE:\n")
                f.write(f"Throughput: {throughput:.1f} inferences/sec\n")
                f.write(f"Lat√™ncia: {(total_time/i)*1000:.1f}ms per batch\n")
        
        print(f"   ‚úÖ Relat√≥rio salvo: {report_file}")
        
        return {
            'saturation_report': saturation_report,
            'throughput': locals().get('throughput', 0),
            'model_info': {
                'type': type(model).__name__,
                'policy': type(model.policy).__name__,
                'device': str(model.device),
                'steps': getattr(model, 'num_timesteps', 'unknown')
            }
        }
        
    except Exception as e:
        print(f"‚ùå ERRO na avalia√ß√£o: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    start_time = time.time()
    
    result = load_checkpoint_and_evaluate()
    
    end_time = time.time()
    
    print(f"\nüéØ AVALIA√á√ÉO CONCLU√çDA em {end_time - start_time:.1f}s")
    
    if result:
        print("‚úÖ Resultado dispon√≠vel para an√°lise")
        
        # Summary
        saturation = result['saturation_report']
        print(f"\nüìä RESUMO:")
        print(f"   Par√¢metros totais: {saturation['total_params']:,}")
        print(f"   Zero ratio: {saturation.get('global_zero_ratio', 0)*100:.2f}%")
        print(f"   Saturated ratio: {saturation.get('global_saturated_ratio', 0)*100:.2f}%")
        if 'throughput' in result:
            print(f"   Performance: {result['throughput']:.1f} inferences/sec")
    else:
        print("‚ùå Avalia√ß√£o falhou")