"""
ğŸ§ª TESTE COMPLETO: TwoHeadV8Elegance Architecture

Testa todos os componentes da V8Elegance:
- LSTM Ãºnica compartilhada
- Entry Head especÃ­fico (entry + confidence)  
- Management Head especÃ­fico (SL/TP por posiÃ§Ã£o)
- Memory Bank elegante
- Market Context Ãºnico
- 8D action space completo
"""

import torch
import torch.nn as nn
import numpy as np
import sys
import traceback
from gym import spaces

# Add project path
sys.path.append(r'D:\Projeto')

def test_v8_elegance_complete():
    """ğŸ§ª Teste completo da arquitetura V8Elegance"""
    
    print("ğŸš€ INICIANDO TESTE COMPLETO: TwoHeadV8Elegance")
    print("="*60)
    
    try:
        # Import V8Elegance
        from trading_framework.policies.two_head_v8_elegance import (
            TwoHeadV8Elegance, DaytradeEntryHead, DaytradeManagementHead,
            MarketContextEncoder, ElegantMemoryBank, get_v8_elegance_kwargs,
            validate_v8_elegance_policy
        )
        print("âœ… Imports V8Elegance successful")
        
    except Exception as e:
        print(f"âŒ Erro nos imports: {e}")
        traceback.print_exc()
        return False
    
    # Test individual components first
    print("\n" + "="*60)
    print("ğŸ”§ TESTANDO COMPONENTES INDIVIDUAIS")
    print("="*60)
    
    # 1. Test MarketContextEncoder
    print("\n1. ğŸŒ Testando MarketContextEncoder...")
    try:
        context_encoder = MarketContextEncoder(input_dim=256, context_dim=64)
        lstm_features = torch.randn(2, 10, 256)  # batch, seq, features
        context_features, regime_id, info = context_encoder(lstm_features)
        
        assert context_features.shape == (2, 10, 64), f"Context features shape: {context_features.shape}"
        assert isinstance(regime_id, int), f"Regime ID type: {type(regime_id)}"
        assert 0 <= regime_id <= 3, f"Regime ID range: {regime_id}"
        assert 'regime_name' in info, "Missing regime_name in info"
        
        print(f"   âœ… Context shape: {context_features.shape}")
        print(f"   âœ… Regime: {regime_id} ({info['regime_name']})")
        print(f"   âœ… Confidence: {info.get('regime_confidence', 0):.3f}")
        
    except Exception as e:
        print(f"   âŒ MarketContextEncoder failed: {e}")
        return False
    
    # 2. Test DaytradeEntryHead
    print("\n2. ğŸ¯ Testando DaytradeEntryHead...")
    try:
        entry_head = DaytradeEntryHead(input_dim=320)  # 256 + 64
        lstm_features = torch.randn(2, 256)
        market_context = torch.randn(2, 64)
        
        raw_entry, entry_confidence, gate_info = entry_head(lstm_features, market_context)
        
        assert raw_entry.shape == (2, 1), f"Raw entry shape: {raw_entry.shape}"
        assert entry_confidence.shape == (2, 1), f"Entry confidence shape: {entry_confidence.shape}"
        assert torch.all((entry_confidence >= 0) & (entry_confidence <= 1)), "Entry confidence not in [0,1]"
        assert 'entry_head_type' in gate_info, "Missing entry_head_type in gate_info"
        
        print(f"   âœ… Raw entry range: [{raw_entry.min():.3f}, {raw_entry.max():.3f}]")
        print(f"   âœ… Confidence range: [{entry_confidence.min():.3f}, {entry_confidence.max():.3f}]")
        print(f"   âœ… Gate info keys: {list(gate_info.keys())}")
        
    except Exception as e:
        print(f"   âŒ DaytradeEntryHead failed: {e}")
        traceback.print_exc()
        return False
    
    # 3. Test DaytradeManagementHead  
    print("\n3. ğŸ’° Testando DaytradeManagementHead...")
    try:
        mgmt_head = DaytradeManagementHead(input_dim=320)
        lstm_features = torch.randn(2, 256)
        market_context = torch.randn(2, 64)
        
        mgmt_decisions, mgmt_conf, mgmt_weights = mgmt_head(lstm_features, market_context)
        
        assert mgmt_decisions.shape == (2, 6), f"Management decisions shape: {mgmt_decisions.shape}"
        assert mgmt_conf.shape == (2, 1), f"Management confidence shape: {mgmt_conf.shape}"
        assert mgmt_weights.shape == (2, 3), f"Management weights shape: {mgmt_weights.shape}"
        assert torch.all((mgmt_decisions >= -3) & (mgmt_decisions <= 3)), "SL/TP not in [-3,3]"
        
        print(f"   âœ… SL/TP decisions shape: {mgmt_decisions.shape}")
        print(f"   âœ… SL/TP range: [{mgmt_decisions.min():.3f}, {mgmt_decisions.max():.3f}]")
        print(f"   âœ… Mgmt confidence: [{mgmt_conf.min():.3f}, {mgmt_conf.max():.3f}]")
        
    except Exception as e:
        print(f"   âŒ DaytradeManagementHead failed: {e}")
        traceback.print_exc()
        return False
    
    # 4. Test ElegantMemoryBank
    print("\n4. ğŸ’¾ Testando ElegantMemoryBank...")
    try:
        memory_bank = ElegantMemoryBank(memory_size=512, trade_dim=8)
        
        # Add some trades
        for i in range(10):
            trade_data = torch.randn(8) * 0.1
            memory_bank.add_trade(trade_data)
        
        context = memory_bank.get_memory_context(batch_size=2)
        assert context.shape == (2, 8), f"Memory context shape: {context.shape}"
        
        print(f"   âœ… Memory size: {memory_bank.memory_size}")
        print(f"   âœ… Current pointer: {memory_bank.memory_ptr.item()}")
        print(f"   âœ… Context shape: {context.shape}")
        
    except Exception as e:
        print(f"   âŒ ElegantMemoryBank failed: {e}")
        return False
    
    # Test complete policy
    print("\n" + "="*60)
    print("ğŸ—ï¸ TESTANDO POLICY COMPLETA")
    print("="*60)
    
    try:
        # Create observation and action spaces
        observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(2580,), dtype=np.float32)
        action_space = spaces.Box(low=-3, high=3, shape=(8,), dtype=np.float32)
        
        print(f"ğŸ“Š Observation space: {observation_space.shape}")
        print(f"ğŸ¯ Action space: {action_space.shape}")
        
        # Get kwargs
        kwargs = get_v8_elegance_kwargs()
        print(f"ğŸ“‹ V8 kwargs keys: {list(kwargs.keys())}")
        
        # Create policy
        print("\nğŸš§ Criando TwoHeadV8Elegance...")
        policy = TwoHeadV8Elegance(
            observation_space=observation_space,
            action_space=action_space,
            lr_schedule=lambda _: 3e-4,
            **kwargs
        )
        print("âœ… Policy criada com sucesso!")
        
        # Validate policy
        print("\nğŸ” Validando policy...")
        validate_v8_elegance_policy(policy)
        
        # Test forward passes
        print("\nğŸ¯ Testando forward passes...")
        
        batch_size = 2
        # FIX: Observations devem ter shape (batch_size, 2580) para o transformer
        observations = torch.randn(batch_size, 2580)
        lstm_states = (
            torch.zeros(1, batch_size, 256),
            torch.zeros(1, batch_size, 256)
        )
        episode_starts = torch.zeros(batch_size, dtype=torch.bool)
        
        # Test actor forward
        print("   ğŸ­ Actor forward...")
        actions, new_states, gate_info = policy.forward_actor(observations, lstm_states, episode_starts)
        
        assert actions.shape == (batch_size, 8), f"Actions shape: {actions.shape}"
        assert len(new_states) == 2, f"LSTM states: {len(new_states)}"
        assert isinstance(gate_info, dict), f"Gate info type: {type(gate_info)}"
        
        print(f"      âœ… Actions shape: {actions.shape}")
        print(f"      âœ… Action ranges:")
        print(f"         [0] entry_decision: {actions[:, 0].tolist()}")
        print(f"         [1] confidence: [{actions[:, 1].min():.3f}, {actions[:, 1].max():.3f}]")
        print(f"         [2-7] SL/TP: [{actions[:, 2:].min():.3f}, {actions[:, 2:].max():.3f}]")
        
        # Test critic forward
        print("   ğŸ’° Critic forward...")
        values, critic_states = policy.forward_critic(observations, lstm_states, episode_starts)
        
        assert values.shape == (batch_size, 1), f"Values shape: {values.shape}"
        
        print(f"      âœ… Values shape: {values.shape}")
        print(f"      âœ… Values range: [{values.min():.3f}, {values.max():.3f}]")
        
        # Test predict_values
        print("   ğŸ“Š Predict values...")
        pred_values = policy.predict_values(observations, lstm_states, episode_starts)
        
        assert pred_values.shape == values.shape, f"Predicted values shape mismatch"
        
        print(f"      âœ… Predicted values consistent with forward_critic")
        
        # Test status
        print("   ğŸ“ˆ Status check...")
        status = policy.get_v8_status()
        
        expected_keys = ['architecture', 'lstm_hidden', 'features_dim', 'current_regime']
        for key in expected_keys:
            assert key in status, f"Missing key in status: {key}"
        
        print(f"      âœ… Status keys: {list(status.keys())}")
        print(f"      âœ… Current regime: {status['current_regime']} ({status.get('regime_info', {}).get('regime_name', 'unknown')})")
        
        # Test post training step
        print("   ğŸƒ Post training step...")
        experience = {
            'reward': 0.1,
            'duration': 5.0,
            'confidence': 0.8,
            'done': False,
            'pnl': 0.05
        }
        
        post_info = policy.post_training_step(experience)
        
        assert 'v8_regime' in post_info, "Missing v8_regime in post_info"
        assert 'v8_training_step' in post_info, "Missing v8_training_step in post_info"
        
        print(f"      âœ… Post training info: {list(post_info.keys())}")
        print(f"      âœ… Training step: {post_info['v8_training_step']}")
        
    except Exception as e:
        print(f"âŒ Erro no teste da policy completa: {e}")
        traceback.print_exc()
        return False
    
    # Final validation
    print("\n" + "="*60)
    print("ğŸ VALIDAÃ‡ÃƒO FINAL")
    print("="*60)
    
    print("âœ… Todos os testes passaram!")
    print()
    print("ğŸ“Š RESUMO V8ELEGANCE:")
    print(f"   ğŸ§  LSTM compartilhada: {policy.v8_lstm_hidden}D")
    print(f"   ğŸ¯ Entry Head: EspecÃ­fico (entry + confidence)")  
    print(f"   ğŸ’° Management Head: EspecÃ­fico (SL/TP por posiÃ§Ã£o)")
    print(f"   ğŸ’¾ Memory Bank: {policy.v8_memory_size} trades")
    print(f"   ğŸŒ Market Context: {policy.v8_context_dim}D (4 regimes)")
    print(f"   âš¡ Action Space: 8D completo")
    print()
    print("ğŸ¯ CARACTERÃSTICAS ELEGANTES:")
    print("   âœ… Uma LSTM (nÃ£o vÃ¡rias)")
    print("   âœ… Heads especÃ­ficos (nÃ£o genÃ©ricos)")
    print("   âœ… Memory simplificado (nÃ£o complexo)")  
    print("   âœ… Context Ãºnico (nÃ£o mÃºltiplos gates)")
    print("   âœ… 8D actions mantidas (funcionalidade completa)")
    
    return True

if __name__ == "__main__":
    success = test_v8_elegance_complete()
    
    if success:
        print("\nğŸš€ TwoHeadV8Elegance APROVADA - Pronta para uso!")
    else:
        print("\nâŒ TwoHeadV8Elegance FALHOU - Revisar implementaÃ§Ã£o")
    
    print("\n" + "="*60)