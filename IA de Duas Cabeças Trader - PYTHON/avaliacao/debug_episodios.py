#!/usr/bin/env python3
"""
Debug do Sistema de Epis√≥dios SILUS
===================================
Investigar por que epis√≥dios n√£o est√£o terminando corretamente
"""

import sys
import os
sys.path.append('D:/Projeto')

import numpy as np
import pandas as pd
from pathlib import Path
import time

# Importar o ambiente SILUS
from silus import TradingEnv, load_optimized_data

def debug_episode_system():
    """Testar o sistema de epis√≥dios manualmente"""
    
    print("="*80)
    print("üîç DEBUG DO SISTEMA DE EPIS√ìDIOS SILUS")
    print("="*80)
    
    # Carregar dados
    print("\n‚è≥ Carregando dataset...")
    df = load_optimized_data()
    print(f"   Dataset carregado: {len(df)} barras")
    
    # Criar ambiente
    print("\nüèóÔ∏è Criando ambiente...")
    env = TradingEnv(df, window_size=20, is_training=True, initial_balance=500)
    
    print(f"   MAX_STEPS configurado: {env.MAX_STEPS}")
    print(f"   Dataset size: {len(env.df)}")
    print(f"   Initial balance: {env.initial_balance}")
    print(f"   Current step inicial: {env.current_step}")
    print(f"   Episode steps inicial: {env.episode_steps}")
    
    # Testar reset
    print("\nüîÑ Testando reset...")
    obs = env.reset()
    print(f"   Ap√≥s reset:")
    print(f"     Current step: {env.current_step}")
    print(f"     Episode steps: {env.episode_steps}")
    print(f"     Portfolio value: {env.portfolio_value}")
    print(f"     Observation shape: {obs.shape}")
    
    # Simular alguns steps
    print(f"\nüöÄ Simulando steps at√© encontrar epis√≥dio completo...")
    
    episode_count = 0
    step_count = 0
    max_test_steps = 10000
    
    episode_rewards = []
    episode_lengths = []
    portfolio_resets = []
    
    current_episode_reward = 0
    current_episode_length = 0
    
    for step in range(max_test_steps):
        # A√ß√£o aleat√≥ria
        action = env.action_space.sample()
        
        # Step no ambiente
        obs, reward, done, info = env.step(action)
        
        current_episode_reward += reward
        current_episode_length += 1
        step_count += 1
        
        # Verificar reset de portfolio
        if abs(env.portfolio_value - 500.0) < 0.01:
            portfolio_resets.append(step)
        
        # Verificar se epis√≥dio terminou
        if done:
            episode_count += 1
            episode_rewards.append(current_episode_reward)
            episode_lengths.append(current_episode_length)
            
            print(f"\n‚úÖ EPIS√ìDIO {episode_count} COMPLETADO!")
            print(f"   Steps no epis√≥dio: {current_episode_length}")
            print(f"   Reward total: {current_episode_reward:.6f}")
            print(f"   Portfolio final: {env.portfolio_value:.2f}")
            print(f"   Trades no epis√≥dio: {len(env.trades)}")
            print(f"   Current step: {env.current_step}")
            print(f"   Episode steps: {env.episode_steps}")
            
            # Reset para pr√≥ximo epis√≥dio
            obs = env.reset()
            current_episode_reward = 0
            current_episode_length = 0
            
            print(f"   Ap√≥s reset autom√°tico:")
            print(f"     Current step: {env.current_step}")
            print(f"     Episode steps: {env.episode_steps}")
            print(f"     Portfolio value: {env.portfolio_value}")
            
            # Parar ap√≥s alguns epis√≥dios para an√°lise
            if episode_count >= 3:
                break
        
        # Log de progresso
        if step % 1000 == 0 and step > 0:
            print(f"   Step {step}: Episode steps: {env.episode_steps}, Portfolio: {env.portfolio_value:.2f}")
    
    # An√°lise final
    print(f"\n" + "="*80)
    print("üìä RESULTADO DA AN√ÅLISE")
    print("="*80)
    
    print(f"\nüî¢ ESTAT√çSTICAS:")
    print(f"   Total steps testados: {step_count}")
    print(f"   Epis√≥dios completados: {episode_count}")
    print(f"   Portfolio resets detectados: {len(portfolio_resets)}")
    
    if episode_count > 0:
        print(f"\n‚úÖ EPIS√ìDIOS FUNCIONANDO:")
        print(f"   Reward m√©dio por epis√≥dio: {np.mean(episode_rewards):.6f}")
        print(f"   Length m√©dio por epis√≥dio: {np.mean(episode_lengths):.1f}")
        print(f"   Steps entre resets de portfolio: {np.diff(portfolio_resets).mean():.1f}")
        
        # Verificar se rewards s√£o sempre zero
        if all(r == 0 for r in episode_rewards):
            print(f"   ‚ùå PROBLEMA: Todos os episode rewards s√£o ZERO!")
        else:
            print(f"   ‚úÖ Episode rewards variando corretamente")
    
    else:
        print(f"\n‚ùå PROBLEMA CR√çTICO: NENHUM EPIS√ìDIO COMPLETADO!")
        print(f"   Max episode length atual: {current_episode_length}")
        print(f"   Current step final: {env.current_step}")
        print(f"   Episode steps final: {env.episode_steps}")
        
        # Verificar condi√ß√µes de done
        print(f"\nüîç VERIFICANDO CONDI√á√ïES DE DONE:")
        print(f"   current_step >= len(df) - 1: {env.current_step >= len(env.df) - 1}")
        print(f"   episode_steps >= MAX_STEPS: {env.episode_steps >= env.MAX_STEPS}")
        print(f"   Valores: current_step={env.current_step}, len(df)={len(env.df)}, episode_steps={env.episode_steps}, MAX_STEPS={env.MAX_STEPS}")
    
    if portfolio_resets:
        print(f"\nüîÑ PORTFOLIO RESETS:")
        print(f"   Frequ√™ncia m√©dia: a cada {step_count / len(portfolio_resets):.1f} steps")
        print(f"   Primeiros resets em: {portfolio_resets[:10]}")
    
    # Analisar system reward
    print(f"\nüéØ AN√ÅLISE DO REWARD SYSTEM:")
    if hasattr(env, 'reward_system'):
        print(f"   Reward system: {type(env.reward_system).__name__}")
        print(f"   Initial balance: {env.reward_system.initial_balance}")
    else:
        print(f"   ‚ùå Reward system n√£o encontrado!")
    
    return {
        'episodes_completed': episode_count,
        'episode_rewards': episode_rewards,
        'episode_lengths': episode_lengths,
        'portfolio_resets': len(portfolio_resets),
        'total_steps': step_count
    }

if __name__ == "__main__":
    result = debug_episode_system()
    
    print(f"\n" + "="*80)
    print("üí° CONCLUS√ïES")
    print("="*80)
    
    if result['episodes_completed'] == 0:
        print("""
‚ùå PROBLEMA CONFIRMADO: Sistema de epis√≥dios QUEBRADO

POSS√çVEIS CAUSAS:
1. MAX_STEPS muito alto (3000) vs dataset pequeno
2. Condi√ß√£o de done n√£o sendo atendida
3. current_step n√£o avan√ßando corretamente
4. episode_steps n√£o sendo resetado

SOLU√á√ïES SUGERIDAS:
1. Reduzir MAX_STEPS para 252 (1 dia de trading)
2. Verificar l√≥gica de done no step()
3. Garantir reset correto de episode_steps
4. Adicionar done por timeout absoluto
""")
    else:
        print(f"""
‚úÖ Sistema funcionando parcialmente
- {result['episodes_completed']} epis√≥dios completados
- Reward m√©dio: {np.mean(result['episode_rewards']) if result['episode_rewards'] else 0:.6f}

Se rewards s√£o zero, problema √© no reward system, n√£o nos epis√≥dios.
""")