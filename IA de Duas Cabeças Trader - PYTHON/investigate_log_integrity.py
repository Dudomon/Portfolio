#!/usr/bin/env python3
"""
ğŸ” INVESTIGAÃ‡ÃƒO: Logs gerando valores incorretos?
Verificar se o problema estÃ¡ na coleta/logging das mÃ©tricas
"""

import json
import os

def investigate_log_integrity():
    print("ğŸ” INVESTIGAÃ‡ÃƒO: INTEGRIDADE DOS LOGS")
    print("=" * 60)

    # Vamos comparar diferentes logs para ver padrÃµes
    log_files = [
        "D:/Projeto/avaliacoes/training_20250925_155645_1092_c91f73d9.jsonl",  # Antes das mudanÃ§as
        "D:/Projeto/avaliacoes/training_20250925_182105_22376_6cd3fa56.jsonl"   # Depois das mudanÃ§as
    ]

    for i, filename in enumerate(log_files):
        print(f"\nğŸ“Š ANÃLISE LOG {i+1}: {os.path.basename(filename)}")
        print("-" * 50)

        if not os.path.exists(filename):
            print(f"âŒ Arquivo nÃ£o encontrado!")
            continue

        try:
            with open(filename, 'r') as f:
                lines = f.readlines()

            total_lines = len(lines)
            training_lines = []

            for line_num, line in enumerate(lines, 1):
                try:
                    data = json.loads(line.strip())

                    # Verificar se Ã© linha de treinamento
                    if 'explained_variance' in data:
                        training_lines.append((line_num, data))

                except json.JSONDecodeError as e:
                    print(f"âš ï¸ JSON invÃ¡lido na linha {line_num}: {e}")
                    continue
        except Exception as e:
            print(f"âŒ Erro ao processar arquivo: {e}")
            continue

        print(f"ğŸ“ˆ Total de linhas: {total_lines}")
        print(f"ğŸ“ˆ Linhas de treinamento: {len(training_lines)}")

        if not training_lines:
            print("âŒ NENHUMA linha de treinamento encontrada!")
            continue

        # AnÃ¡lise das primeiras e Ãºltimas 5 linhas de treinamento
        print(f"\nğŸ” PRIMEIRAS 5 LINHAS DE TREINAMENTO:")
            for j, (line_num, data) in enumerate(training_lines[:5]):
                step = data.get('step', 'N/A')
                exp_var = data.get('explained_variance', 'N/A')
                policy_loss = data.get('policy_loss', 'N/A')
                value_loss = data.get('value_loss', 'N/A')
                clip_frac = data.get('clip_fraction', 'N/A')
                approx_kl = data.get('approx_kl', 'N/A')

                print(f"  Linha {line_num}: Step={step}")
                print(f"    exp_var={exp_var}, policy_loss={policy_loss}")
                print(f"    value_loss={value_loss}, clip_frac={clip_frac}, kl={approx_kl}")

            print(f"\nğŸ” ÃšLTIMAS 5 LINHAS DE TREINAMENTO:")
            for j, (line_num, data) in enumerate(training_lines[-5:]):
                step = data.get('step', 'N/A')
                exp_var = data.get('explained_variance', 'N/A')
                policy_loss = data.get('policy_loss', 'N/A')
                value_loss = data.get('value_loss', 'N/A')
                clip_frac = data.get('clip_fraction', 'N/A')
                approx_kl = data.get('approx_kl', 'N/A')

                print(f"  Linha {line_num}: Step={step}")
                print(f"    exp_var={exp_var}, policy_loss={policy_loss}")
                print(f"    value_loss={value_loss}, clip_frac={clip_frac}, kl={approx_kl}")

            # Detectar padrÃµes suspeitos
            print(f"\nğŸš¨ DETECÃ‡ÃƒO DE PADRÃ•ES SUSPEITOS:")

            all_zeros_count = 0
            all_same_count = 0
            missing_fields_count = 0

            prev_values = None

            for line_num, data in training_lines:
                # Contar zeros absolutos
                key_metrics = ['explained_variance', 'policy_loss', 'value_loss', 'clip_fraction', 'approx_kl']
                current_values = [data.get(key, None) for key in key_metrics]

                # Zeros absolutos
                if all(val == 0 for val in current_values if val is not None):
                    all_zeros_count += 1

                # Valores idÃªnticos consecutivos
                if prev_values is not None and current_values == prev_values:
                    all_same_count += 1

                # Campos ausentes
                missing = [key for key in key_metrics if key not in data or data[key] is None]
                if missing:
                    missing_fields_count += 1

                prev_values = current_values

            print(f"   ğŸ”´ Linhas com TODOS valores = 0: {all_zeros_count}/{len(training_lines)} ({all_zeros_count/len(training_lines)*100:.1f}%)")
            print(f"   ğŸ”´ Linhas idÃªnticas consecutivas: {all_same_count}/{len(training_lines)} ({all_same_count/len(training_lines)*100:.1f}%)")
            print(f"   ğŸ”´ Linhas com campos ausentes: {missing_fields_count}/{len(training_lines)} ({missing_fields_count/len(training_lines)*100:.1f}%)")

            # DiagnÃ³stico
            if all_zeros_count > len(training_lines) * 0.8:
                print(f"   âŒ SUSPEITO: 80%+ das linhas tÃªm todos valores zerados")
            if all_same_count > len(training_lines) * 0.5:
                print(f"   âŒ SUSPEITO: 50%+ das linhas sÃ£o idÃªnticas consecutivas")
            if missing_fields_count > len(training_lines) * 0.1:
                print(f"   âŒ SUSPEITO: 10%+ das linhas tÃªm campos ausentes")

    # AnÃ¡lise comparativa
    print(f"\nğŸ”¬ HIPÃ“TESES SOBRE O PROBLEMA:")
    print("-" * 50)
    print("1. ğŸ“ PROBLEMA NO LOGGING:")
    print("   - Cherry.py pode estar logando valores default/zero")
    print("   - Callback de logging pode estar capturando mÃ©tricas vazias")
    print("   - Timing issue: logging antes das mÃ©tricas serem calculadas")

    print("\n2. ğŸ§  PROBLEMA NO PPO:")
    print("   - Model.learn() nÃ£o estÃ¡ executando updates reais")
    print("   - Stable-Baselines3 pode estar com problema interno")
    print("   - Policy nÃ£o estÃ¡ sendo atualizada")

    print("\n3. ğŸ”„ PROBLEMA NO ENVIRONMENT:")
    print("   - Experiences nÃ£o estÃ£o sendo coletadas corretamente")
    print("   - Rewards sÃ£o constantes â†’ sem gradiente â†’ sem update")
    print("   - Observations sÃ£o constantes â†’ sem aprendizado")

    print("\n4. ğŸ’¾ PROBLEMA DE CHECKPOINT:")
    print("   - Model carregado estÃ¡ congelado")
    print("   - ParÃ¢metros nÃ£o estÃ£o sendo atualizados")
    print("   - Gradientes bloqueados")

    print("\nğŸ¯ PRÃ“XIMOS STEPS PARA DIAGNOSTICAR:")
    print("-" * 50)
    print("1. Verificar se cherry.py estÃ¡ realmente chamando model.learn()")
    print("2. Adicionar debug prints no momento da captura de mÃ©tricas")
    print("3. Verificar se o model carregado permite updates (.train() vs .eval())")
    print("4. Verificar se rewards/observations tÃªm variabilidade")
    print("5. Testar com model novo (sem checkpoint) para comparar")

if __name__ == "__main__":
    investigate_log_integrity()