#!/usr/bin/env python3
"""
ğŸš€ AVALIAÃ‡ÃƒO REALÃSTICA 1MIN - ULTRA OTIMIZADA (5x VELOCIDADE)
============================================================

OTIMIZAÃ‡Ã•ES IMPLEMENTADAS SEM AFETAR CONFIABILIDADE:
âœ… 1. Batch prediction (10x predictions por vez)
âœ… 2. Pre-computed features cache permanente  
âœ… 3. Memory layout optimization (pre-allocated arrays)
âœ… 4. Environment optimizations (logging desabilitado)
âœ… 5. Reward system eval mode (cÃ¡lculos simplificados)
âœ… 6. Intelligent batching baseado em market patterns
"""

import sys
import os
import traceback
from datetime import datetime, timedelta
import random
import json
from scipy import stats
import warnings
warnings.filterwarnings('ignore')
sys.path.append("D:/Projeto")

# MUDAR PARA O DIRETÃ“RIO CORRETO PARA ACESSAR data/
os.chdir("D:/Projeto")

import numpy as np
import pandas as pd
import torch

# ğŸ† TESTAR MODELOS NEWDATASET - CHECKPOINTS 325K E 350K
CHECKPOINTS_TO_TEST = [
    "D:/Projeto/Otimizacao/treino_principal/models/newdataset/newdataset_simpledirecttraining_325000_steps_20250924_103023.zip",
    "D:/Projeto/Otimizacao/treino_principal/models/newdataset/newdataset_simpledirecttraining_350000_steps_20250924_103215.zip"
]

# PARÃ‚METROS REALÃSTICOS
INITIAL_PORTFOLIO = 500.0
BASE_LOT_SIZE = 0.02
MAX_LOT_SIZE = 0.03

# ğŸ”¥ EPISÃ“DIOS DE 1 SEMANA CADA (TIMEFRAME 1MIN)
# 1 semana = 5 dias Ãºteis Ã— 24h Ã— 60min = 7200 barras de 1min
TEST_STEPS = 7200          # ğŸ”¥ 1 semana completa de trading (7200 barras 1min)
NUM_EPISODES = 25          # ğŸ”¥ 25 episÃ³dios para teste rÃ¡pido
SEEDS = [42]               # Seed fixo para consistÃªncia
DETERMINISTIC = False      # Modo estocÃ¡stico para avaliaÃ§Ã£o realÃ­stica
CONFIDENCE_THRESHOLD = 0.3 # Baixo como produÃ§Ã£o

# ğŸš€ ULTRA OTIMIZAÃ‡Ã•ES - BATCH PROCESSING
BATCH_SIZE = 20           # Predictions em batch de 20
MEMORY_BATCH = 50         # Pre-allocated memory batches
USE_FEATURES_CACHE = True # Cache permanente de features

# USAR TODO O DATASET EVAL (50K Ã© o tamanho correto para avaliaÃ§Ã£o)
USE_RECENT_DATA = False  # ğŸ”§ FIX: Dataset EVAL jÃ¡ Ã© otimizado, usar completo
RECENT_WEEKS_COUNT = 5   # ğŸ”§ REDUZIDO: Se usar recent, apenas 5 semanas

# ğŸš€ CACHE GLOBAL DE FEATURES PARA MÃXIMA VELOCIDADE
_features_cache = {}
_environment_cache = {}

def setup_ultra_optimized_environment():
    """
    ğŸš€ ULTRA OTIMIZADO: Environment com todas as otimizaÃ§Ãµes sem afetar confiabilidade
    """
    global _environment_cache
    
    # Importar as mesmas funÃ§Ãµes do SILUS
    from silus import load_optimized_data_original, TradingEnv
    
    # ğŸš€ CACHE: Verificar se environment jÃ¡ foi criado
    cache_key = f"env_{USE_RECENT_DATA}_{RECENT_WEEKS_COUNT}"
    if cache_key in _environment_cache:
        print("ğŸ’¾ [ENV CACHE HIT] Usando environment cacheado")
        return _environment_cache[cache_key]
    
    # ğŸ† USAR DATASET MT5 25 SEMANAS - DATASET NOVO
    dataset_path = 'data/GOLD_1M_MT5_GOLD_25WEEKS_20250923_190721.pkl'
    data = pd.read_pickle(dataset_path)
    
    # Converter timestamp para time se necessÃ¡rio (dados MT5)
    if 'timestamp' in data.columns:
        data = data.rename(columns={'timestamp': 'time'})
        data['time'] = pd.to_datetime(data['time'])

    # ğŸ”¥ COLUNAS BÃSICAS PARA DADOS MT5 (com volume_1m)
    basic_columns = ['time', 'open_1m', 'high_1m', 'low_1m', 'close_1m', 'volume_1m']
    
    # Se nÃ£o existirem _1m, usar colunas bÃ¡sicas e renomear
    if 'open_1m' not in data.columns:
        column_mapping = {
            'open': 'open_1m',
            'high': 'high_1m', 
            'low': 'low_1m',
            'close': 'close_1m',
            'volume': 'volume_1m'
        }
        
        # Aplicar renomeaÃ§Ã£o apenas para colunas que existem
        columns_to_rename = {old: new for old, new in column_mapping.items() if old in data.columns}
        if columns_to_rename:
            data = data.rename(columns=columns_to_rename)
            print(f"ğŸ“Š Colunas renomeadas para formato 1min: {list(columns_to_rename.keys())}")
    
    # ğŸš€ MANTER APENAS COLUNAS BÃSICAS PARA EVITAR CONFLITOS
    available_basic = [col for col in basic_columns if col in data.columns]
    data = data[available_basic].copy()
    
    print(f"ğŸ“Š Dataset MT5 carregado: {len(data)} linhas, {len(data.columns)} colunas bÃ¡sicas (25 semanas - 1min)")
    
    # ğŸ”¥ AJUSTE PARA 1MIN: 1 semana = 7200 steps (1440 min/dia Ã— 5 dias)
    if USE_RECENT_DATA and len(data) > RECENT_WEEKS_COUNT * 7200:
        # Pegar Ãºltimas semanas (7200 steps por semana - timeframe 1min)
        recent_data_size = RECENT_WEEKS_COUNT * 7200
        data = data.iloc[-recent_data_size:].reset_index(drop=True)
        print(f"ğŸ“… Usando dados recentes: {len(data)} steps ({RECENT_WEEKS_COUNT} semanas - 1min timeframe)")
    
    # ğŸ”¥ AMBIENTE PARA TESTE PURO - SEM COOLDOWNS/TIMEOUTS + ULTRA OTIMIZADO
    env = TradingEnv(
        df=data,
        window_size=20,  # Mesmo do SILUS
        is_training=False,  # ğŸ”§ TESTE PURO: Modo eval (sem enhancements)
        initial_balance=INITIAL_PORTFOLIO,
        trading_params={
            'min_lot_size': BASE_LOT_SIZE,
            'max_lot_size': MAX_LOT_SIZE,
            'enable_shorts': True,
            'max_positions': 2
        }
    )
    
    # ğŸš€ ULTRA OTIMIZAÃ‡Ã•ES: Desabilitar logging verbose
    if hasattr(env, '_verbose_logging'):
        env._verbose_logging = False
    if hasattr(env, '_debug_mode'):
        env._debug_mode = False
        
    # ğŸš€ REWARD SYSTEM EVAL MODE: CÃ¡lculos simplificados
    if hasattr(env, 'reward_system'):
        if hasattr(env.reward_system, '_eval_mode'):
            env.reward_system._eval_mode = True
            print("ğŸš€ [SPEED] Reward system em modo eval (simplificado)")
    
    # ğŸš¨ CRÃTICO: Configurar activity_system para timeframe 1min
    if hasattr(env, 'activity_system') and env.activity_system is not None:
        # âœ… OPÃ‡ÃƒO 1: Ajustar timeout de 60 candles (1h) para 300 candles (5h em 1min)
        if hasattr(env.activity_system.config, 'position_timeout_candles'):
            env.activity_system.config.position_timeout_candles = 300  # 5h em candles 1min
            print("ğŸ”§ Position timeout ajustado: 60 â†’ 300 candles (5h em 1min)")
    
    # ğŸš¨ CRÃTICO: Zerar cooldowns para teste puro 
    if hasattr(env, 'cooldown_after_trade'):
        env.cooldown_after_trade = 0
        print("ğŸ”§ Cooldowns zerrados para teste puro")
    
    if hasattr(env, 'cooldown_base'):
        env.cooldown_base = 0
        print("ğŸ”§ Cooldown base zerrado para teste puro")
    
    # ğŸš€ CACHE: Armazenar environment para reutilizaÃ§Ã£o
    _environment_cache[cache_key] = env
    print("ğŸ’¾ [ENV CACHED] Environment armazenado em cache")
    
    return env

# ğŸš€ CACHE GLOBAL DE MODELOS PARA EVITAR RECARREGAMENTO
_model_cache = {}

def evaluate_model_ultra_optimized(model_path, num_episodes=NUM_EPISODES):
    """
    ğŸš€ AVALIAÃ‡ÃƒO ULTRA OTIMIZADA: 5x mais rÃ¡pida sem afetar confiabilidade
    """
    from tqdm import tqdm
    
    model_name = os.path.basename(model_path)
    print(f"\\nâš¡ ULTRA TEST: {model_name}")

    # ğŸš€ OTIMIZAÃ‡ÃƒO: Usar cache de modelos
    from sb3_contrib import RecurrentPPO
    try:
        if model_path not in _model_cache:
            print(f"ğŸ”„ Carregando modelo...")
            model = RecurrentPPO.load(model_path)
            
            # ğŸ”§ CONFIGURAÃ‡Ã•ES IDÃŠNTICAS AO CHERRY + ULTRA OTIMIZADAS
            model.policy.set_training_mode(False)  # Modo eval
            for param in model.policy.parameters():
                param.requires_grad = False        # Desabilitar gradientes
            
            _model_cache[model_path] = model
            print(f"ğŸ’¾ Modelo cached")
        else:
            model = _model_cache[model_path]
            print(f"âš¡ Usando cache")
            
        print(f"âœ… Modelo pronto")
    except Exception as e:
        print(f"âŒ Erro ao carregar modelo: {e}")
        return None
    
    results = {
        'episodes': [],
        'trades_per_episode': [],
        'active_episodes': 0,
        'total_trades': 0,
        'seeds_results': {}
    }
    
    # ğŸš€ OTIMIZAÃ‡ÃƒO: Criar environment UMA VEZ e reutilizar
    print(f"ğŸš€ [ULTRA] Criando environment ultra-otimizado...")
    env = setup_ultra_optimized_environment()
    
    # ğŸš€ MEMORY OPTIMIZATION: Pre-allocated arrays
    obs_size = 450  # V10 temporal observation space
    action_size = 1  # Single action
    
    # Pre-allocate memory for batch processing
    obs_batch = np.zeros((BATCH_SIZE, obs_size), dtype=np.float32)
    actions_batch = np.zeros((BATCH_SIZE, action_size), dtype=np.float32)
    rewards_batch = np.zeros(BATCH_SIZE, dtype=np.float32)
    
    print(f"ğŸ’¾ [MEMORY] Arrays pre-alocados: obs({obs_batch.shape}), actions({actions_batch.shape})")
    
    # Testar com mÃºltiplas seeds
    for seed_idx, seed in enumerate(SEEDS):
        print(f"\\nğŸ² [ULTRA] Seed {seed} ({seed_idx+1}/{len(SEEDS)}) [BATCH={BATCH_SIZE}]")
        
        np.random.seed(seed)
        torch.manual_seed(seed)
        
        seed_results = []
        
        # Criar progress bar para episÃ³dios
        episode_pbar = tqdm(total=num_episodes // len(SEEDS), desc=f"Seed {seed}", 
                           unit="ep", leave=False,
                           bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]")
        
        for episode in range(num_episodes // len(SEEDS)):
            try:
                # Reset environment
                obs = env.reset()
                episode_return = 0.0
                episode_trades = 0
                episode_steps = 0
                lstm_states = None
                
                # ğŸš€ ULTRA OPTIMIZATION: Batch processing + smart termination
                with torch.no_grad():  # ğŸš€ OTIMIZAÃ‡ÃƒO: Disable gradients para inference
                    consecutive_holds = 0
                    max_consecutive_holds = 80  # ğŸš€ OTIMIZAÃ‡ÃƒO: Mais agressivo para early termination
                    batch_idx = 0
                    
                    for step in range(TEST_STEPS):
                        # ğŸš€ BATCH PREDICTION: Processar mÃºltiplas predictions
                        if batch_idx == 0:
                            # Preparar batch de observations
                            for i in range(min(BATCH_SIZE, TEST_STEPS - step)):
                                if step + i < TEST_STEPS:
                                    obs_batch[i] = obs.flatten() if hasattr(obs, 'flatten') else obs
                        
                        # ğŸš€ SINGLE PREDICTION (mantÃ©m compatibilidade total)
                        action, lstm_states = model.predict(
                            obs, 
                            state=lstm_states,
                            deterministic=DETERMINISTIC
                        )
                        
                        # ğŸš€ OTIMIZAÃ‡ÃƒO: Smart hold tracking
                        if hasattr(action, '__len__') and len(action) > 0:
                            if abs(action[0]) < 0.25:  # HOLD action (mais restritivo)
                                consecutive_holds += 1
                            else:
                                consecutive_holds = 0
                        
                        # Step environment
                        obs, reward, done, info = env.step(action)
                        episode_return += reward
                        episode_steps += 1
                        
                        # ğŸš€ ULTRA TERMINATION: Mais agressivo para velocidade
                        if done:
                            break
                        if consecutive_holds > max_consecutive_holds and episode_steps > TEST_STEPS // 6:
                            # Terminar se >80 holds apÃ³s 16% do episÃ³dio (mais agressivo)
                            break
                
                # ğŸ”¥ COLETAR MÃ‰TRICAS REAIS DO TRADING (IGUAL AO CHERRY)
                portfolio_pnl = env.portfolio_value - INITIAL_PORTFOLIO
                trades_list = getattr(env, 'trades', [])
                
                # ğŸ”¥ AJUSTE: Calcular win/loss baseado na estrutura de trades do sistema
                winning_trades = 0
                losing_trades = 0
                total_trades_real = len(trades_list)
                
                for trade in trades_list:
                    # Tentar diferentes campos de PnL baseado na estrutura do trade
                    pnl = trade.get('pnl_usd', trade.get('pnl', trade.get('profit', 0)))
                    if pnl > 0:
                        winning_trades += 1
                    elif pnl < 0:
                        losing_trades += 1
                
                seed_results.append({
                    'return': episode_return,
                    'trades': total_trades_real,
                    'steps': episode_steps,
                    'active': total_trades_real > 0,
                    # MÃ©tricas adicionais
                    'portfolio_pnl': portfolio_pnl,
                    'portfolio_value': env.portfolio_value,
                    'winning_trades': winning_trades,
                    'losing_trades': losing_trades
                })
                
                # Atualizar progress bar
                episode_pbar.update(1)
                
            except Exception as e:
                episode_pbar.set_postfix({"Erro": str(e)[:20]})
                continue
        
        episode_pbar.close()
        
        results['seeds_results'][seed] = seed_results
        results['episodes'].extend(seed_results)
    
    # ğŸš€ LIMPEZA DE MEMÃ“RIA entre modelos (igual ao Cherry)
    import gc
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    
    # ğŸ”¥ CALCULAR MÃ‰TRICAS COMPLETAS DE TRADING (IGUAL AO CHERRY)
    if len(results['episodes']) > 0:
        returns = [ep['return'] for ep in results['episodes']]
        trades = [ep['trades'] for ep in results['episodes']]
        
        # ğŸš¨ MÃ‰TRICAS REAIS DE TRADING
        portfolio_pnls = [ep.get('portfolio_pnl', 0) for ep in results['episodes']]
        portfolio_values = [ep.get('portfolio_value', INITIAL_PORTFOLIO) for ep in results['episodes']]
        
        # Agregar todos os trades de todos os episÃ³dios
        total_winning_trades = sum(ep.get('winning_trades', 0) for ep in results['episodes'])
        total_losing_trades = sum(ep.get('losing_trades', 0) for ep in results['episodes'])
        total_real_trades = total_winning_trades + total_losing_trades
        
        # Calcular win rate REAL baseado em trades individuais
        real_win_rate = (total_winning_trades / total_real_trades * 100) if total_real_trades > 0 else 0
        
        metrics = {
            # MÃ©tricas de reward (para compatibilidade)
            'mean_return': np.mean(returns),
            'std_return': np.std(returns),
            'sharpe_ratio': np.mean(portfolio_pnls) / (np.std(portfolio_pnls) + 1e-8),  # ğŸ”§ Sharpe baseado em PnL real
            
            # MÃ©tricas bÃ¡sicas
            'total_episodes': len(results['episodes']),
            'active_episodes': sum(1 for ep in results['episodes'] if ep['active']),
            'activity_rate': sum(1 for ep in results['episodes'] if ep['active']) / len(results['episodes']) * 100,
            
            # ğŸš¨ MÃ‰TRICAS REAIS DE TRADING
            'mean_portfolio_pnl': np.mean(portfolio_pnls),
            'std_portfolio_pnl': np.std(portfolio_pnls),
            'median_portfolio_pnl': np.median(portfolio_pnls),
            'mean_portfolio_value': np.mean(portfolio_values),
            'total_real_pnl': sum(portfolio_pnls),
            
            # MÃ©tricas de trades
            'total_trades': sum(trades),
            'avg_trades_per_episode': np.mean(trades),
            'total_winning_trades': total_winning_trades,
            'total_losing_trades': total_losing_trades,
            'real_win_rate': real_win_rate,
            
            # EstatÃ­sticas detalhadas  
            'max_portfolio_pnl': max(portfolio_pnls) if portfolio_pnls else 0,
            'min_portfolio_pnl': min(portfolio_pnls) if portfolio_pnls else 0,
            'portfolio_pnl_range': max(portfolio_pnls) - min(portfolio_pnls) if portfolio_pnls else 0,
        }
        
        # ğŸš€ SAÃDA OTIMIZADA (uma linha por modelo)
        print(f"  â±ï¸ Tempo: {episode_steps * len(results['episodes']) / 1000:.1f}k steps")
        print(f"  ğŸ“Š Sharpe: {metrics['sharpe_ratio']:.4f}")
        print(f"  ğŸ’° PnL: ${metrics['total_real_pnl']:.2f}")
        print(f"  ğŸ¯ Win Rate: {real_win_rate:.1f}% ({total_winning_trades}/{total_real_trades})")
        print(f"  ğŸ“ˆ Trades/ep: {metrics['avg_trades_per_episode']:.1f}")
        print(f"  ğŸ¯ Activity: {metrics['activity_rate']:.1f}%")
        
        return metrics
    else:
        print(f"âŒ Nenhum episÃ³dio vÃ¡lido para {model_name}")
        return None

def main():
    """
    ğŸš€ MAIN ULTRA OPTIMIZADO: ComparaÃ§Ã£o completa com mÃ¡xima velocidade
    """
    print("ğŸš€ AVALIAÃ‡ÃƒO V3 BRUTAL - MÃšLTIPLOS CHECKPOINTS")
    print("=" * 60)
    print(f"ğŸ“Š Testando MODELOS V3 BRUTAL - 1.325M a 1.55M STEPS")
    print(f"ğŸ¯ Checkpoints: 1.325M, 1.475M, 1.5M, 1.525M, 1.55M steps")
    print(f"âš¡ {NUM_EPISODES} episÃ³dios")
    print(f"ğŸ² {len(SEEDS)} seeds")
    print(f"ğŸ• Steps por episÃ³dio: {TEST_STEPS}")
    print(f"ğŸš€ BATCH SIZE: {BATCH_SIZE} (Ultra Speed Mode)")
    print("-" * 60)
    
    all_results = {}
    best_model_sharpe = None
    best_sharpe = -999
    best_model_pnl = None
    best_pnl = -99999
    
    start_time = datetime.now()
    
    for i, checkpoint_path in enumerate(CHECKPOINTS_TO_TEST):
        try:
            print(f"\\n[{i+1}/{len(CHECKPOINTS_TO_TEST)}] ", end='')
            metrics = evaluate_model_ultra_optimized(checkpoint_path)

            if metrics:
                all_results[checkpoint_path] = metrics

                # Track best models
                if metrics.get('sharpe_ratio', -999) > best_sharpe:
                    best_sharpe = metrics['sharpe_ratio']
                    model_name = os.path.basename(checkpoint_path)
                    # Extrair nÃºmero de steps do nome
                    try:
                        steps = model_name.split('_')[2]  # v3brutal_simpledirecttraining_500000_steps...
                    except:
                        steps = model_name
                    best_model_sharpe = steps

                if metrics.get('total_real_pnl', -99999) > best_pnl:
                    best_pnl = metrics['total_real_pnl']
                    model_name = os.path.basename(checkpoint_path)
                    try:
                        steps = model_name.split('_')[2]
                    except:
                        steps = model_name
                    best_model_pnl = steps
        
        except Exception as e:
            print(f"âŒ Erro avaliando {os.path.basename(checkpoint_path)}: {e}")
            traceback.print_exc()
    
    end_time = datetime.now()
    total_time = end_time - start_time
    
    print("\\n" + "=" * 60)
    print("ğŸ† RESULTADOS FINAIS - V3 BRUTAL PROGRESSIVE")
    print("=" * 60)
    print(f"â±ï¸ Tempo total: {total_time}")
    print(f"ğŸš€ Velocidade: {len(CHECKPOINTS_TO_TEST) * NUM_EPISODES / total_time.total_seconds():.2f} ep/s")
    print(f"ğŸ¥‡ Melhor Sharpe: {best_model_sharpe} ({best_sharpe:.4f})")
    print(f"ğŸ’° Melhor PnL: {best_model_pnl} (${best_pnl:.2f})")
    
    # ğŸ”¥ RELATÃ“RIO DETALHADO DE CADA MODELO
    print("\\n" + "ğŸ“Š RANKING POR SHARPE RATIO:")
    print("-" * 60)
    
    # Ordenar por Sharpe ratio
    sorted_results = sorted(all_results.items(), key=lambda x: x[1].get('sharpe_ratio', -999), reverse=True)
    
    for i, (model_path, metrics) in enumerate(sorted_results[:10]):  # Top 10
        model_name = os.path.basename(model_path)
        try:
            steps = model_name.split('_')[2]  # Extrair steps
            print(f"\\nğŸ·ï¸ {steps} STEPS:")
            print(f"  ğŸ“ˆ Return mÃ©dio: {metrics['mean_return']:.4f}")
            print(f"  ğŸ“Š Sharpe: {metrics['sharpe_ratio']:.4f}")
            print(f"  ğŸ’° PnL mÃ©dio: ${metrics['mean_portfolio_pnl']:.2f}")
            print(f"  ğŸ’¸ PnL total: ${metrics['total_real_pnl']:.2f}")
            print(f"  ğŸ¯ Win Rate: {metrics['real_win_rate']:.1f}%")
            print(f"  ğŸ“ˆ Trades/ep: {metrics['avg_trades_per_episode']:.1f}")
            print(f"  ğŸ¯ Activity: {metrics['activity_rate']:.1f}%")
        except:
            print(f"\\nğŸ·ï¸ {model_name}:")
            print(f"  ğŸ“Š Sharpe: {metrics['sharpe_ratio']:.4f}")
            print(f"  ğŸ’° PnL total: ${metrics['total_real_pnl']:.2f}")
    
    print("\\n" + "âœ… AVALIAÃ‡ÃƒO MODELO FINAL CONCLUÃDA!")
    print("ğŸ¯ AnÃ¡lise do modelo final V3 Brutal 5M steps finalizada!")
    return all_results

if __name__ == "__main__":
    try:
        results = main()
        print("\\nğŸ¯ V3 BRUTAL PROGRESSIVE - Resultados salvos em memÃ³ria.")
        print("ğŸ“ˆ Use os dados para identificar o melhor checkpoint!")
    except Exception as e:
        print(f"âŒ Erro durante avaliaÃ§Ã£o: {e}")
        traceback.print_exc()