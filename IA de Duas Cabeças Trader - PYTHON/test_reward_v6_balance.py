"""
Teste de Balanceamento - Reward V6 Pro com B√¥nus de Atividade
Verifica propor√ß√µes e magnitudes dos componentes do reward
"""

import numpy as np
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from trading_framework.rewards.reward_daytrade_v6_pro import RewardV6Pro

class MockEnv:
    def __init__(self):
        self.portfolio_value = 500.0
        self.positions = []
        self.trades = []
        self.current_step = 0
        self.steps_since_last_trade = 0
        self.max_lot_size = 0.03
        # Mock OHLC data
        self.df = type('MockDF', (), {})()
        self.df.high_5m = np.array([2050.0] * 100)
        self.df.low_5m = np.array([2040.0] * 100)

def test_scenario(reward_system, scenario_name, env, action, old_state, expected_behavior):
    """Testa um cen√°rio espec√≠fico"""
    print(f"\nüîç {scenario_name}")
    print("-" * 50)
    
    reward, info, done = reward_system.calculate_reward_and_info(env, action, old_state)
    
    print(f"Action magnitude: {info.get('action_magnitude', 0.0):.3f}")
    print(f"Steps inactive: {info.get('steps_inactive', 0)}")
    print()
    
    components = {
        'PnL': info.get('base_pnl', 0.0),
        'Close': info.get('close_component', 0.0),
        'Risk': info.get('risk_component', 0.0),
        'Activity': info.get('activity_component', 0.0)
    }
    
    total_abs = sum(abs(v) for v in components.values())
    
    for name, value in components.items():
        percentage = (abs(value) / total_abs * 100) if total_abs > 0 else 0
        print(f"{name:8}: {value:+7.4f} ({percentage:5.1f}%)")
    
    print(f"{'TOTAL':8}: {reward:+7.4f}")
    print(f"Expected: {expected_behavior}")
    
    return reward, components

def main():
    print("üß™ TESTE DE BALANCEAMENTO - REWARD V6 PRO")
    print("=" * 60)
    
    reward_system = RewardV6Pro(initial_balance=500.0)
    
    # Cen√°rio 1: Mercado Lateral + A√ß√£o Decisiva
    print("\nüìä CEN√ÅRIO 1: Mercado Lateral + A√ß√£o Decisiva")
    env1 = MockEnv()
    env1.portfolio_value = 500.0  # Sem mudan√ßa no equity
    env1.steps_since_last_trade = 5  # Pouco tempo inativo
    action1 = np.array([0.8, 0.2, -0.3])  # A√ß√£o forte
    old_state1 = {'positions': []}
    
    reward1, comp1 = test_scenario(
        reward_system, "A√ß√£o Decisiva sem PnL", 
        env1, action1, old_state1,
        "Activity deve dominar quando PnL = 0"
    )
    
    # Cen√°rio 2: Mercado Lateral + Inatividade Prolongada
    print("\nüìä CEN√ÅRIO 2: Mercado Lateral + Inatividade Prolongada")
    env2 = MockEnv()
    env2.portfolio_value = 500.0
    env2.steps_since_last_trade = 100  # Muita inatividade
    action2 = np.array([0.12, -0.08, 0.05])  # A√ß√£o moderada
    old_state2 = {'positions': []}
    
    reward2, comp2 = test_scenario(
        reward_system, "A√ß√£o Moderada + Inatividade", 
        env2, action2, old_state2,
        "Activity com multiplicador de inatividade"
    )
    
    # Cen√°rio 3: PnL Positivo + A√ß√£o
    print("\nüìä CEN√ÅRIO 3: PnL Positivo + A√ß√£o")
    env3 = MockEnv()
    env3.portfolio_value = 510.0  # +$10 profit
    env3.steps_since_last_trade = 20
    action3 = np.array([0.6, -0.4, 0.1])  # A√ß√£o decisiva
    old_state3 = {'positions': []}
    reward_system.last_portfolio_value = 500.0  # Reset para calcular delta
    
    reward3, comp3 = test_scenario(
        reward_system, "PnL Positivo + A√ß√£o", 
        env3, action3, old_state3,
        "PnL deve dominar, Activity como suporte"
    )
    
    # Cen√°rio 4: Ina√ß√£o Completa
    print("\nüìä CEN√ÅRIO 4: Ina√ß√£o Completa")
    env4 = MockEnv()
    env4.portfolio_value = 500.0
    env4.steps_since_last_trade = 50
    action4 = np.array([0.01, -0.005, 0.008])  # Praticamente sem a√ß√£o
    old_state4 = {'positions': []}
    reward_system.last_portfolio_value = 500.0
    
    reward4, comp4 = test_scenario(
        reward_system, "Ina√ß√£o Completa", 
        env4, action4, old_state4,
        "Penalidade por ina√ß√£o + multiplicador"
    )
    
    # Cen√°rio 5: PnL Negativo + Posi√ß√£o com Risco
    print("\nüìä CEN√ÅRIO 5: PnL Negativo + Posi√ß√£o com Risco")
    env5 = MockEnv()
    env5.portfolio_value = 485.0  # -$15 loss
    env5.steps_since_last_trade = 10
    env5.positions = [{
        'type': 'long',
        'entry_price': 2045.0,
        'entry_step': env5.current_step - 60,  # 60 steps ago
        'lot_size': 0.03  # Max lot
    }]
    action5 = np.array([0.0, 0.0, -0.9])  # Tentativa de fechar
    old_state5 = {'positions': env5.positions}
    reward_system.last_portfolio_value = 500.0
    
    reward5, comp5 = test_scenario(
        reward_system, "Loss + Posi√ß√£o de Risco", 
        env5, action5, old_state5,
        "Risk penalty dominante, Activity tentando compensar"
    )
    
    # An√°lise Final
    print("\n" + "="*60)
    print("üìà AN√ÅLISE DE BALANCEAMENTO")
    print("="*60)
    
    scenarios = [
        ("Lateral + A√ß√£o", reward1, comp1),
        ("Lateral + Inatividade", reward2, comp2), 
        ("PnL+ + A√ß√£o", reward3, comp3),
        ("Ina√ß√£o Total", reward4, comp4),
        ("Loss + Risco", reward5, comp5)
    ]
    
    print(f"{'Cen√°rio':<20} {'Total':<8} {'PnL%':<6} {'Act%':<6} {'Risk%':<7} {'Balance'}")
    print("-" * 70)
    
    for name, total_reward, components in scenarios:
        total_abs = sum(abs(v) for v in components.values()) or 1
        pnl_pct = abs(components['PnL']) / total_abs * 100
        act_pct = abs(components['Activity']) / total_abs * 100  
        risk_pct = abs(components['Risk']) / total_abs * 100
        
        # Avaliar balanceamento
        if pnl_pct < 20 and act_pct > 40:
            balance = "‚úÖ Act-Dom"
        elif pnl_pct > 60:
            balance = "‚úÖ PnL-Dom"
        elif risk_pct > 50:
            balance = "‚ö†Ô∏è Risk-Dom"
        else:
            balance = "‚úÖ Balanced"
            
        print(f"{name:<20} {total_reward:<+8.3f} {pnl_pct:<6.1f} {act_pct:<6.1f} {risk_pct:<7.1f} {balance}")
    
    # Recomenda√ß√µes
    print("\nüéØ RECOMENDA√á√ïES:")
    print("‚Ä¢ Activity domina em mercados laterais (‚úÖ)")
    print("‚Ä¢ PnL mant√©m domin√¢ncia em tend√™ncias (‚úÖ)")
    print("‚Ä¢ Multiplicador de inatividade funcional (‚úÖ)")
    print("‚Ä¢ Penalidades por ina√ß√£o balanceadas (‚úÖ)")
    
    avg_activity_impact = np.mean([abs(comp['Activity']) for _, _, comp in scenarios])
    print(f"‚Ä¢ Impacto m√©dio do Activity: {avg_activity_impact:.4f}")
    
    if avg_activity_impact < 0.001:
        print("‚ö†Ô∏è Activity muito fraco - aumentar w_activity")
    elif avg_activity_impact > 0.05:
        print("‚ö†Ô∏è Activity muito forte - reduzir w_activity")  
    else:
        print("‚úÖ Activity bem balanceado")

if __name__ == "__main__":
    main()