#!/usr/bin/env python3
"""
ğŸ” INVESTIGADOR DE DIFICULDADE DO DATASET V2
Analisa se o dataset estÃ¡ artificialmente fÃ¡cil
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime

def investigate_dataset_difficulty():
    """Investigar dificuldade real do dataset V2"""
    print("ğŸ” INVESTIGAÃ‡ÃƒO: DATASET V2 MUITO FÃCIL?")
    print("="*60)
    
    dataset_path = "data/GC=F_HYBRID_V2_3Y_1MIN_20250911_200306.csv"
    
    print(f"ğŸ“‚ Carregando dataset: {len(dataset_path)} chars")
    df = pd.read_csv(dataset_path, nrows=100000)  # Primeiras 100k para velocidade
    print(f"âœ… Carregado: {len(df):,} linhas")
    
    # 1. ANÃLISE DE PADRÃ•ES PREVISÃVEIS
    print(f"\nğŸ¯ TESTE 1: PADRÃ•ES PREVISÃVEIS")
    print("-"*40)
    
    # Calcular retornos
    df['returns'] = df['close'].pct_change().fillna(0)
    
    # SequÃªncias de mesmo sinal (tendÃªncia)
    df['return_sign'] = np.sign(df['returns'])
    
    # Contar sequÃªncias longas de mesmo sinal
    sequences = []
    current_sign = 0
    current_length = 0
    
    for sign in df['return_sign']:
        if sign == current_sign and sign != 0:
            current_length += 1
        else:
            if current_length > 5:  # SequÃªncias > 5 sÃ£o suspeitas
                sequences.append(current_length)
            current_sign = sign
            current_length = 1
    
    if sequences:
        avg_sequence = np.mean(sequences)
        max_sequence = max(sequences)
        print(f"âš ï¸ SUSPEITO: {len(sequences)} sequÃªncias longas (>5)")
        print(f"   SequÃªncia mÃ©dia: {avg_sequence:.1f} barras")
        print(f"   SequÃªncia mÃ¡xima: {max_sequence} barras")
        if avg_sequence > 15:
            print(f"âŒ MUITO PREVISÃVEL: SequÃªncias muito longas")
    else:
        print(f"âœ… OK: Sem sequÃªncias suspeitas")
    
    # 2. ANÃLISE DE VOLATILIDADE ARTIFICIAL
    print(f"\nğŸ“Š TESTE 2: VOLATILIDADE REALÃSTICA")
    print("-"*40)
    
    # Volatilidade rolling
    df['vol_60'] = df['returns'].rolling(60).std() * 100
    
    vol_stats = df['vol_60'].dropna().describe()
    print(f"Volatilidade 60min:")
    print(f"   MÃ©dia: {vol_stats['mean']:.4f}%")
    print(f"   Std: {vol_stats['std']:.4f}%")
    print(f"   Min: {vol_stats['min']:.4f}%")
    print(f"   Max: {vol_stats['max']:.4f}%")
    
    # Volatilidade muito baixa Ã© suspeita
    if vol_stats['mean'] < 0.01:
        print(f"âŒ SUSPEITO: Volatilidade muito baixa ({vol_stats['mean']:.4f}%)")
    elif vol_stats['std'] < 0.005:
        print(f"âŒ SUSPEITO: Volatilidade muito constante (std: {vol_stats['std']:.4f}%)")
    else:
        print(f"âœ… VOLATILIDADE OK")
    
    # 3. TESTE DE AUTOCORRELAÃ‡ÃƒO (PadrÃµes repetitivos)
    print(f"\nğŸ”„ TESTE 3: AUTOCORRELAÃ‡ÃƒO (PADRÃ•ES CÃCLICOS)")
    print("-"*40)
    
    # AutocorrelaÃ§Ã£o dos retornos
    returns_clean = df['returns'].dropna()
    
    autocorrs = []
    for lag in [1, 5, 10, 30, 60]:
        if len(returns_clean) > lag:
            corr = returns_clean.corr(returns_clean.shift(lag))
            autocorrs.append((lag, corr))
            print(f"   Lag {lag:2d}: {corr:.4f}")
    
    # AutocorrelaÃ§Ã£o alta = padrÃµes previsÃ­veis
    high_corrs = [corr for lag, corr in autocorrs if abs(corr) > 0.1]
    if high_corrs:
        print(f"âŒ SUSPEITO: {len(high_corrs)} autocorrelaÃ§Ãµes altas (>0.1)")
    else:
        print(f"âœ… OK: AutocorrelaÃ§Ãµes baixas")
    
    # 4. TESTE DE GAPS E SALTOS IRREAIS
    print(f"\nâš¡ TESTE 4: GAPS E SALTOS IRREAIS")
    print("-"*40)
    
    # Calcular mudanÃ§as percentuais extremas
    abs_returns = np.abs(df['returns'])
    extreme_moves = abs_returns[abs_returns > 0.01]  # >1%
    
    print(f"Movimentos >1%: {len(extreme_moves)} ({len(extreme_moves)/len(df)*100:.2f}%)")
    
    if len(extreme_moves) == 0:
        print(f"âŒ SUSPEITO: Nenhum movimento >1% em {len(df):,} barras")
    elif len(extreme_moves) < len(df) * 0.001:  # <0.1%
        print(f"âŒ SUSPEITO: PouquÃ­ssimos movimentos grandes ({len(extreme_moves)/len(df)*100:.3f}%)")
    else:
        print(f"âœ… OK: Movimentos grandes presentes")
    
    # 5. TESTE DE SPREAD BID-ASK (Realismo)
    print(f"\nğŸ’° TESTE 5: SPREAD E REALISMO DE TRADING")
    print("-"*40)
    
    # Verificar se spread existe e Ã© realista
    if 'spread' in df.columns:
        spread_stats = df['spread'].describe()
        print(f"Spread mÃ©dio: {spread_stats['mean']:.4f}")
        
        if spread_stats['mean'] == 0:
            print(f"âŒ IRREAL: Spread sempre 0 (sem custos de trading)")
        else:
            print(f"âœ… OK: Spread presente")
    
    # 6. PADRÃ•ES HORÃRIOS ARTIFICIAIS
    print(f"\nâ° TESTE 6: PADRÃ•ES HORÃRIOS ARTIFICIAIS")
    print("-"*40)
    
    df['time'] = pd.to_datetime(df['time'])
    df['hour'] = df['time'].dt.hour
    
    hourly_vol = df.groupby('hour')['returns'].std()
    vol_range = hourly_vol.max() - hourly_vol.min()
    
    print(f"Range volatilidade horÃ¡ria: {vol_range:.6f}")
    
    if vol_range < 0.0001:
        print(f"âŒ SUSPEITO: Volatilidade muito uniforme por hora")
    else:
        print(f"âœ… OK: VariaÃ§Ã£o horÃ¡ria presente")
    
    # 7. TESTE DE REGIME ÃšNICO (Falta de bear markets)
    print(f"\nğŸ“ˆ TESTE 7: REGIMES DE MERCADO")
    print("-"*40)
    
    # TendÃªncias de longo prazo
    df['ma_200'] = df['close'].rolling(200).mean()
    df['above_ma200'] = df['close'] > df['ma_200']
    
    pct_above_ma200 = df['above_ma200'].mean() * 100
    print(f"% tempo acima MA200: {pct_above_ma200:.1f}%")
    
    if pct_above_ma200 > 80:
        print(f"âŒ SUSPEITO: Sempre bull market ({pct_above_ma200:.1f}%)")
    elif pct_above_ma200 < 20:
        print(f"âŒ SUSPEITO: Sempre bear market ({pct_above_ma200:.1f}%)")
    else:
        print(f"âœ… OK: Regimes variados")
    
    # RESUMO FINAL
    print(f"\n" + "="*60)
    print(f"ğŸ¯ RESUMO DA INVESTIGAÃ‡ÃƒO:")
    print(f"="*60)
    
    issues = []
    if sequences and avg_sequence > 15:
        issues.append(f"SequÃªncias previsÃ­veis (mÃ©dia {avg_sequence:.1f})")
    if vol_stats['mean'] < 0.01:
        issues.append(f"Volatilidade baixa ({vol_stats['mean']:.4f}%)")
    if high_corrs:
        issues.append(f"{len(high_corrs)} autocorrelaÃ§Ãµes altas")
    if len(extreme_moves) < len(df) * 0.001:
        issues.append("Poucos movimentos extremos")
    if 'spread' in df.columns and df['spread'].mean() == 0:
        issues.append("Spread zero (irreal)")
    if vol_range < 0.0001:
        issues.append("Volatilidade horÃ¡ria uniforme")
    if pct_above_ma200 > 80 or pct_above_ma200 < 20:
        issues.append(f"Regime Ãºnico ({pct_above_ma200:.1f}% acima MA200)")
    
    if not issues:
        print(f"ğŸ‰ DATASET REALISTA: Nenhuma irregularidade encontrada")
        return "REALISTIC"
    elif len(issues) <= 2:
        print(f"âš ï¸ DATASET SUSPEITO: {len(issues)} problemas encontrados")
        for issue in issues:
            print(f"   - {issue}")
        return "SUSPICIOUS"
    else:
        print(f"âŒ DATASET ARTIFICIAL: {len(issues)} problemas sÃ©rios")
        for issue in issues:
            print(f"   - {issue}")
        print(f"\nğŸ”¥ CONCLUSÃƒO: Dataset V2 estÃ¡ FACILITANDO o treinamento!")
        print(f"   Win rate 92% Ã© explicado por dataset previsÃ­vel/artificial")
        return "ARTIFICIAL"

if __name__ == "__main__":
    result = investigate_dataset_difficulty()
    print(f"\nğŸ VEREDICTO FINAL: {result}")