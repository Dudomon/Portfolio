#!/usr/bin/env python3
"""
üîß GRADIENT CALLBACK
Callback para integra√ß√£o autom√°tica do monitoramento de gradientes
com Stable-Baselines3 e RecurrentPPO
"""

import os
import sys
import numpy as np
from stable_baselines3.common.callbacks import BaseCallback
from typing import Dict, Optional

class GradientHealthCallback(BaseCallback):
    """
    üîç Callback para monitoramento autom√°tico de gradientes
    
    Funcionalidades:
    - Monitora sa√∫de dos gradientes em tempo real
    - Aplica corre√ß√µes autom√°ticas quando necess√°rio
    - Gera alertas para problemas cr√≠ticos
    - Salva relat√≥rios detalhados
    """
    
    def __init__(self, 
                 check_frequency: int = 500,
                 auto_fix: bool = True,
                 alert_threshold: float = 0.3,
                 log_dir: str = "gradient_logs",
                 verbose: int = 1):
        
        super().__init__(verbose)
        
        self.check_frequency = check_frequency
        self.auto_fix = auto_fix
        self.alert_threshold = alert_threshold
        self.log_dir = log_dir
        
        # Status
        self.monitoring_active = False
        self.total_corrections = 0
        self.last_health_score = 1.0
        self.critical_alerts = 0
        
        # Criar diret√≥rio de logs
        os.makedirs(log_dir, exist_ok=True)
    
    def _on_training_start(self) -> None:
        """Inicializar monitoramento no in√≠cio do treinamento"""
        try:
            # Verificar se o modelo suporta monitoramento de gradientes
            if hasattr(self.model.policy, 'setup_gradient_monitoring'):
                success = self.model.policy.setup_gradient_monitoring(
                    check_frequency=self.check_frequency,
                    log_dir=self.log_dir
                )
                
                if success:
                    self.monitoring_active = True
                    if self.verbose >= 1:
                        print(f"‚úÖ Gradient Health Monitoring ativado")
                        print(f"   Check frequency: {self.check_frequency} steps")
                        print(f"   Auto-fix: {self.auto_fix}")
                        print(f"   Alert threshold: {self.alert_threshold}")
                else:
                    if self.verbose >= 1:
                        print("‚ö†Ô∏è Gradient Health Monitoring n√£o p√¥de ser ativado")
            else:
                if self.verbose >= 1:
                    print("‚ö†Ô∏è Modelo n√£o suporta Gradient Health Monitoring")
                    
        except Exception as e:
            if self.verbose >= 1:
                print(f"‚ùå Erro ao inicializar Gradient Health Monitoring: {e}")
    
    def _on_step(self) -> bool:
        """Verificar gradientes a cada step"""
        if not self.monitoring_active:
            return True
        
        try:
            # Verificar e corrigir gradientes
            if hasattr(self.model.policy, 'check_and_fix_gradients'):
                health_report = self.model.policy.check_and_fix_gradients(self.num_timesteps)
                
                if health_report:
                    health_score = health_report.get('health_score', 1.0)
                    self.last_health_score = health_score
                    
                    # Contar corre√ß√µes
                    if 'corrections_applied' in health_report:
                        self.total_corrections += health_report['corrections_applied']
                    
                    # Alertas cr√≠ticos
                    if health_score < self.alert_threshold:
                        self.critical_alerts += 1
                        
                        if self.verbose >= 1:
                            print(f"\n‚ö†Ô∏è ALERTA CR√çTICO - Step {self.num_timesteps}")
                            print(f"   Sa√∫de dos gradientes: {health_score:.3f}")
                            print(f"   Problemas detectados: {len(health_report.get('problematic_layers', []))}")
                            
                            # Mostrar recomenda√ß√µes principais
                            for rec in health_report.get('recommendations', [])[:2]:
                                print(f"   üí° {rec}")
                    
                    # Log peri√≥dico de status
                    elif self.num_timesteps % (self.check_frequency * 10) == 0 and self.verbose >= 2:
                        print(f"üîç Step {self.num_timesteps}: Gradient health = {health_score:.3f}")
            
        except Exception as e:
            if self.verbose >= 1:
                print(f"‚ùå Erro no monitoramento de gradientes (step {self.num_timesteps}): {e}")
        
        return True
    
    def _on_training_end(self) -> None:
        """Finalizar monitoramento e gerar relat√≥rio final"""
        if not self.monitoring_active:
            return
        
        try:
            if self.verbose >= 1:
                print(f"\nüìä RESUMO DO GRADIENT HEALTH MONITORING")
                print(f"=" * 50)
            
            # Obter resumo final
            if hasattr(self.model.policy, 'get_gradient_health_summary'):
                summary = self.model.policy.get_gradient_health_summary()
                
                if self.verbose >= 1:
                    print(f"Status final: {summary.get('status', 'unknown')}")
                    print(f"Sa√∫de m√©dia: {summary.get('avg_health_score', 0):.3f}")
                    print(f"Total de corre√ß√µes: {summary.get('total_corrections', 0)}")
                    print(f"Alertas cr√≠ticos: {self.critical_alerts}")
                    
                    if summary.get('most_problematic_layers'):
                        print(f"Layers mais problem√°ticos:")
                        for layer in summary['most_problematic_layers'][:3]:
                            print(f"  - {layer}")
            
            # Salvar relat√≥rio detalhado
            if hasattr(self.model.policy, 'save_gradient_report'):
                report_file = self.model.policy.save_gradient_report()
                if report_file and self.verbose >= 1:
                    print(f"üìÑ Relat√≥rio detalhado salvo: {report_file}")
            
            if self.verbose >= 1:
                print(f"=" * 50)
                
        except Exception as e:
            if self.verbose >= 1:
                print(f"‚ùå Erro ao finalizar monitoramento: {e}")
    
    def get_monitoring_stats(self) -> Dict:
        """üìä Obter estat√≠sticas do monitoramento"""
        return {
            'monitoring_active': self.monitoring_active,
            'total_corrections': self.total_corrections,
            'last_health_score': self.last_health_score,
            'critical_alerts': self.critical_alerts,
            'check_frequency': self.check_frequency
        }

def create_gradient_callback(**kwargs) -> GradientHealthCallback:
    """üè≠ Factory function para criar callback de gradientes"""
    return GradientHealthCallback(**kwargs)

# Exemplo de uso
if __name__ == "__main__":
    print("üîß Gradient Health Callback - Exemplo de uso:")
    print()
    print("# Integra√ß√£o com treinamento:")
    print("from gradient_callback import create_gradient_callback")
    print()
    print("# Criar callback")
    print("gradient_callback = create_gradient_callback(")
    print("    check_frequency=500,  # Verificar a cada 500 steps")
    print("    auto_fix=True,        # Aplicar corre√ß√µes autom√°ticas")
    print("    alert_threshold=0.3,  # Alertar se sa√∫de < 0.3")
    print("    verbose=1             # N√≠vel de logging")
    print(")")
    print()
    print("# Usar no treinamento:")
    print("model.learn(")
    print("    total_timesteps=1000000,")
    print("    callback=[gradient_callback, other_callbacks...]")
    print(")")
    print()
    print("‚úÖ Callback pronto para uso!")