import pandas as pd
import numpy as np

def verify_dataset_quality():
    print("üîç VERIFICA√á√ÉO COMPLETA DE QUALIDADE DO DATASET")
    print("=" * 60)
    
    # Carregar dataset
    df = pd.read_csv('data/GOLD_TRADING_READY_2M_ENHANCED_INDICATORS.csv')
    
    # Features originais vs indicadores
    original_features = ['timestamp', 'open', 'high', 'low', 'close', 'volume', 'regime']
    indicadores = [col for col in df.columns if col not in original_features]
    
    print(f"üìä ESTRUTURA DO DATASET:")
    print(f"   ‚Ä¢ Total de linhas: {len(df):,}")
    print(f"   ‚Ä¢ Total de colunas: {len(df.columns)}")
    print(f"   ‚Ä¢ Features originais: {len(original_features)}")
    print(f"   ‚Ä¢ Indicadores t√©cnicos: {len(indicadores)}")
    
    print(f"\nüîß INDICADORES T√âCNICOS ADICIONADOS ({len(indicadores)}):")
    for i, ind in enumerate(indicadores, 1):
        print(f"   {i:2d}. {ind}")
    
    print(f"\nüìä QUALIDADE DOS DADOS:")
    print(f"   ‚Ä¢ Valores NaN: {df.isnull().sum().sum()}")
    print(f"   ‚Ä¢ Valores infinitos: {df.isin([float('inf'), -float('inf')]).sum().sum()}")
    print(f"   ‚Ä¢ Duplicatas: {df.duplicated().sum()}")
    
    print(f"\nüìà SAMPLE DE RANGES (primeiros 5 indicadores):")
    for ind in indicadores[:5]:
        min_val = df[ind].min()
        max_val = df[ind].max()
        mean_val = df[ind].mean()
        print(f"   {ind}: [{min_val:.4f}, {max_val:.4f}] (m√©dia: {mean_val:.4f})")
    
    print(f"\nüéØ REGIME DISTRIBUTION:")
    regime_counts = df['regime'].value_counts()
    for regime, count in regime_counts.items():
        pct = (count / len(df)) * 100
        print(f"   {regime}: {count:,} ({pct:.1f}%)")
    
    # Verifica√ß√£o de continuidade temporal
    print(f"\n‚è∞ CONTINUIDADE TEMPORAL:")
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    time_diffs = df['timestamp'].diff().dropna()
    print(f"   ‚Ä¢ Intervalo predominante: {time_diffs.mode()[0]}")
    print(f"   ‚Ä¢ Gaps temporais: {(time_diffs != time_diffs.mode()[0]).sum()}")
    
    # Verifica√ß√£o de correla√ß√µes extremas
    print(f"\nüîó CORRELA√á√ïES ALTAS (>0.95):")
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    corr_matrix = df[numeric_cols].corr()
    high_corr = []
    
    for i in range(len(corr_matrix.columns)):
        for j in range(i+1, len(corr_matrix.columns)):
            corr_val = abs(corr_matrix.iloc[i, j])
            if corr_val > 0.95:
                col1 = corr_matrix.columns[i]
                col2 = corr_matrix.columns[j]
                high_corr.append((col1, col2, corr_val))
    
    if high_corr:
        for col1, col2, corr_val in high_corr[:5]:  # Top 5
            print(f"   {col1} ‚Üî {col2}: {corr_val:.3f}")
    else:
        print("   ‚úÖ Nenhuma correla√ß√£o extrema detectada")
    
    print(f"\n‚úÖ DATASET QUALITY SCORE:")
    quality_score = 100
    
    # Dedu√ß√µes por problemas
    if df.isnull().sum().sum() > 0:
        quality_score -= 20
        print(f"   -20: Valores NaN presentes")
    
    if df.isin([float('inf'), -float('inf')]).sum().sum() > 0:
        quality_score -= 30
        print(f"   -30: Valores infinitos presentes")
    
    if df.duplicated().sum() > 100:
        quality_score -= 10
        print(f"   -10: Muitas duplicatas")
    
    if len(high_corr) > 10:
        quality_score -= 15
        print(f"   -15: Muitas correla√ß√µes extremas")
    
    if len(indicadores) < 25:
        quality_score -= 25
        print(f"   -25: Poucos indicadores t√©cnicos")
    
    print(f"\nüèÜ QUALITY SCORE: {quality_score}/100")
    
    if quality_score >= 90:
        print("‚úÖ DATASET 100% PRONTO PARA TREINAMENTO!")
        return True
    elif quality_score >= 80:
        print("‚ö†Ô∏è Dataset bom, pequenos ajustes recomendados")
        return True
    else:
        print("‚ùå Dataset precisa de corre√ß√µes antes do treinamento")
        return False

if __name__ == "__main__":
    success = verify_dataset_quality()
    exit(0 if success else 1)