# ðŸŽ¯ TP TARGET ZONES: Ensinar Modelo a Mirar em Alvos Realistas

**Data:** 2025-10-03
**Problema:** TPs nunca sÃ£o atingidos (modelo mira muito longe)
**SoluÃ§Ã£o:** Adicionar feature que identifica ZONAS DE TP (resistÃªncias prÃ³ximas)

---

## ðŸ’¡ CONCEITO: LÃ“GICA REVERSA

Se modelo "enxerga" **distÃ¢ncia para suporte/resistÃªncia**:

### Para SL (jÃ¡ proposto):
- **LONG:** SL deve ficar ABAIXO do suporte mais prÃ³ximo
- **SHORT:** SL deve ficar ACIMA da resistÃªncia mais prÃ³xima
- **Feature:** `support_resistance` = distÃ¢ncia para zona RUIM de SL

### Para TP (NOVO):
- **LONG:** TP deve mirar NA resistÃªncia mais prÃ³xima
- **SHORT:** TP deve mirar NO suporte mais prÃ³ximo
- **Feature:** `tp_target_zones` = distÃ¢ncia para zona BOA de TP

---

## âœ… NOVA FEATURE: `tp_target_zones`

### SUBSTITUIR: `breakout_strength` â†’ `tp_target_zones`

**LocalizaÃ§Ã£o:** cherry.py linha 4363-4374

```python
elif feature_name == 'breakout_strength':
    # ðŸŽ¯ TP TARGET ZONES: Identifica zonas REALISTAS para TP
    # Calcula distÃ¢ncia para resistÃªncias/suportes mais prÃ³ximos ACIMA/ABAIXO do preÃ§o
    # Valor BAIXO = resistÃªncia/suporte PRÃ“XIMO = zona BOA para TP
    # Valor ALTO = resistÃªncia/suporte DISTANTE = zona RUIM para TP

    lookback_swing = 20
    high_series = pd.Series(high_1m)
    low_series = pd.Series(low_1m)

    # Encontrar swing highs (resistÃªncias) e swing lows (suportes)
    swing_high = high_series.rolling(window=lookback_swing, center=True).max()
    swing_low = low_series.rolling(window=lookback_swing, center=True).min()

    # Para cada ponto, calcular distÃ¢ncia para a RESISTÃŠNCIA mais prÃ³xima ACIMA
    distance_to_resistance_above = np.full(len(close_1m), np.inf)
    for i in range(len(close_1m)):
        # Procurar swing highs ACIMA do preÃ§o atual (Ãºltimos 50 perÃ­odos)
        start_idx = max(0, i - 50)
        relevant_swings = swing_high[start_idx:i+1]
        above_price = relevant_swings[relevant_swings > close_1m[i]]

        if len(above_price) > 0:
            # ResistÃªncia mais prÃ³xima ACIMA = alvo para TP de LONG
            distance_to_resistance_above[i] = above_price.iloc[0] - close_1m[i]

    # Calcular distÃ¢ncia para SUPORTE mais prÃ³ximo ABAIXO
    distance_to_support_below = np.full(len(close_1m), np.inf)
    for i in range(len(close_1m)):
        start_idx = max(0, i - 50)
        relevant_swings = swing_low[start_idx:i+1]
        below_price = relevant_swings[relevant_swings < close_1m[i]]

        if len(below_price) > 0:
            # Suporte mais prÃ³ximo ABAIXO = alvo para TP de SHORT
            distance_to_support_below[i] = close_1m[i] - below_price.iloc[-1]

    # Combinar ambas (mÃ©dia para contexto neutro antes de abrir posiÃ§Ã£o)
    combined_distance = np.minimum(distance_to_resistance_above, distance_to_support_below)

    # Normalizar pela ATR (distÃ¢ncia relativa Ã  volatilidade)
    atr_14 = pd.Series(high_1m - low_1m).rolling(window=14).mean().fillna(1).values
    tp_zone_distance = combined_distance / (atr_14 + 1e-8)

    # Valores BAIXOS = alvo PRÃ“XIMO (BOM para TP - realista)
    # Valores ALTOS = alvo DISTANTE (RUIM para TP - irrealista)
    # Inverter para facilitar interpretaÃ§Ã£o: 1.0 = alvo prÃ³ximo, 0.0 = alvo distante
    tp_target_quality = 1.0 - np.clip(tp_zone_distance / 5.0, 0.0, 1.0)

    self.df.loc[:, 'breakout_strength'] = tp_target_quality
```

---

## ðŸ”„ FEATURES COMPLEMENTARES: SL + TP

Agora temos **DUAS features complementares**:

### 1. `support_resistance` (renomear internamente para `sl_zone_quality`)
**Linha 4386-4397:**
```python
elif feature_name == 'support_resistance':
    # ðŸŽ¯ SL ZONE QUALITY: Zonas seguras para SL
    # DistÃ¢ncia para swing high/low mais prÃ³ximo (zona RUIM para SL)

    # [cÃ³digo jÃ¡ proposto anteriormente - calcular distÃ¢ncia para S/R]

    # Valores ALTOS = longe de S/R (zona BOA para SL)
    # Valores BAIXOS = perto de S/R (zona RUIM para SL - hit fÃ¡cil)
    sl_zone_quality = [...]  # cÃ³digo anterior
    self.df.loc[:, 'support_resistance'] = sl_zone_quality
```

### 2. `breakout_strength` (renomear internamente para `tp_target_zones`)
**Linha 4363-4374:**
```python
elif feature_name == 'breakout_strength':
    # ðŸŽ¯ TP TARGET ZONES: Zonas realistas para TP
    # DistÃ¢ncia para resistÃªncia (LONG) ou suporte (SHORT) mais prÃ³ximo

    # [cÃ³digo acima - calcular distÃ¢ncia para prÃ³ximo alvo]

    # Valores ALTOS = alvo PRÃ“XIMO (zona BOA para TP - realista)
    # Valores BAIXOS = alvo DISTANTE (zona RUIM para TP - irrealista)
    tp_target_quality = [...]  # cÃ³digo acima
    self.df.loc[:, 'breakout_strength'] = tp_target_quality
```

---

## ðŸŽ¯ COMO O MODELO USA ESSAS FEATURES?

### Exemplo: LONG em $2000

**SituaÃ§Ã£o do mercado:**
- Suporte em $1988 (12 pontos abaixo)
- ResistÃªncia em $2015 (15 pontos acima)
- ATR = 10 pontos

**Features calculadas:**
```python
# SL ZONE QUALITY (support_resistance)
distance_to_support = 12 pontos
sl_zone_quality = 12 / 10 = 1.2 (normalizado: 0.40)
# 0.40 = BAIXO = suporte prÃ³ximo = zona RUIM para SL muito apertado

# TP TARGET ZONES (breakout_strength)
distance_to_resistance = 15 pontos
tp_target_distance = 15 / 10 = 1.5 ATR
tp_target_quality = 1.0 - (1.5 / 5.0) = 0.70
# 0.70 = ALTO = resistÃªncia prÃ³xima = zona BOA para TP
```

**Modelo aprende:**
```
Entry LONG $2000

SL decision:
- support_resistance = 0.40 (BAIXO = suporte em $1988 prÃ³ximo)
- Modelo aprende: "SL de 10 pontos vai bater no suporte, usar 14 pontos"
- SL final: $1986 (14 pontos)

TP decision:
- breakout_strength = 0.70 (ALTO = resistÃªncia em $2015 prÃ³xima)
- Modelo aprende: "TP de 15 pontos mira na resistÃªncia, REALISTA"
- TP final: $2015 (15 pontos)

Risk/Reward: 15/14 = 1.07:1 (realista!)
```

---

## ðŸ“Š IMPACTO ESPERADO

### ANTES (features genÃ©ricas):
```
Entry LONG $2000
SL: $1990 (10 pontos - mÃ­nimo cego)
TP: $2025 (25 pontos - cap cego)

Realidade do mercado:
- Suporte em $1988 â†’ SL hit em 2 candles (pullback natural)
- ResistÃªncia em $2012 â†’ preÃ§o reverte ANTES do TP
- Resultado: -$10 perda (TP nunca atingido)
```

### DEPOIS (features para SL/TP):
```
Entry LONG $2000
SL: $1986 (14 pontos - ABAIXO do suporte $1988)
TP: $2012 (12 pontos - NA resistÃªncia $2012)

Realidade do mercado:
- PreÃ§o puxa atÃ© $1989 â†’ SL NÃƒO hit (respeitou suporte)
- PreÃ§o sobe atÃ© $2012 â†’ TP HIT (mirou na resistÃªncia)
- Resultado: +$12 lucro (TP atingido!)
```

---

## ðŸ† RECOMPENSAS PARA TP INTELIGENTE

### Arquivo: `reward_daytrade_v3_brutal.py`

### ADICIONAR apÃ³s linha 731 (dentro de `_calculate_smart_sltp_heuristics`):

```python
# ðŸŽ¯ HEURÃSTICA 5: TP MIRADO EM ZONA DE RESISTÃŠNCIA
# Bonificar quando TP estÃ¡ prÃ³ximo de uma zona de alvo realista

# Pegar feature tp_target_zones do env
try:
    current_step = getattr(env, 'current_step', 0)
    df = getattr(env, 'df', None)

    if df is not None and 'breakout_strength' in df.columns:
        # breakout_strength agora Ã© tp_target_quality
        tp_target_quality = df['breakout_strength'].iloc[current_step]

        # TP target quality ALTO = resistÃªncia prÃ³xima
        if tp_target_quality > 0.6:
            # Calcular se o TP atual do modelo estÃ¡ prÃ³ximo dessa zona
            # (dentro de Â±3 pontos da resistÃªncia ideal)

            # Feature indica que resistÃªncia estÃ¡ prÃ³xima
            # Se TP do modelo tambÃ©m estÃ¡ nessa zona, REWARD
            shaping += 0.05 * tp_target_quality

        elif tp_target_quality < 0.3:
            # TP target quality BAIXO = resistÃªncia distante
            # Se modelo setou TP muito alto (>20 pontos), PENALTY
            if tp_distance > 20:
                shaping -= 0.03
except:
    pass
```

### ADICIONAR nova funÃ§Ã£o apÃ³s linha 845:

```python
def _calculate_tp_realism_bonus(self, env) -> float:
    """
    ðŸŽ¯ BONIFICAR TP realista baseado em estrutura de mercado

    TP BOM:
    - Mira em resistÃªncia prÃ³xima (LONG) ou suporte prÃ³ximo (SHORT)
    - DistÃ¢ncia Ã© mÃºltiplo razoÃ¡vel de ATR (1-2.5 ATR)

    TP RUIM:
    - Ignora resistÃªncias prÃ³ximas
    - DistÃ¢ncia irrealista (>3 ATR ou >25 pontos)
    """
    try:
        bonus = 0.0
        positions = getattr(env, 'positions', [])

        if not positions:
            return 0.0

        # Pegar dados de mercado
        current_step = getattr(env, 'current_step', 0)
        df = getattr(env, 'df', None)

        if df is None or 'breakout_strength' in df.columns:
            return 0.0

        tp_target_quality = df['breakout_strength'].iloc[current_step]
        current_atr = getattr(env, 'current_atr', 15.0)

        for position in positions:
            if not isinstance(position, dict):
                continue

            entry_price = position.get('entry_price', 0)
            tp_price = position.get('tp', 0)
            pos_type = position.get('type', '')

            if entry_price == 0 or tp_price == 0:
                continue

            # Calcular distÃ¢ncia do TP em pontos
            if pos_type == 'long':
                tp_distance = tp_price - entry_price
            else:
                tp_distance = entry_price - tp_price

            # Calcular distÃ¢ncia em mÃºltiplos de ATR
            tp_atr_multiple = tp_distance / current_atr if current_atr > 0 else 0

            # CASO 1: TP target quality ALTO (resistÃªncia prÃ³xima)
            if tp_target_quality > 0.6:
                # ResistÃªncia estÃ¡ prÃ³xima (ex: 1.5 ATR)
                # Se modelo setou TP prÃ³ximo (1-2 ATR), REWARD
                if 1.0 <= tp_atr_multiple <= 2.0:
                    bonus += 0.08 * tp_target_quality
                # Se modelo setou TP muito longe ignorando resistÃªncia, PENALTY
                elif tp_atr_multiple > 2.5:
                    bonus -= 0.05

            # CASO 2: TP target quality BAIXO (resistÃªncia distante)
            elif tp_target_quality < 0.3:
                # ResistÃªncia estÃ¡ longe (>3 ATR)
                # Se modelo setou TP conservador (<2 ATR), REWARD
                if tp_atr_multiple < 2.0:
                    bonus += 0.03
                # Se modelo setou TP no CAP (25 pontos) mirando muito longe, PENALTY
                elif tp_distance >= 24:
                    bonus -= 0.08

        return max(bonus, -0.5)

    except Exception as e:
        self.logger.debug(f"Erro em tp_realism_bonus: {e}")
        return 0.0
```

### INTEGRAR NO REWARD (linha ~368):

```python
# 11. ðŸŽ¯ TP REALISM: Bonificar TP que mira em zonas realistas
tp_realism = self._calculate_tp_realism_bonus(env)
shaping_reward += tp_realism
info['tp_realism_bonus'] = tp_realism
```

---

## ðŸŽ¯ RESULTADO FINAL: FEATURES PARA SL + TP

```python
high_quality_features = [
    'volume_momentum',       # âœ… Volume dinÃ¢mico
    'price_position',        # âœ… PosiÃ§Ã£o no range
    'breakout_strength',     # ðŸ†• TP TARGET ZONES (zonas realistas para TP)
    'trend_consistency',     # âœ… ConsistÃªncia do trend
    'support_resistance',    # ðŸ†• SL ZONE QUALITY (zonas seguras para SL)
    'volatility_regime',     # âœ… Regime de volatilidade
    'market_structure'       # ðŸ†• RECENT VOLATILITY SPIKE (ajuste contextual)
]
```

---

## ðŸ“Š EXEMPLO COMPLETO DE APRENDIZADO

### SituaÃ§Ã£o: LONG em mercado com estrutura clara

**Mercado:**
- PreÃ§o atual: $2000
- Suporte em $1985 (15 pontos abaixo)
- ResistÃªncia em $2018 (18 pontos acima)
- ATR: 12 pontos

**Features:**
```python
support_resistance (SL zone) = 0.35  # Suporte prÃ³ximo (ruim para SL <15 pts)
breakout_strength (TP zone)  = 0.75  # ResistÃªncia prÃ³xima (bom para TP ~18 pts)
volatility_regime            = 0.40  # Volatilidade mÃ©dia
market_structure (vol spike) = 0.30  # Mercado calmo
```

**Modelo aprende:**
```
Entrada: LONG $2000

DecisÃ£o SL:
- support_resistance = 0.35 (BAIXO)
  â†’ Suporte em $1985 prÃ³ximo
  â†’ SL de 12 pontos bateria ANTES do suporte
  â†’ AUMENTAR para 17 pontos
- SL final: $1983

DecisÃ£o TP:
- breakout_strength = 0.75 (ALTO)
  â†’ ResistÃªncia em $2018 prÃ³xima
  â†’ TP de 18 pontos mira EXATAMENTE na resistÃªncia
  â†’ IDEAL!
- TP final: $2018

Risk/Reward: 18/17 = 1.06:1
TP realista: ResistÃªncia conhecida
SL seguro: Abaixo do suporte
```

**Resultado esperado:**
- TP hit rate: **40-50%** (vs 5% atual)
- SL hit rate: **50-60%** (vs 95% atual)
- Win rate balanceado com RR ratio realista

---

## âœ… IMPLEMENTAÃ‡ÃƒO FINAL

**Arquivos a modificar:**

### 1. cherry.py (2 mudanÃ§as):
- **Linha 4363-4374:** `breakout_strength` â†’ TP Target Zones
- **Linha 4386-4397:** `support_resistance` â†’ SL Zone Quality

### 2. reward_daytrade_v3_brutal.py (2 mudanÃ§as):
- **Linha 731:** Adicionar heurÃ­stica TP em zona de resistÃªncia
- **Linha 845:** Adicionar `_calculate_tp_realism_bonus()`

**Tempo:** 20-25 minutos

**Obs space:** NÃƒO ALTERADO (mesmas features, cÃ¡lculo diferente)

---

**Gerado:** 2025-10-03
**Problema:** TPs nunca atingidos (miram muito longe)
**SoluÃ§Ã£o:** Feature que identifica zonas REALISTAS para TP (resistÃªncias prÃ³ximas)
**BenefÃ­cio:** Modelo aprende a mirar em alvos ATINGÃVEIS
