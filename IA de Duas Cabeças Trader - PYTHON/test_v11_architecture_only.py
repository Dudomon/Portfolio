#!/usr/bin/env python3
"""
ğŸ§ª TESTE ARQUITETURA V11 HÃBRIDA - FOCO NA POLICY
Teste simplificado focado apenas na arquitetura LSTM+GRU
"""

import sys
import os
sys.path.append("D:/Projeto")

import torch
import torch.nn as nn
import numpy as np
from datetime import datetime
import traceback

# Import da V11 Sigmoid
from trading_framework.policies.two_head_v11_sigmoid import (
    TwoHeadV11Sigmoid, 
    get_v8_elegance_kwargs
)

def test_v11_architecture():
    """ğŸ—ï¸ Teste direto da arquitetura V11 HÃ­brida"""
    print("ğŸ§ª TESTE ARQUITETURA V11 HÃBRIDA LSTM+GRU")
    print("="*50)
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ–¥ï¸ Device: {device}")
    
    try:
        # Simular observation_space e action_space
        from gym.spaces import Box
        
        observation_space = Box(low=-np.inf, high=np.inf, shape=(450,), dtype=np.float32)
        action_space = Box(low=-1, high=1, shape=(4,), dtype=np.float32)
        
        print(f"ğŸ“Š Observation Space: {observation_space.shape}")
        print(f"ğŸ¯ Action Space: {action_space.shape}")
        
        # Criar policy V11 diretamente
        kwargs = get_v8_elegance_kwargs()
        
        # Adicionar lr_schedule obrigatÃ³rio
        def lr_schedule(progress):
            return 1e-4
        
        policy = TwoHeadV11Sigmoid(
            observation_space=observation_space,
            action_space=action_space,
            lr_schedule=lr_schedule,
            **kwargs
        )
        
        policy = policy.to(device)
        print("âœ… Policy V11 criada com sucesso")
        
        # Verificar componentes hÃ­bridos
        components = {
            'v8_shared_lstm': hasattr(policy, 'v8_shared_lstm'),
            'v11_shared_gru': hasattr(policy, 'v11_shared_gru'),
            'hybrid_fusion': hasattr(policy, 'hybrid_fusion'),
            'market_context': hasattr(policy, 'market_context'),
            'entry_head': hasattr(policy, 'entry_head'),
            'management_head': hasattr(policy, 'management_head'),
            'memory_bank': hasattr(policy, 'memory_bank'),
            'v8_critic': hasattr(policy, 'v8_critic')
        }
        
        print("\nğŸ” COMPONENTES DETECTADOS:")
        for comp, present in components.items():
            status = "âœ…" if present else "âŒ"
            print(f"{status} {comp}")
        
        # Contar parÃ¢metros
        if components['v8_shared_lstm']:
            lstm_params = sum(p.numel() for p in policy.v8_shared_lstm.parameters())
            print(f"\nğŸ§  LSTM: {lstm_params:,} parÃ¢metros")
        
        if components['v11_shared_gru']:
            gru_params = sum(p.numel() for p in policy.v11_shared_gru.parameters())
            print(f"âš¡ GRU: {gru_params:,} parÃ¢metros")
            print("ğŸ”¥ ARQUITETURA HÃBRIDA CONFIRMADA!")
        
        if components['hybrid_fusion']:
            fusion_params = sum(p.numel() for p in policy.hybrid_fusion.parameters())
            print(f"ğŸ”— FusÃ£o: {fusion_params:,} parÃ¢metros")
        
        total_params = sum(p.numel() for p in policy.parameters())
        print(f"ğŸ“Š TOTAL: {total_params:,} parÃ¢metros")
        
        # Teste de forward pass
        print("\nğŸ”„ TESTE FORWARD PASS:")
        batch_size = 2
        obs = torch.randn(batch_size, 450, device=device)
        
        # Inicializar estados LSTM manualmente
        hidden_size = 256  # v8_lstm_hidden
        lstm_states = (
            torch.zeros(1, batch_size, hidden_size, device=device),  # hidden
            torch.zeros(1, batch_size, hidden_size, device=device)   # cell
        )
        episode_starts = torch.zeros(batch_size, dtype=torch.bool, device=device)
        
        with torch.no_grad():
            # Forward actor
            actions, new_lstm_states, gate_info = policy.forward_actor(obs, lstm_states, episode_starts)
            print(f"âœ… Actions shape: {actions.shape}")
            print(f"ğŸ“Š Actions range: [{actions.min():.3f}, {actions.max():.3f}]")
            
            # Forward critic
            values, _ = policy.forward_critic(obs, lstm_states, episode_starts)
            print(f"âœ… Values shape: {values.shape}")
            print(f"ğŸ“Š Values range: [{values.min():.3f}, {values.max():.3f}]")
        
        # Teste de gradientes
        print("\nğŸ“ˆ TESTE GRADIENTES:")
        policy.train()
        
        # Novo forward pass com gradientes habilitados
        obs_grad = torch.randn(batch_size, 450, device=device, requires_grad=True)
        actions_grad, _, _ = policy.forward_actor(obs_grad, lstm_states, episode_starts)
        values_grad, _ = policy.forward_critic(obs_grad, lstm_states, episode_starts)
        
        # Simular loss e backward
        fake_loss = actions_grad.mean() + values_grad.mean()
        fake_loss.backward()
        
        # Verificar gradientes
        grad_components = {}
        
        # LSTM gradientes
        for name, param in policy.v8_shared_lstm.named_parameters():
            if param.grad is not None:
                grad_norm = param.grad.norm().item()
                grad_components[f'lstm_{name}'] = grad_norm
        
        # GRU gradientes
        for name, param in policy.v11_shared_gru.named_parameters():
            if param.grad is not None:
                grad_norm = param.grad.norm().item()
                grad_components[f'gru_{name}'] = grad_norm
        
        # Fusion gradientes
        for i, layer in enumerate(policy.hybrid_fusion):
            if hasattr(layer, 'weight') and layer.weight.grad is not None:
                grad_norm = layer.weight.grad.norm().item()
                grad_components[f'fusion_{i}'] = grad_norm
        
        healthy_grads = sum(1 for norm in grad_components.values() if norm > 1e-6)
        total_grads = len(grad_components)
        
        print(f"âœ… Gradientes saudÃ¡veis: {healthy_grads}/{total_grads}")
        
        for name, norm in list(grad_components.items())[:5]:  # Mostrar apenas 5
            status = "âœ…" if norm > 1e-6 else "âš ï¸"
            print(f"{status} {name}: {norm:.2e}")
        
        # Limpar gradientes
        policy.zero_grad()
        
        # Resultado final
        if all(components.values()) and healthy_grads > total_grads * 0.7:
            print("\nğŸ‰ TESTE APROVADO!")
            print("âœ… V11 HÃ­brida LSTM+GRU funcionando perfeitamente")
            print("ğŸš€ Pronta para prÃ©-treino!")
            return True
        else:
            print("\nâš ï¸ TESTE PARCIAL")
            print("ğŸ”§ Alguns componentes precisam de revisÃ£o")
            return False
            
    except Exception as e:
        print(f"\nâŒ TESTE FALHOU: {e}")
        traceback.print_exc()
        return False

def main():
    """ğŸš€ FunÃ§Ã£o principal"""
    success = test_v11_architecture()
    
    if success:
        print("\n" + "="*50)
        print("ğŸ‰ V11 HÃBRIDA APROVADA!")
        print("ğŸ”¥ LSTM (longo prazo) + GRU (reatividade) + FusÃ£o Neural")
        print("ğŸš€ Sistema pronto para treinamento!")
        return 0
    else:
        print("\n" + "="*50)
        print("âŒ V11 HÃBRIDA COM PROBLEMAS")
        print("ğŸ”§ Revisar implementaÃ§Ã£o antes do treino")
        return 1

if __name__ == "__main__":
    exit_code = main()
    print(f"\nâ¸ï¸ Teste finalizado (cÃ³digo: {exit_code})")
    exit(exit_code)