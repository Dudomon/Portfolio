#!/usr/bin/env python3
"""
ğŸ” LSTM DEATH INVESTIGATOR
Descobrir sistematicamente o que estÃ¡ matando os LSTMs da V8Heritage
"""

import torch
import torch.nn as nn
import numpy as np
from stable_baselines3.common.callbacks import BaseCallback

class LSTMDeathInvestigator(BaseCallback):
    """
    ğŸ” Investigador forense para descobrir o que mata os LSTMs
    """
    
    def __init__(self, verbose: int = 1):
        super().__init__(verbose)
        self.investigation_data = []
        self.lstm_health_history = {}
        self.step_count = 0
        self.death_detected = False
        
    def _on_step(self) -> bool:
        self.step_count += 1
        
        # Investigar a cada 50 steps
        if self.step_count % 50 == 0:
            self._investigate_lstm_health()
            
        return True
    
    def _investigate_lstm_health(self):
        """ğŸ” InvestigaÃ§Ã£o forense completa dos LSTMs"""
        
        if not hasattr(self.model, 'policy'):
            return
            
        policy = self.model.policy
        
        # Verificar se Ã© V8Heritage
        if not hasattr(policy, 'neural_architecture'):
            return
            
        print(f"\nğŸ” INVESTIGAÃ‡ÃƒO FORENSE - Step {self.step_count}")
        print("=" * 60)
        
        neural_arch = policy.neural_architecture
        
        for lstm_name in ['actor_lstm', 'critic_lstm']:
            if hasattr(neural_arch, lstm_name):
                lstm = getattr(neural_arch, lstm_name)
                self._investigate_single_lstm(lstm_name, lstm)
    
    def _investigate_single_lstm(self, lstm_name, lstm):
        """ğŸ” InvestigaÃ§Ã£o detalhada de um LSTM especÃ­fico"""
        
        print(f"\nğŸ¯ INVESTIGANDO {lstm_name.upper()}")
        print("-" * 40)
        
        investigation = {
            'step': self.step_count,
            'lstm_name': lstm_name,
            'params': {},
            'gradients': {},
            'optimizer_state': {},
            'suspicious_findings': []
        }
        
        # 1. ANÃLISE DOS PARÃ‚METROS
        for param_name, param in lstm.named_parameters():
            if param is not None:
                zeros_count = (param.data.abs() < 1e-8).sum().item()
                total_params = param.data.numel()
                zero_ratio = zeros_count / total_params
                
                param_stats = {
                    'zero_ratio': zero_ratio,
                    'mean': param.data.mean().item(),
                    'std': param.data.std().item(),
                    'min': param.data.min().item(),
                    'max': param.data.max().item(),
                    'has_nan': torch.isnan(param.data).any().item(),
                    'has_inf': torch.isinf(param.data).any().item()
                }
                
                investigation['params'][param_name] = param_stats
                
                print(f"ğŸ“Š {param_name}:")
                print(f"   Zeros: {zero_ratio*100:.1f}% | Mean: {param_stats['mean']:.6f} | Std: {param_stats['std']:.6f}")
                print(f"   Range: [{param_stats['min']:.6f}, {param_stats['max']:.6f}] | NaN: {param_stats['has_nan']} | Inf: {param_stats['has_inf']}")
                
                # Detectar morte sÃºbita
                if zero_ratio > 0.8:  # 80% zeros = morte
                    investigation['suspicious_findings'].append(f"{param_name}: MORTE DETECTADA ({zero_ratio*100:.1f}% zeros)")
                    print(f"   ğŸš¨ MORTE DETECTADA: {zero_ratio*100:.1f}% zeros!")
                    self.death_detected = True
                
                # 2. ANÃLISE DOS GRADIENTES
                if param.grad is not None:
                    grad_zeros = (param.grad.abs() < 1e-8).sum().item()
                    grad_total = param.grad.numel()
                    grad_zero_ratio = grad_zeros / grad_total
                    
                    grad_stats = {
                        'zero_ratio': grad_zero_ratio,
                        'mean': param.grad.mean().item(),
                        'std': param.grad.std().item(),
                        'norm': param.grad.norm().item(),
                        'has_nan': torch.isnan(param.grad).any().item(),
                        'has_inf': torch.isinf(param.grad).any().item()
                    }
                    
                    investigation['gradients'][param_name] = grad_stats
                    
                    print(f"   ğŸ¯ Gradientes: Zeros: {grad_zero_ratio*100:.1f}% | Norm: {grad_stats['norm']:.6f}")
                    print(f"   ğŸ¯ Grad Range: Mean: {grad_stats['mean']:.6f} | Std: {grad_stats['std']:.6f}")
                    
                    # Detectar problemas de gradientes
                    if grad_zero_ratio > 0.9:
                        investigation['suspicious_findings'].append(f"{param_name}: GRADIENTES MORTOS ({grad_zero_ratio*100:.1f}% zeros)")
                        print(f"   ğŸš¨ GRADIENTES MORTOS: {grad_zero_ratio*100:.1f}% zeros!")
                    
                    if grad_stats['norm'] < 1e-8:
                        investigation['suspicious_findings'].append(f"{param_name}: GRADIENTES MICROSCÃ“PICOS (norm={grad_stats['norm']:.2e})")
                        print(f"   ğŸš¨ GRADIENTES MICROSCÃ“PICOS: norm={grad_stats['norm']:.2e}")
                    
                    if grad_stats['norm'] > 100:
                        investigation['suspicious_findings'].append(f"{param_name}: GRADIENTES EXPLOSIVOS (norm={grad_stats['norm']:.2e})")
                        print(f"   ğŸš¨ GRADIENTES EXPLOSIVOS: norm={grad_stats['norm']:.2e}")
                        
                else:
                    investigation['gradients'][param_name] = None
                    print(f"   âš ï¸ SEM GRADIENTES!")
                    investigation['suspicious_findings'].append(f"{param_name}: SEM GRADIENTES")
        
        # 3. ANÃLISE DO OPTIMIZER STATE
        self._investigate_optimizer_state(lstm_name, lstm, investigation)
        
        # 4. SALVAR DADOS DA INVESTIGAÃ‡ÃƒO
        self.investigation_data.append(investigation)
        
        # 5. RELATÃ“RIO DE SUSPEITAS
        if investigation['suspicious_findings']:
            print(f"\nğŸš¨ SUSPEITAS DETECTADAS EM {lstm_name.upper()}:")
            for finding in investigation['suspicious_findings']:
                print(f"   ğŸ” {finding}")
    
    def _investigate_optimizer_state(self, lstm_name, lstm, investigation):
        """ğŸ” Investigar estado do optimizer"""
        
        try:
            optimizer = self.model.policy.optimizer
            if optimizer is None:
                print("   âš ï¸ Optimizer nÃ£o encontrado!")
                return
                
            print(f"\nğŸ”§ OPTIMIZER INFO:")
            print(f"   Tipo: {type(optimizer).__name__}")
            
            # Verificar learning rate
            for param_group in optimizer.param_groups:
                lr = param_group.get('lr', 'N/A')
                weight_decay = param_group.get('weight_decay', 'N/A')
                print(f"   LR: {lr} | Weight Decay: {weight_decay}")
                
                investigation['optimizer_state']['lr'] = lr
                investigation['optimizer_state']['weight_decay'] = weight_decay
                
                # Detectar problemas
                if isinstance(lr, float) and lr > 1e-2:
                    investigation['suspicious_findings'].append(f"LR MUITO ALTO: {lr}")
                    print(f"   ğŸš¨ LR MUITO ALTO: {lr}")
                
                if isinstance(weight_decay, float) and weight_decay > 1e-2:
                    investigation['suspicious_findings'].append(f"WEIGHT DECAY MUITO ALTO: {weight_decay}")
                    print(f"   ğŸš¨ WEIGHT DECAY MUITO ALTO: {weight_decay}")
            
            # Verificar estado dos parÃ¢metros LSTM no optimizer
            for param_name, param in lstm.named_parameters():
                if param in optimizer.state:
                    state = optimizer.state[param]
                    print(f"   ğŸ“Š {param_name} optimizer state: {list(state.keys())}")
                    
                    # Verificar momentum/adam states
                    if 'exp_avg' in state:
                        exp_avg_norm = state['exp_avg'].norm().item()
                        print(f"      exp_avg norm: {exp_avg_norm:.6f}")
                        if exp_avg_norm > 10:
                            investigation['suspicious_findings'].append(f"{param_name}: MOMENTUM EXPLOSIVO ({exp_avg_norm:.2e})")
                    
                    if 'exp_avg_sq' in state:
                        exp_avg_sq_norm = state['exp_avg_sq'].norm().item()
                        print(f"      exp_avg_sq norm: {exp_avg_sq_norm:.6f}")
                        if exp_avg_sq_norm > 100:
                            investigation['suspicious_findings'].append(f"{param_name}: SECOND MOMENT EXPLOSIVO ({exp_avg_sq_norm:.2e})")
                
        except Exception as e:
            print(f"   âŒ Erro ao investigar optimizer: {e}")
            investigation['optimizer_state']['error'] = str(e)
    
    def get_investigation_report(self):
        """ğŸ“‹ Gerar relatÃ³rio completo da investigaÃ§Ã£o"""
        
        if not self.investigation_data:
            return "Nenhum dado de investigaÃ§Ã£o coletado."
        
        report = []
        report.append("ğŸ” RELATÃ“RIO FORENSE: MORTE DOS LSTMs V8HERITAGE")
        report.append("=" * 60)
        
        # AnÃ¡lise cronolÃ³gica das mortes
        deaths_detected = []
        for data in self.investigation_data:
            if data['suspicious_findings']:
                deaths_detected.append(data)
        
        if deaths_detected:
            report.append(f"\nğŸš¨ {len(deaths_detected)} EVENTOS SUSPEITOS DETECTADOS:")
            
            for death in deaths_detected:
                report.append(f"\nStep {death['step']} - {death['lstm_name']}:")
                for finding in death['suspicious_findings']:
                    report.append(f"  ğŸ” {finding}")
        
        # PadrÃµes identificados
        report.append(f"\nğŸ“Š ANÃLISE DE PADRÃ•ES:")
        report.append(f"Total de steps investigados: {len(self.investigation_data)}")
        report.append(f"Eventos suspeitos: {len(deaths_detected)}")
        
        return "\n".join(report)

# FunÃ§Ã£o para adicionar o investigador aos callbacks
def create_lstm_death_investigator():
    """ğŸ” Criar investigador forense para LSTMs"""
    return LSTMDeathInvestigator(verbose=1)