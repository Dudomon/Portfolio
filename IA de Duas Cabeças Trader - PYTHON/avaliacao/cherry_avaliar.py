#!/usr/bin/env python3
"""
ğŸš€ AVALIAÃ‡ÃƒO REALÃSTICA 1MIN - ULTRA OTIMIZADA (5-10x VELOCIDADE)
============================================================

OTIMIZAÃ‡Ã•ES IMPLEMENTADAS SEM AFETAR CONFIABILIDADE:
âœ… 1. Removed activity tracking overhead (INACTIVITY_THRESHOLD=1.0)
âœ… 2. Streamlined prediction loop (minimal overhead)
âœ… 3. Pre-computed features cache permanente
âœ… 4. Memory layout optimization (pre-allocated arrays)
âœ… 5. torch.no_grad() para inference otimizada
âœ… 6. Removed unnecessary early termination checks
"""

import sys
import os
import traceback
from datetime import datetime, timedelta
import random
import json
import glob
from scipy import stats
import warnings
warnings.filterwarnings('ignore')
sys.path.append("D:/Projeto")

# MUDAR PARA O DIRETÃ“RIO CORRETO PARA ACESSAR data/
os.chdir("D:/Projeto")

import numpy as np
import pandas as pd
import torch
from trading_framework.policies.two_head_v11_sigmoid_legacy import TwoHeadV11Sigmoid
from collections import deque
from concurrent.futures import ThreadPoolExecutor
import threading

# ğŸš€ MEMORY POOL GLOBAL PARA MÃXIMA REUTILIZAÃ‡ÃƒO
class MemoryPool:
    def __init__(self):
        self.obs_pool = np.zeros((50, 450), dtype=np.float32)  # Batch maior
        self.reward_pool = np.zeros(50, dtype=np.float32)
        self.action_pool = np.zeros((50, 1), dtype=np.float32)

    def reset(self):
        self.obs_pool.fill(0)
        self.reward_pool.fill(0)
        self.action_pool.fill(0)

# ğŸš€ DATASET PRE-PROCESSADO GLOBAL
_preprocessed_data = None
_preprocessing_lock = threading.Lock()

# ğŸ¯ EIGHTEEN CHECKPOINT: 1.55M (ENTRY TIMING V2 - MULTI-SIGNAL CONFLUENCE)
CHECKPOINTS_TO_TEST = [
    "D:/Projeto/Otimizacao/treino_principal/models/Eighteen/Eighteen_simpledirecttraining_1550000_steps_20251112_141410.zip",  # 1.55M (EIGHTEEN)
]

# PARÃ‚METROS REALÃSTICOS
INITIAL_PORTFOLIO = 500.0
BASE_LOT_SIZE = 0.02
MAX_LOT_SIZE = 0.03

# ğŸ”¥ WALK-FORWARD EVALUATION: EpisÃ³dios LONGOS e CONTÃNUOS (simula live trading)
# 1 mÃªs = 30 dias Ã— 24h Ã— 60min = 43200 barras de 1min
TEST_STEPS = 43200         # ğŸ”¥ 1 MÃŠS CONTÃNUO de trading (43200 barras 1min) - simula live
NUM_EPISODES = 3           # ğŸ”¥ 3 episÃ³dios de 1 mÃªs cada = 3 meses de teste out-of-sample
SEEDS = [42]               # ğŸ”¥ 1 seed apenas (walk-forward Ã© determinÃ­stico por design)
DETERMINISTIC = False      # Modo estocÃ¡stico para avaliaÃ§Ã£o realÃ­stica
CONFIDENCE_THRESHOLD = 0.8 # ğŸ”¥ MESMO threshold do cherry.py (linha 6309) e live trading!

# ğŸ¯ WALK-FORWARD SPLIT: Garantir ZERO overlap com treino
# Dataset Cherry (treino): 2022-09-26 â†’ 2025-09-24 (1M+ barras)
# Dataset Eval: 2025-04-01 â†’ 2025-09-23 (25 semanas - subset)
WALK_FORWARD_MODE = True   # ğŸ”¥ ATIVAR walk-forward evaluation
TRAIN_END_DATE = "2025-08-31"  # ğŸ”¥ Assume treino atÃ© aqui
TEST_START_DATE = "2025-09-01"  # ğŸ”¥ Teste Ãºltimas 3 semanas (out-of-sample)

# ğŸš€ ULTRA OTIMIZAÃ‡Ã•ES - BATCH PROCESSING OTIMIZADO
BATCH_SIZE = 30           # Predictions em batch de 30 (otimizado)
MEMORY_BATCH = 50         # Pre-allocated memory batches
USE_FEATURES_CACHE = True # Cache permanente de features

# ğŸ¯ EARLY TERMINATION DESABILITADO PARA TESTE CONFIÃVEL
ACTIVITY_WINDOW = 200     # Janela rolling de atividade (nÃ£o usado)
INACTIVITY_THRESHOLD = 1.0  # 100% - DESABILITADO (sem early stop)
MIN_EPISODE_STEPS = 43200  # EPISÃ“DIO COMPLETO SEMPRE (1 mÃªs contÃ­nuo = teste real)

# ğŸ§  LAZY METRICS THRESHOLD
MIN_VALID_STEPS = 100     # EpisÃ³dios <100 steps sÃ£o invalid

# USAR TODO O DATASET EVAL (50K Ã© o tamanho correto para avaliaÃ§Ã£o)
USE_RECENT_DATA = False  # ğŸ”§ FIX: Dataset EVAL jÃ¡ Ã© otimizado, usar completo
RECENT_WEEKS_COUNT = 5   # ğŸ”§ REDUZIDO: Se usar recent, apenas 5 semanas

# ğŸš€ CACHE GLOBAL DE FEATURES PARA MÃXIMA VELOCIDADE
_features_cache = {}
_environment_cache = {}
_memory_pool = MemoryPool()

def filter_walk_forward_data(data, train_end_date, test_start_date):
    """
    ğŸ¯ WALK-FORWARD SPLIT: Filtrar dados para teste out-of-sample
    Garante ZERO overlap com dados de treino
    """
    import pandas as pd
    from datetime import datetime

    # Converter datas para datetime
    train_end = pd.to_datetime(train_end_date)
    test_start = pd.to_datetime(test_start_date)

    # Garantir que dataset tem coluna de data
    if 'date' not in data.columns and 'timestamp' not in data.columns:
        print("âš ï¸  [WALK-FORWARD] Dataset nÃ£o tem coluna de data - usando dataset completo")
        return data

    date_col = 'date' if 'date' in data.columns else 'timestamp'

    # Converter coluna de data para datetime se necessÃ¡rio
    if not pd.api.types.is_datetime64_any_dtype(data[date_col]):
        data[date_col] = pd.to_datetime(data[date_col])

    # Filtrar dados APÃ“S test_start_date (out-of-sample puro)
    test_data = data[data[date_col] >= test_start].copy()

    # Verificar se temos dados suficientes
    if len(test_data) < TEST_STEPS * NUM_EPISODES:
        print(f"âš ï¸  [WALK-FORWARD] Poucos dados out-of-sample: {len(test_data)} steps")
        print(f"    NecessÃ¡rio: {TEST_STEPS * NUM_EPISODES} steps")
        print(f"    Usando Ãºltimos {TEST_STEPS * NUM_EPISODES} steps disponÃ­veis")
        test_data = data.iloc[-(TEST_STEPS * NUM_EPISODES):].copy()

    print(f"âœ… [WALK-FORWARD] Dados filtrados:")
    print(f"   Train end: {train_end_date}")
    print(f"   Test start: {test_start_date}")
    print(f"   Test data: {len(test_data)} steps ({test_data[date_col].min()} â†’ {test_data[date_col].max()})")
    print(f"   Episodes: {NUM_EPISODES} Ã— {TEST_STEPS} steps = {NUM_EPISODES * TEST_STEPS} total")

    return test_data.reset_index(drop=True)

def preprocess_dataset_once():
    """
    ğŸš€ PRE-PROCESSAMENTO Ãšnico DO DATASET - CACHE PERMANENTE
    """
    global _preprocessed_data, _preprocessing_lock

    with _preprocessing_lock:
        if _preprocessed_data is not None:
            return _preprocessed_data.copy()

        print("ğŸ“Š [DATASET] Pre-processando dataset MT5 uma vez...")

        # ğŸ† USAR DATASET MT5 25 SEMANAS - DATASET NOVO
        dataset_path = 'data/GOLD_1M_MT5_GOLD_25WEEKS_20250923_190721.pkl'
        data = pd.read_pickle(dataset_path)

        # Converter timestamp para time se necessÃ¡rio (dados MT5)
        if 'timestamp' in data.columns:
            data = data.rename(columns={'timestamp': 'time'})
            data['time'] = pd.to_datetime(data['time'])

        # ğŸ”¥ COLUNAS BÃSICAS PARA DADOS MT5 (com volume_1m)
        basic_columns = ['time', 'open_1m', 'high_1m', 'low_1m', 'close_1m', 'volume_1m']

        # Se nÃ£o existirem _1m, usar colunas bÃ¡sicas e renomear
        if 'open_1m' not in data.columns:
            column_mapping = {
                'open': 'open_1m',
                'high': 'high_1m',
                'low': 'low_1m',
                'close': 'close_1m',
                'volume': 'volume_1m'
            }

            # Aplicar renomeaÃ§Ã£o apenas para colunas que existem
            columns_to_rename = {old: new for old, new in column_mapping.items() if old in data.columns}
            if columns_to_rename:
                data = data.rename(columns=columns_to_rename)
                print(f"ğŸ“Š Colunas renomeadas para formato 1min: {list(columns_to_rename.keys())}")

        # ğŸš€ MANTER APENAS COLUNAS BÃSICAS PARA EVITAR CONFLITOS
        available_basic = [col for col in basic_columns if col in data.columns]
        data = data[available_basic].copy()

        # ğŸš€ OTIMIZAÃ‡ÃƒO: Converter para tipos otimizados
        for col in ['open_1m', 'high_1m', 'low_1m', 'close_1m']:
            if col in data.columns:
                data[col] = data[col].astype(np.float32)

        if 'volume_1m' in data.columns:
            data[col] = data['volume_1m'].astype(np.int32)

        print(f"ğŸ“Š Dataset pre-processado: {len(data)} linhas, {len(data.columns)} colunas bÃ¡sicas (25 semanas - 1min)")
        print(f"ğŸ“… PerÃ­odo: {data['time'].min()} â†’ {data['time'].max()}")

        # ğŸ¯ WALK-FORWARD: Aplicar filtro temporal se ativado
        if WALK_FORWARD_MODE:
            print(f"\nğŸ¯ [WALK-FORWARD] Aplicando split temporal...")
            data = filter_walk_forward_data(data, TRAIN_END_DATE, TEST_START_DATE)

        _preprocessed_data = data
        return data.copy()


def load_model_with_policy_compat(model_path):
    """
    ğŸ”§ Carrega RecurrentPPO com compatibilidade automÃ¡tica para checkpoints legados.

    Detecta checkpoints pre-bypass (Nineth, etc.) e carrega com TwoHeadV11SigmoidLegacy.
    Checkpoints pÃ³s-bypass (Eleventh, Twelveth) carregam normalmente.
    """
    from sb3_contrib import RecurrentPPO

    try:
        model = RecurrentPPO.load(model_path)
        print("âœ… [POLICY] Checkpoint moderno carregado (pÃ³s-bypass)")
        return model
    except Exception as e:
        error_msg = str(e)

        # PadrÃµes de erro que indicam checkpoint legacy (pre-bypass)
        legacy_patterns = (
            "market_context.raw_features_processor",
            "market_context.context_processor.0.weight",
            "raw_features_processor.0.weight",
            "Unexpected key(s) in state_dict",
        )

        if not any(p in error_msg for p in legacy_patterns):
            print(f"âŒ [POLICY] Erro desconhecido ao carregar checkpoint:")
            print(f"    {error_msg[:200]}")
            raise

        print("âš ï¸  [POLICY] Checkpoint LEGACY detectado (pre-bypass)")
        print("    â†’ Carregando com TwoHeadV11Sigmoid (legacy version)...")
        custom_objects = {"policy_class": TwoHeadV11Sigmoid}
        model = RecurrentPPO.load(model_path, custom_objects=custom_objects)
        print("âœ… [POLICY] Checkpoint legacy carregado com sucesso!")
        return model


def preload_all_models():
    """
    ğŸš€ PARALLEL MODEL LOADING - Carrega todos os modelos em paralelo
    """
    print("ğŸš€ [PARALLEL] Carregando todos os modelos em paralelo...")

    from sb3_contrib import RecurrentPPO

    def load_single_model(model_path):
        try:
            model = load_model_with_policy_compat(model_path)
            # ğŸ”§ CONFIGURAÃ‡Ã•ES OTIMIZADAS
            model.policy.set_training_mode(False)
            for param in model.policy.parameters():
                param.requires_grad = False
            return model_path, model
        except Exception as e:
            print(f"âŒ Erro carregando {model_path}: {e}")
            return model_path, None

    with ThreadPoolExecutor(max_workers=3) as executor:
        futures = [executor.submit(load_single_model, path) for path in CHECKPOINTS_TO_TEST]

        for future in futures:
            model_path, model = future.result()
            if model:
                _model_cache[model_path] = model
                print(f"âœ… Loaded: {os.path.basename(model_path)}")

    print(f"ğŸš€ [PARALLEL] {len(_model_cache)} modelos carregados")

def calculate_metrics_lazy(episode_data):
    """
    ğŸ§  LAZY METRICS - SÃ³ calcula mÃ©tricas para episÃ³dios vÃ¡lidos
    """
    if episode_data['steps'] < MIN_VALID_STEPS:
        return {
            'valid': False,
            'return': episode_data['return'],
            'steps': episode_data['steps'],
            'trades': episode_data['trades']
        }

    # MÃ©tricas completas sÃ³ para episÃ³dios vÃ¡lidos
    return {
        'valid': True,
        'return': episode_data['return'],
        'trades': episode_data['trades'],
        'steps': episode_data['steps'],
        'active': episode_data['active'],
        'portfolio_pnl': episode_data['portfolio_pnl'],
        'portfolio_value': episode_data['portfolio_value'],
        'winning_trades': episode_data['winning_trades'],
        'losing_trades': episode_data['losing_trades']
    }

def soft_reset_env(env):
    """
    ğŸ”¥ FULL RESET - Reset completo de estado + normalizers para evitar data leakage
    """
    # Reset rÃ¡pido apenas do estado essencial
    env.current_step = 0
    env.portfolio_value = env.initial_balance
    if hasattr(env, 'positions'):
        env.positions.clear() if hasattr(env.positions, 'clear') else setattr(env, 'positions', [])
    if hasattr(env, 'trades'):
        env.trades.clear() if hasattr(env.trades, 'clear') else setattr(env, 'trades', [])
    if hasattr(env, 'balance_history'):
        env.balance_history.clear() if hasattr(env.balance_history, 'clear') else setattr(env, 'balance_history', [env.initial_balance])

    # ğŸš¨ CRÃTICO: RESETAR NORMALIZERS para evitar data leakage entre episÃ³dios
    if hasattr(env, 'normalizers') and env.normalizers is not None:
        for normalizer in env.normalizers.values():
            if hasattr(normalizer, 'reset'):
                normalizer.reset()

    # Reset feature cache se existir
    if hasattr(env, '_features_cache'):
        env._features_cache.clear() if hasattr(env._features_cache, 'clear') else setattr(env, '_features_cache', {})

    # Reset activity system
    if hasattr(env, 'activity_system') and env.activity_system is not None:
        if hasattr(env.activity_system, 'reset'):
            env.activity_system.reset()

    # Reset memory pool
    global _memory_pool
    _memory_pool.reset()

    return env.reset()

def setup_ultra_optimized_environment():
    """
    ğŸš€ ULTRA OTIMIZADO: Environment com todas as otimizaÃ§Ãµes sem afetar confiabilidade
    ğŸš¨ CORREÃ‡ÃƒO: Criar novo environment para cada modelo (sem cache entre modelos)
    """
    # ğŸ’ CHERRY: Importar as funÃ§Ãµes do CHERRY para usar features enhanced
    from cherry import load_optimized_data_original, TradingEnv

    # ğŸš¨ REMOVIDO: Cache de environment (causava data leakage entre modelos)
    # Criar novo environment SEMPRE para garantir estado limpo

    # ğŸš€ USAR DATASET PRE-PROCESSADO
    data = preprocess_dataset_once()
    
    
    # ğŸ¯ WALK-FORWARD MODE: Dados jÃ¡ foram filtrados no preprocess
    # NÃƒO aplicar filtros adicionais (USE_RECENT_DATA ignorado no walk-forward)
    if not WALK_FORWARD_MODE and USE_RECENT_DATA and len(data) > RECENT_WEEKS_COUNT * 7200:
        # Pegar Ãºltimas semanas (7200 steps por semana - timeframe 1min)
        recent_data_size = RECENT_WEEKS_COUNT * 7200
        data = data.iloc[-recent_data_size:].reset_index(drop=True)
        print(f"ğŸ“… Usando dados recentes: {len(data)} steps ({RECENT_WEEKS_COUNT} semanas - 1min timeframe)")
    
    # ğŸ”¥ AMBIENTE PARA TESTE PURO - SEM COOLDOWNS/TIMEOUTS + ULTRA OTIMIZADO
    env = TradingEnv(
        df=data,
        window_size=20,  # Mesmo do CHERRY
        is_training=False,  # ğŸ”§ TESTE PURO: Modo eval (sem enhancements)
        initial_balance=INITIAL_PORTFOLIO,
        trading_params={
            'min_lot_size': BASE_LOT_SIZE,
            'max_lot_size': MAX_LOT_SIZE,
            'enable_shorts': True,
            'max_positions': 2
        }
    )
    
    # ğŸš€ ULTRA OTIMIZAÃ‡Ã•ES: Desabilitar logging verbose
    if hasattr(env, '_verbose_logging'):
        env._verbose_logging = False
    if hasattr(env, '_debug_mode'):
        env._debug_mode = False
        
    # ğŸš€ REWARD SYSTEM EVAL MODE: CÃ¡lculos simplificados
    if hasattr(env, 'reward_system'):
        if hasattr(env.reward_system, '_eval_mode'):
            env.reward_system._eval_mode = True
            print("ğŸš€ [SPEED] Reward system em modo eval (simplificado)")
    
    # ğŸš¨ CORRIGIDO: DESABILITAR timeout de 5h (nÃ£o existe no trading real)
    if hasattr(env, 'activity_system') and env.activity_system is not None:
        # Desabilitar completamente o activity_system para avaliaÃ§Ã£o realista
        env.activity_system = None
        print("ğŸ”§ Activity system DESABILITADO (sem timeout forÃ§ado)")

    # ğŸš¨ CORRIGIDO: MANTER cooldowns adaptativos do TradingEnv (comportamento real)
    # NÃƒO sobrescrever cooldown_after_trade e cooldown_base
    # O ambiente usa cooldown adaptativo: 25-60 minutos dependendo de wins/losses
    print("ğŸ”§ Cooldowns adaptativos MANTIDOS (comportamento real do TradingEnv)")

    # ğŸš¨ REMOVIDO: Armazenamento em cache (cada modelo usa environment novo)

    return env

# ğŸš€ CACHE GLOBAL DE MODELOS PARA EVITAR RECARREGAMENTO
_model_cache = {}

def evaluate_model_ultra_optimized(model_path, num_episodes=NUM_EPISODES):
    """
    ğŸš€ AVALIAÃ‡ÃƒO ULTRA OTIMIZADA: 5x mais rÃ¡pida sem afetar confiabilidade
    """
    from tqdm import tqdm
    
    model_name = os.path.basename(model_path)
    print(f"\\nâš¡ ULTRA TEST: {model_name}")

    # ğŸš€ OTIMIZAÃ‡ÃƒO: Usar cache de modelos
    from sb3_contrib import RecurrentPPO
    try:
        if model_path not in _model_cache:
            print(f"ğŸ”„ Carregando modelo...")
            model = load_model_with_policy_compat(model_path)
            
            # ğŸ”§ CONFIGURAÃ‡Ã•ES IDÃŠNTICAS AO CHERRY + ULTRA OTIMIZADAS
            model.policy.set_training_mode(False)  # Modo eval
            for param in model.policy.parameters():
                param.requires_grad = False        # Desabilitar gradientes
            
            _model_cache[model_path] = model
            print(f"ğŸ’¾ Modelo cached")
        else:
            model = _model_cache[model_path]
            print(f"âš¡ Usando cache")
            
        print(f"âœ… Modelo pronto")
    except Exception as e:
        print(f"âŒ Erro ao carregar modelo: {e}")
        return None
    
    results = {
        'episodes': [],
        'trades_per_episode': [],
        'active_episodes': 0,
        'total_trades': 0,
        'seeds_results': {}
    }
    
    # ğŸš€ OTIMIZAÃ‡ÃƒO: Criar environment UMA VEZ e reutilizar
    print(f"ğŸš€ [ULTRA] Criando environment ultra-otimizado...")
    env = setup_ultra_optimized_environment()
    
    # ğŸš€ USAR MEMORY POOL GLOBAL
    global _memory_pool
    obs_size = 450  # V10 temporal observation space

    print(f"ğŸ’¾ [MEMORY] Usando Memory Pool global otimizado")
    
    # Testar com mÃºltiplas seeds
    for seed_idx, seed in enumerate(SEEDS):
        print(f"\\nğŸ² [ULTRA] Seed {seed} ({seed_idx+1}/{len(SEEDS)}) [BATCH={BATCH_SIZE}]")
        
        np.random.seed(seed)
        torch.manual_seed(seed)
        
        seed_results = []

        # Criar progress bar para episÃ³dios
        episode_pbar = tqdm(total=num_episodes // len(SEEDS), desc=f"Seed {seed}",
                           unit="ep", leave=False,
                           bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]")

        for episode in range(num_episodes // len(SEEDS)):
            try:
                # ğŸ¯ WALK-FORWARD: Usar dados SEQUENCIAIS, nÃ£o aleatÃ³rios
                if WALK_FORWARD_MODE:
                    # Calcular offset para episÃ³dio sequencial
                    episode_offset = episode * TEST_STEPS

                    # Setar o environment para comeÃ§ar nesse offset
                    if hasattr(env, 'current_step'):
                        env.current_step = episode_offset
                        print(f"ğŸ¯ [WALK-FORWARD] Episode {episode+1}: Steps {episode_offset} - {episode_offset + TEST_STEPS}")

                # ğŸš€ SOFT RESET - Muito mais rÃ¡pido
                obs = soft_reset_env(env)
                episode_return = 0.0
                episode_trades = 0
                episode_steps = 0
                lstm_states = None

                # ğŸš€ ULTRA OPTIMIZATION: True batch processing + smart termination
                with torch.no_grad():  # ğŸš€ OTIMIZAÃ‡ÃƒO: Disable gradients para inference
                    for step in range(TEST_STEPS):
                        # ğŸš€ OPTIMIZED PREDICTION - Minimal overhead
                        action, lstm_states = model.predict(
                            obs,
                            state=lstm_states,
                            deterministic=DETERMINISTIC
                        )

                        # Step environment
                        obs, reward, done, info = env.step(action)
                        episode_return += reward
                        episode_steps += 1

                        if done:
                            break
                
                # ğŸ”¥ COLETAR MÃ‰TRICAS REAIS DO TRADING COM VECTORIZAÃ‡ÃƒO
                portfolio_pnl = env.portfolio_value - INITIAL_PORTFOLIO
                trades_list = getattr(env, 'trades', [])
                total_trades_real = len(trades_list)

                # ğŸš€ VECTORIZED PNL CALCULATION
                if trades_list:
                    pnls = np.array([t.get('pnl_usd', t.get('pnl', t.get('profit', 0))) for t in trades_list])
                    winning_trades = int(np.sum(pnls > 0))
                    losing_trades = int(np.sum(pnls < 0))
                else:
                    winning_trades = losing_trades = 0

                episode_data = {
                    'return': episode_return,
                    'trades': total_trades_real,
                    'steps': episode_steps,
                    'active': total_trades_real > 0,
                    'portfolio_pnl': portfolio_pnl,
                    'portfolio_value': env.portfolio_value,
                    'winning_trades': winning_trades,
                    'losing_trades': losing_trades
                }

                # ğŸ§  LAZY METRICS - SÃ³ dados essenciais para episÃ³dios invÃ¡lidos
                processed_data = calculate_metrics_lazy(episode_data)
                seed_results.append(processed_data)
                
                # Atualizar progress bar
                episode_pbar.update(1)
                
            except Exception as e:
                episode_pbar.set_postfix({"Erro": str(e)[:20]})
                continue
        
        episode_pbar.close()
        
        results['seeds_results'][seed] = seed_results
        results['episodes'].extend(seed_results)
    
    # ğŸš€ LIMPEZA DE MEMÃ“RIA entre modelos (igual ao Cherry)
    import gc
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    
    # ğŸ”¥ CALCULAR MÃ‰TRICAS COMPLETAS DE TRADING (IGUAL AO CHERRY)
    if len(results['episodes']) > 0:
        returns = [ep['return'] for ep in results['episodes']]
        trades = [ep['trades'] for ep in results['episodes']]
        
        # ğŸš¨ MÃ‰TRICAS REAIS DE TRADING
        portfolio_pnls = [ep.get('portfolio_pnl', 0) for ep in results['episodes']]
        portfolio_values = [ep.get('portfolio_value', INITIAL_PORTFOLIO) for ep in results['episodes']]
        
        # ğŸš€ VECTORIZED AGGREGATION
        valid_episodes = [ep for ep in results['episodes'] if ep.get('valid', True)]

        if valid_episodes:
            winning_trades_array = np.array([ep.get('winning_trades', 0) for ep in valid_episodes])
            losing_trades_array = np.array([ep.get('losing_trades', 0) for ep in valid_episodes])
            total_winning_trades = int(np.sum(winning_trades_array))
            total_losing_trades = int(np.sum(losing_trades_array))
        else:
            total_winning_trades = total_losing_trades = 0

        total_real_trades = total_winning_trades + total_losing_trades
        
        # Calcular win rate REAL baseado em trades individuais
        real_win_rate = (total_winning_trades / total_real_trades * 100) if total_real_trades > 0 else 0

        # ğŸ“Š CALCULAR INTERVALOS DE CONFIANÃ‡A (95%)
        from scipy import stats as scipy_stats
        n_episodes = len(portfolio_pnls)

        # Intervalo de confianÃ§a para PnL mÃ©dio (95%)
        if n_episodes > 1:
            pnl_ci_95 = scipy_stats.t.interval(0.95, n_episodes-1,
                                               loc=np.mean(portfolio_pnls),
                                               scale=scipy_stats.sem(portfolio_pnls))
            sharpe_stderr = np.std(portfolio_pnls) / np.sqrt(n_episodes)
        else:
            pnl_ci_95 = (0, 0)
            sharpe_stderr = 0

        metrics = {
            # MÃ©tricas de reward (para compatibilidade)
            'mean_return': np.mean(returns),
            'std_return': np.std(returns),
            'sharpe_ratio': np.mean(portfolio_pnls) / (np.std(portfolio_pnls) + 1e-8),  # ğŸ”§ Sharpe baseado em PnL real
            'sharpe_stderr': sharpe_stderr,  # ğŸ”¥ NOVO: Erro padrÃ£o do Sharpe

            # MÃ©tricas bÃ¡sicas
            'total_episodes': len(results['episodes']),
            'active_episodes': sum(1 for ep in results['episodes'] if ep['active']),
            'activity_rate': sum(1 for ep in results['episodes'] if ep['active']) / len(results['episodes']) * 100,

            # ğŸš¨ MÃ‰TRICAS REAIS DE TRADING
            'mean_portfolio_pnl': np.mean(portfolio_pnls),
            'std_portfolio_pnl': np.std(portfolio_pnls),
            'median_portfolio_pnl': np.median(portfolio_pnls),
            'mean_portfolio_value': np.mean(portfolio_values),
            'total_real_pnl': sum(portfolio_pnls),
            'pnl_ci_95_lower': pnl_ci_95[0],  # ğŸ”¥ NOVO: Intervalo de confianÃ§a inferior
            'pnl_ci_95_upper': pnl_ci_95[1],  # ğŸ”¥ NOVO: Intervalo de confianÃ§a superior

            # MÃ©tricas de trades
            'total_trades': sum(trades),
            'avg_trades_per_episode': np.mean(trades),
            'total_winning_trades': total_winning_trades,
            'total_losing_trades': total_losing_trades,
            'real_win_rate': real_win_rate,

            # EstatÃ­sticas detalhadas
            'max_portfolio_pnl': max(portfolio_pnls) if portfolio_pnls else 0,
            'min_portfolio_pnl': min(portfolio_pnls) if portfolio_pnls else 0,
            'portfolio_pnl_range': max(portfolio_pnls) - min(portfolio_pnls) if portfolio_pnls else 0,
        }
        
        # ğŸš€ SAÃDA OTIMIZADA COM INTERVALOS DE CONFIANÃ‡A
        print(f"  â±ï¸ Tempo: {episode_steps * len(results['episodes']) / 1000:.1f}k steps")
        print(f"  ğŸ“Š Sharpe: {metrics['sharpe_ratio']:.4f} Â±{sharpe_stderr:.4f}")
        print(f"  ğŸ’° PnL MÃ©dio: ${metrics['mean_portfolio_pnl']:.2f} (CI95: ${pnl_ci_95[0]:.2f} - ${pnl_ci_95[1]:.2f})")
        print(f"  ğŸ’¸ PnL Total: ${metrics['total_real_pnl']:.2f}")
        print(f"  ğŸ¯ Win Rate: {real_win_rate:.1f}% ({total_winning_trades}/{total_real_trades})")
        print(f"  ğŸ“ˆ Trades/ep: {metrics['avg_trades_per_episode']:.1f}")
        print(f"  ğŸ¯ Activity: {metrics['activity_rate']:.1f}%")
        
        return metrics
    else:
        print(f"âŒ Nenhum episÃ³dio vÃ¡lido para {model_name}")
        return None

def main():
    """
    ğŸš€ MAIN ULTRA OPTIMIZADO: AvaliaÃ§Ã£o Nineth 4.5M e 4.75M com mÃ¡xima velocidade
    """
    print("ğŸš€ AVALIAÃ‡ÃƒO NINETH - CHECKPOINTS 4.5M e 4.75M (PRE-BYPASS)")
    print("=" * 60)
    print(f"ğŸ¯ Nineth checkpoints: 4.5M e 4.75M (Legacy policy)")
    print(f"âš¡ {NUM_EPISODES} episÃ³dios por checkpoint")
    print(f"ğŸ² {len(SEEDS)} seeds")
    print(f"ğŸ• Steps por episÃ³dio: {TEST_STEPS}")
    print(f"ğŸš€ BATCH SIZE: {BATCH_SIZE} (Ultra Speed Mode)")
    print(f"ğŸ¯ SMART TERMINATION: {INACTIVITY_THRESHOLD*100:.0f}% holds, window={ACTIVITY_WINDOW}")
    print(f"ğŸ§  LAZY METRICS: Min {MIN_VALID_STEPS} steps")
    print("-" * 60)

    # ğŸš€ PRE-LOAD todos os modelos em paralelo
    print("ğŸš€ [INIT] Pre-carregando dataset e modelos...")
    preload_all_models()
    preprocess_dataset_once()  # Pre-processar dataset
    print("âœ… [INIT] InicializaÃ§Ã£o completa\n")

    all_results = {}
    best_model_sharpe = None
    best_sharpe = -999
    best_model_pnl = None
    best_pnl = -99999

    start_time = datetime.now()
    
    for i, checkpoint_path in enumerate(CHECKPOINTS_TO_TEST):
        try:
            print(f"[{i+1}/{len(CHECKPOINTS_TO_TEST)}] ", end='')

            # Carregar modelo diretamente (sem cache)
            model_name = os.path.basename(checkpoint_path)
            print(f"ğŸ“ {model_name}")

            metrics = evaluate_model_ultra_optimized(checkpoint_path)

            if metrics:
                all_results[model_name] = metrics

                # Track best models
                if metrics.get('sharpe_ratio', -999) > best_sharpe:
                    best_sharpe = metrics['sharpe_ratio']
                    best_model_sharpe = model_name

                if metrics.get('total_real_pnl', -99999) > best_pnl:
                    best_pnl = metrics['total_real_pnl']
                    model_name = os.path.basename(checkpoint_path)
                    try:
                        steps = model_name.split('_')[2]
                    except:
                        steps = model_name
                    best_model_pnl = steps
        
        except Exception as e:
            print(f"âŒ Erro avaliando {os.path.basename(checkpoint_path)}: {e}")
            traceback.print_exc()
    
    end_time = datetime.now()
    total_time = end_time - start_time
    
    print("\\n" + "=" * 60)
    print("ğŸ† RESULTADOS FINAIS - BATTLE OF CHAMPIONS")
    print("=" * 60)
    print(f"â±ï¸ Tempo total: {total_time}")
    print(f"ğŸš€ Velocidade: {len(CHECKPOINTS_TO_TEST) * NUM_EPISODES / total_time.total_seconds():.2f} ep/s")
    print(f"ğŸ¥‡ Melhor Sharpe: {best_model_sharpe} ({best_sharpe:.4f})")
    print(f"ğŸ’° Melhor PnL: {best_model_pnl} (${best_pnl:.2f})")
    
    # ğŸ”¥ RELATÃ“RIO DETALHADO DE CADA MODELO
    print("\\n" + "ğŸ“Š RANKING POR SHARPE RATIO:")
    print("-" * 60)
    
    # Ordenar por Sharpe ratio
    sorted_results = sorted(all_results.items(), key=lambda x: x[1].get('sharpe_ratio', -999), reverse=True)
    
    for i, (model_path, metrics) in enumerate(sorted_results):  # Todos os checkpoints
        model_name = os.path.basename(model_path)
        try:
            # Extrair steps do nome do checkpoint: checkpoint_4500000_steps_...
            # Split: ['checkpoint', '4500000', 'steps', ...]
            parts = model_name.split('_')
            steps = parts[1]  # Segundo elemento = nÃºmero de steps
            steps_formatted = f"{int(steps)/1000000:.2f}M" if int(steps) >= 1000000 else f"{int(steps)/1000:.0f}k"
            print(f"\\nğŸ·ï¸ NINETH {steps_formatted} ({steps} steps):")
            print(f"  ğŸ“ˆ Return mÃ©dio: {metrics['mean_return']:.4f}")
            print(f"  ğŸ“Š Sharpe: {metrics['sharpe_ratio']:.4f} Â±{metrics.get('sharpe_stderr', 0):.4f}")
            print(f"  ğŸ’° PnL mÃ©dio: ${metrics['mean_portfolio_pnl']:.2f} (CI95: ${metrics.get('pnl_ci_95_lower', 0):.2f} - ${metrics.get('pnl_ci_95_upper', 0):.2f})")
            print(f"  ğŸ’¸ PnL total: ${metrics['total_real_pnl']:.2f}")
            print(f"  ğŸ¯ Win Rate: {metrics['real_win_rate']:.1f}%")
            print(f"  ğŸ“ˆ Trades/ep: {metrics['avg_trades_per_episode']:.1f}")
            print(f"  ğŸ¯ Activity: {metrics['activity_rate']:.1f}%")
        except Exception as e:
            print(f"\\nğŸ·ï¸ {model_name}:")
            print(f"  ğŸ“Š Sharpe: {metrics['sharpe_ratio']:.4f}")
            print(f"  ğŸ’° PnL total: ${metrics['total_real_pnl']:.2f}")
            print(f"  (Erro ao extrair steps: {e})")
    
    print("\\n" + "âœ… AVALIAÃ‡ÃƒO NINETH CONCLUÃDA!")
    print("ğŸ¯ Nineth 4.5M e 4.75M - Checkpoints PRE-BYPASS testados!")
    return all_results

if __name__ == "__main__":
    try:
        results = main()
        print("\\nğŸ¯ AVALIAÃ‡ÃƒO NINETH - Resultados salvos em memÃ³ria.")
        print("ğŸ† Checkpoints 4.5M e 4.75M (Legacy) - Teste completo!")
    except Exception as e:
        print(f"âŒ Erro durante avaliaÃ§Ã£o: {e}")
        traceback.print_exc()
