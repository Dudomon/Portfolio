#!/usr/bin/env python3
"""
üçí TESTE CHERRY DEBUG - INVESTIGAR AMBIENTE
==========================================

Teste direto do TradingEnv do Cherry para investigar por que 0 trades.
Vamos testar o pr√≥prio ambiente Cherry step by step.
"""

import sys
import os
import numpy as np
import pandas as pd
import torch
from datetime import datetime

sys.path.append("D:/Projeto")

def test_cherry_env_direct():
    """Testar TradingEnv do Cherry diretamente"""
    print("üçí TESTE DIRETO DO TRADING ENV CHERRY")
    print("=" * 60)
    
    # Mudar para diret√≥rio correto
    original_cwd = os.getcwd()
    os.chdir("D:/Projeto")
    
    try:
        # Importar Cherry
        from cherry import load_optimized_data_original, TradingEnv
        
        # Carregar dados
        print("üìä Carregando dados Cherry...")
        data = load_optimized_data_original()
        print(f"‚úÖ Dados carregados: {len(data)} barras")
        
        # Usar √∫ltimas 5000 barras (teste r√°pido)
        if len(data) > 5000:
            data = data.iloc[-5000:].reset_index(drop=True)
            print(f"üìÖ Usando dados recentes: {len(data)} barras")
        
        # Criar ambiente Cherry
        print("\nüîß Criando TradingEnv Cherry...")
        env = TradingEnv(
            df=data,
            window_size=20,
            is_training=True,  # FOR√áAR modo treinamento
            initial_balance=500.0,
            trading_params={
                'min_lot_size': 0.02,
                'max_lot_size': 0.03,
                'enable_shorts': True,
                'max_positions': 2
            }
        )
        
        print(f"‚úÖ Ambiente criado")
        print(f"üîç Action Space: {env.action_space}")
        print(f"üîç Obs Space: {env.observation_space.shape}")
        
        # Reset inicial
        print("\nüîÑ Reset inicial...")
        obs = env.reset()
        print(f"‚úÖ Obs shape: {obs.shape}")
        
        # Testar actions manuais
        print("\nüéØ TESTANDO ACTIONS MANUAIS:")
        print("=" * 40)
        
        test_actions = [
            # entry_decision, confidence, pos1_mgmt, pos2_mgmt
            [1.0, 0.8, 0.0, 0.0],  # LONG com alta confian√ßa
            [2.0, 0.9, 0.0, 0.0],  # SHORT com alta confian√ßa
            [1.5, 0.7, 0.0, 0.0],  # Entry moderado
            [0.8, 0.6, 0.0, 0.0],  # Entry baixo mas com confian√ßa
            [0.0, 0.0, 0.0, 0.0],  # HOLD
        ]
        
        total_trades = 0
        
        for i, action in enumerate(test_actions):
            print(f"\nStep {i+1}: Action={action}")
            
            # Converter para numpy array
            action = np.array(action, dtype=np.float32)
            
            # Executar step
            obs, reward, done, info = env.step(action)
            
            # Verificar resultado
            trades_executed = info.get('trade_executed', False)
            positions_count = len(getattr(env, 'positions', []))
            portfolio_value = env.portfolio_value
            
            print(f"  Trade executado: {trades_executed}")
            print(f"  Posi√ß√µes ativas: {positions_count}")
            print(f"  Portfolio: ${portfolio_value:.2f}")
            print(f"  Reward: {reward:.4f}")
            
            if trades_executed:
                total_trades += 1
                print("  ‚úÖ TRADE EXECUTADO!")
            else:
                print("  ‚ùå Nenhum trade")
            
            # Info adicional
            if 'debug_info' in info:
                print(f"  Debug: {info['debug_info']}")
        
        print(f"\nüìä RESULTADO FINAL:")
        print(f"  Total trades executados: {total_trades}")
        print(f"  Portfolio final: ${env.portfolio_value:.2f}")
        
        # Teste com modelo real se dispon√≠vel
        print(f"\nü§ñ TESTANDO COM MODELO CHERRY:")
        print("=" * 40)
        
        model_path = "D:/Projeto/Otimizacao/treino_principal/models/Cherry/Cherry_simpledirecttraining_1000000_steps_20250905_112708.zip"
        
        if os.path.exists(model_path):
            try:
                from sb3_contrib import RecurrentPPO
                model = RecurrentPPO.load(model_path)
                model.policy.set_training_mode(False)
                print("‚úÖ Modelo carregado")
                
                # Reset ambiente
                obs = env.reset()
                lstm_states = None
                model_trades = 0
                
                # Testar 100 steps
                print("üöÄ Executando 100 steps com modelo...")
                for step in range(100):
                    # Predict
                    action, lstm_states = model.predict(obs, state=lstm_states, deterministic=False)
                    
                    # Debug primeiros 5 steps
                    if step < 5:
                        print(f"  Step {step}: Action={action}, Entry={action[0]:.3f}, Conf={action[1]:.3f}")
                    
                    # Step
                    obs, reward, done, info = env.step(action)
                    
                    if info.get('trade_executed', False):
                        model_trades += 1
                        print(f"  Step {step}: ‚úÖ TRADE EXECUTADO! Total: {model_trades}")
                
                print(f"\nüìä RESULTADO MODELO:")
                print(f"  Trades executados: {model_trades}")
                print(f"  Portfolio final: ${env.portfolio_value:.2f}")
                
            except Exception as e:
                print(f"‚ùå Erro ao testar modelo: {e}")
        else:
            print("‚ö†Ô∏è Modelo n√£o encontrado")
        
        return True
        
    except Exception as e:
        print(f"‚ùå ERRO: {e}")
        import traceback
        traceback.print_exc()
        return False
        
    finally:
        os.chdir(original_cwd)

if __name__ == "__main__":
    print(f"‚è∞ In√≠cio: {datetime.now().strftime('%H:%M:%S')}")
    
    try:
        success = test_cherry_env_direct()
        
        if success:
            print(f"\n‚úÖ TESTE CONCLU√çDO")
        else:
            print(f"\n‚ùå TESTE FALHOU")
            
    except KeyboardInterrupt:
        print(f"\n‚èπÔ∏è Interrompido")
    except Exception as e:
        print(f"\n‚ùå ERRO CR√çTICO: {e}")
    
    print(f"‚è∞ Fim: {datetime.now().strftime('%H:%M:%S')}")