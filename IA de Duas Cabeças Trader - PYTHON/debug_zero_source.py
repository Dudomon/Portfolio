"""
üîç DEBUG ZERO SOURCE - Descobrir ONDE os zeros come√ßam
Sistema para rastrear exatamente qual componente inicia os zeros
"""

import numpy as np
import sys
import os
sys.path.append(os.getcwd())

def analyze_zero_progression():
    """Analisa a progress√£o dos zeros no seu log"""
    
    print("üîç AN√ÅLISE DA PROGRESS√ÉO DE ZEROS")
    print("=" * 60)
    
    # Dados do seu log
    zero_components = [
        ("features_extractor.temporal_projection.weight", 54.3),
        ("features_extractor.transformer_layer.self_attn.in_proj_bias", 33.3),
        ("lstm_actor.weight_ih_l0", 48.4),
        ("lstm_actor.weight_hh_l0", 61.3),
        ("lstm_actor.bias_ih_l0", 42.1),
        ("lstm_actor.bias_hh_l0", 42.1),
    ]
    
    print("üìä COMPONENTES COM ZEROS:")
    for component, percentage in zero_components:
        risk_level = "üö® CR√çTICO" if percentage > 50 else "‚ö†Ô∏è  ALTO" if percentage > 30 else "üìä NORMAL"
        print(f"  {risk_level} {component}: {percentage}%")
    
    print(f"\nüéØ AN√ÅLISE POR CAMADA:")
    
    # Transformer components
    transformer_zeros = [c for c in zero_components if "features_extractor" in c[0]]
    print(f"\nüîß TRANSFORMER EXTRACTOR:")
    for component, percentage in transformer_zeros:
        print(f"  - {component.split('.')[-1]}: {percentage}%")
        
    # LSTM components  
    lstm_zeros = [c for c in zero_components if "lstm_actor" in c[0]]
    print(f"\nüß† LSTM ACTOR:")
    for component, percentage in lstm_zeros:
        print(f"  - {component.split('.')[-1]}: {percentage}%")
    
    print(f"\nüí° HIP√ìTESES SOBRE A ORIGEM:")
    
    # An√°lise das hip√≥teses
    max_transformer = max([p for c, p in transformer_zeros])
    max_lstm = max([p for c, p in lstm_zeros])
    
    if max_transformer > max_lstm:
        print(f"  üéØ HIP√ìTESE 1: Transformer √© a origem (max: {max_transformer}%)")
        print(f"    - temporal_projection est√° explodindo primeiro")
        print(f"    - Gradientes propagam para LSTM downstream")
        print(f"    - A√á√ÉO: Investigar transformer_extractor.py")
    else:
        print(f"  üéØ HIP√ìTESE 2: LSTM √© a origem (max: {max_lstm}%)")
        print(f"    - LSTM saturando por inputs extremos")
        print(f"    - Gradientes propagam para transformer upstream")
        print(f"    - A√á√ÉO: Investigar LSTM initialization ou inputs")
    
    if "weight_hh_l0" in [c[0].split('.')[-1] for c, p in lstm_zeros if p > 60]:
        print(f"  üö® HIP√ìTESE 3: LSTM recurrent weights problem")
        print(f"    - weight_hh_l0 (recurrent) > 60% zeros")
        print(f"    - Gradient vanishing/exploding em sequ√™ncias")
        print(f"    - A√á√ÉO: Verificar sequence length e gradient clipping")
    
    print(f"\nüîç PADR√ÉO DE DISTRIBUI√á√ÉO DE A√á√ïES:")
    print(f"  - HOLD: 88.7% (MUITO ALTO - indica paralisia)")
    print(f"  - LONG: 7.5% (baixo)")  
    print(f"  - SHORT: 0.1% (quase zero)")
    print(f"  üí° ISSO SUGERE: Network est√° 'travando' nas a√ß√µes seguras")
    
    print(f"\nüß† ESTRAT√âGIAS DE DEBUG:")
    print(f"  1. üîß REDUZIR transformer monitor frequencies mais ainda")
    print(f"  2. üéØ VERIFICAR se gradient clipping est√° muito baixo")
    print(f"  3. üìâ TESTAR com reward system V2 temporariamente")
    print(f"  4. ‚ö° AUMENTAR learning rate para compensar zeros")
    print(f"  5. üîÑ REINICIALIZAR pesos das camadas problem√°ticas")
    
    print(f"\nüéØ PRIORIDADE DE INVESTIGA√á√ÉO:")
    print(f"  1. features_extractor.temporal_projection.weight (54.3%)")
    print(f"  2. lstm_actor.weight_hh_l0 (61.3%)")
    print(f"  3. Intera√ß√£o entre transformer ‚Üí LSTM")
    
    return {
        'transformer_max': max_transformer,
        'lstm_max': max_lstm,
        'primary_suspect': 'transformer' if max_transformer > max_lstm else 'lstm'
    }

def suggest_fixes():
    """Sugere corre√ß√µes espec√≠ficas baseadas na an√°lise"""
    
    print(f"\nüõ†Ô∏è CORRE√á√ïES ESPEC√çFICAS RECOMENDADAS:")
    print("=" * 60)
    
    print(f"\n1. üéØ TEMPORAL_PROJECTION (54.3% zeros):")
    print(f"   - Reduzir xavier gain de 0.6 para 0.3")
    print(f"   - Adicionar gradient clipping espec√≠fico")
    print(f"   - Verificar input normalization")
    
    print(f"\n2. üß† LSTM WEIGHTS (61.3% zeros):")
    print(f"   - Aumentar forget gate bias para 2.0")
    print(f"   - Verificar se sequence est√° muito longa")
    print(f"   - Considerar gradient clipping por camada")
    
    print(f"\n3. ‚ö° LEARNING RATE:")
    print(f"   - Atual: 3e-05 pode estar MUITO baixo para recovery")
    print(f"   - Testar: 6e-05 temporariamente")
    print(f"   - Ou usar learning rate warm-up")
    
    print(f"\n4. üîÑ RESET STRATEGY:")
    print(f"   - Re-initialize s√≥ as camadas problem√°ticas")
    print(f"   - Manter pesos que est√£o funcionando")
    print(f"   - Gradient accumulation para estabilizar")

if __name__ == "__main__":
    results = analyze_zero_progression()
    suggest_fixes()